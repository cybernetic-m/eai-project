{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3O4mXmBol0t"
      },
      "source": [
        "# IMPORT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "try:\n",
        "    import google.colab # type: ignore\n",
        "    colab = True\n",
        "except:\n",
        "    colab = False\n",
        "\n",
        "if colab:\n",
        "    !git clone \"https://github.com/cybernetic-m/eai-project.git\" # type: ignore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "9gQw18CXol0v"
      },
      "outputs": [],
      "source": [
        "# Model\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torch import optim\n",
        "from torch.optim.lr_scheduler import ExponentialLR \n",
        "\n",
        "# Others\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        " \n",
        "# Our files\n",
        "if colab:\n",
        "    sys.path.append('/content/eai-project/training')\n",
        "    sys.path.append('/content/eai-project/preprocessing')\n",
        "    sys.path.append('/content/eai-project/dataset')\n",
        "    sys.path.append('/content/eai-project/utils')\n",
        "    sys.path.append('/content/eai-project/models')\n",
        "    sys.path.append('/content/eai-project/testing')\n",
        "    from train import train\n",
        "    from preprocessing import *\n",
        "    from thermal_dataset import thermal_dataset \n",
        "    from utils import *\n",
        "    from complete_model import complete_model \n",
        "    from lstm_only import lstm_only\n",
        "    from testing import test\n",
        "    prefix = '/content'\n",
        "        \n",
        "else:\n",
        "    from training.train import train\n",
        "    from preprocessing.preprocessing import *\n",
        "    from dataset.thermal_dataset import thermal_dataset\n",
        "    from utils.csv_utils import *\n",
        "    from models.complete_model import complete_model\n",
        "    from models.complete_model_autoencoder import complete_model_autoencoder\n",
        "    from models.lstm_only import lstm_only\n",
        "    from testing.test import test\n",
        "    from blocks import mlp, linear, rnn, lstm, cnn\n",
        "    prefix = '.'\n",
        "    \n",
        "pd.set_option('display.max_columns', None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "autoencoder_train = False # to train only the autoencoder\n",
        "\n",
        "hyper_parameters = {'num_epochs': 100,\n",
        "                    'batch_size': 256,\n",
        "                    'hidden_dim' : 3,\n",
        "                    'lr': 0.001,\n",
        "                    'mode': 'auto-weighted', #average, mlp, linear, auto-weighted\n",
        "                    'extractor_type': 'conv', #lstm (if you want to use the lstm autoencoder), conv (if you want to use the convolutional autoencoder)\n",
        "                    'ensemble': True,\n",
        "                    'timesteps': 200,\n",
        "                    'window_size':30,\n",
        "                    'norm': 'Std', # Not (Raw Data), Minmax (MinMax Scaling), Std (Standard Scaling)\n",
        "                    'file':1,\n",
        "                    'weight_decay': 0,\n",
        "                    'pretrain':False,\n",
        "                    'heterogeneous': True,\n",
        "                    'lr_multipliers_extractor': 0.1,\n",
        "                    'lr_multipliers_ensemble': {\n",
        "                        mlp: 10,\n",
        "                        linear: 10,\n",
        "                        rnn: 1,\n",
        "                        lstm: 1,\n",
        "                        cnn: 1\n",
        "                    }\n",
        "\n",
        "                        }\n",
        "\n",
        "# Parameters of the convolutional autoencoder\n",
        "conv_autoencoder_dict = {'in_kern_out': [[4, 5, 5], [5, 5, 6],[6, 5, 7]], # List of hyperparam of autoencoder [[in_channels, kernel_size, out_channels], ...]\n",
        "                    'pooling_kernel_size': 2, # how much big is the kernel of the pooling (i.e. 2 means halving the dimension each layer)\n",
        "                    'padding': 'same', # 'same', 'full', 'valid'\n",
        "                    'pooling': 'max', # 'max' for Max Pooling and 'avg' for Average Pooling \n",
        "                    'scale_factor': 2, # upsample scale_factor, 2 means double the dimension each layer\n",
        "                    'upsample_mode': 'linear', # mode of the upsampling 'linear', 'nearest'\n",
        "                    'dropout': 0.0\n",
        " }\n",
        "\n",
        "lstm_autoencoder_dict = {'in_hidd': [[4, 3], [3,2]], # List of hyperparam of autoencoder [[input_dim, hidden_dim], ...]\n",
        "                        'dropout': 0.75\n",
        " }\n",
        "\n",
        "\n",
        "if hyper_parameters['extractor_type'] == 'conv':\n",
        "    feature_dim = int(( hyper_parameters['timesteps'] / (2*(len(conv_autoencoder_dict['in_kern_out'])-1))*conv_autoencoder_dict['in_kern_out'][-1][-1]) /2)\n",
        "    autoencoder_dict = conv_autoencoder_dict\n",
        "elif hyper_parameters['extractor_type'] == 'lstm':\n",
        "    feature_dim = hyper_parameters['timesteps']*lstm_autoencoder_dict['in_hidd'][-1][-1] \n",
        "    autoencoder_dict = conv_autoencoder_dict\n",
        "if hyper_parameters['heterogeneous']:\n",
        "    feature_dim += 3\n",
        "    \n",
        "\n",
        "# Definition of the model (You can decomment to include more models)\n",
        "ensemble_model = {\n",
        "    'mlp': [{'layer_dim_list': [ feature_dim,int(feature_dim/1.5),int(feature_dim/3),int(feature_dim/5),int(feature_dim/8),int(feature_dim/10),3]}],\n",
        "            #{'layer_dim_list': [ feature_dim,int(feature_dim*1.5),3]}], \n",
        "    'ARIMA': [{'p': 2, 'd': 0, 'q': 2, 'ps': 0, 'ds': 0, 'qs': 0, 's': 1}], \n",
        "    #'linear_regressor': [{'in_features': feature_dim, 'out_features': 3, 'bias':False}],\n",
        "    'lstm': [{'feature_dim':3, 'input_dim':feature_dim, 'num_layers':1}],\n",
        "    #'rnn': [{'feature_dim':3, 'input_dim':feature_dim, 'num_layers':1}],\n",
        "    #'cnn': [{'input_dim':hyper_parameters['hidden_dim'],\n",
        "    #            'hidden_dim_list': [ int(feature_dim/10),int(feature_dim/20),int(feature_dim/30)],\n",
        "    #            'output_dim': 3,\n",
        "    #            'kernel_size_list':[2,4,2]\n",
        "    #            }]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data already exists!\n",
            "./data/Xtraining1Std.npy\n",
            "./data/Y30training1Std.npy\n"
          ]
        }
      ],
      "source": [
        "skip = False\n",
        "test_flag = True\n",
        "\n",
        "if os.path.exists(prefix+'/data/X'+'training'+str(hyper_parameters['file'])+str(hyper_parameters['norm'])+'.npy') and os.path.exists(prefix+'/data/Y'+str(hyper_parameters['window_size'])+'training'+str(hyper_parameters['file'])+str(hyper_parameters['norm'])+'.npy'):\n",
        "    print(\"Data already exists!\")\n",
        "    print(prefix+'/data/X'+'training'+str(hyper_parameters['file'])+str(hyper_parameters['norm'])+'.npy')\n",
        "    print(prefix+'/data/Y'+str(hyper_parameters['window_size'])+'training'+str(hyper_parameters['file'])+str(hyper_parameters['norm'])+'.npy')\n",
        "    skip = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Reproducibility and Device Setting**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set a seed for reproducibility purposes\n",
        "seed = 46\n",
        "torch.manual_seed(seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "np.random.seed(seed)\n",
        "\n",
        "# Set the device (cuda for Nvidia GPUs, mps for M1, M2 .. Apple Silicon)\n",
        "if torch.cuda.is_available():\n",
        "    device = \"cuda\"\n",
        "elif torch.backends.mps.is_available():\n",
        "    device = \"mps\"\n",
        "else:\n",
        "    device = \"cpu\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFQrCrM-ol0w"
      },
      "source": [
        "# DATASET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1mHN7T9Rol0x",
        "outputId": "6d8b8eef-3135-4b49-f113-9ac4548ea7aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CSV file already downloaded!\n",
            "CSV file already unzipped!\n"
          ]
        }
      ],
      "source": [
        "link_zipped_csv = 'https://drive.google.com/file/d/1MssQF4pI_rZqiiDBP4XaLTT1ZaN6ykLm/view?usp=drive_link'\n",
        "gdrive_link = 'https://drive.google.com/uc?id='\n",
        "csv_dir = './csv'\n",
        "zipped_file = './csv.zip'\n",
        "\n",
        "download_csv(\n",
        "    link_zipped_csv,\n",
        "    gdrive_link,\n",
        "    zipped_file\n",
        ")\n",
        "\n",
        "unzip_csv(\n",
        "    zipped_file,\n",
        "    csv_dir,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "eKLx-ldvGxvs"
      },
      "outputs": [],
      "source": [
        "if not skip:\n",
        "\n",
        "    path = '/content/csv/thermal_drift_features_lab_05_02.csv'\n",
        "\n",
        "    # Read all the CSV files containing the Temperatures\n",
        "    features_1 = pd.read_csv(os.path.join(prefix,'csv/thermal_drift_features_lab_05_02.csv'))\n",
        "    features_2 = pd.read_csv(os.path.join(prefix, 'csv/thermal_drift_features_lab_05_03.csv'))\n",
        "    features_3 = pd.read_csv(os.path.join(prefix,'csv/thermal_drift_features_lab_05_04.csv'))\n",
        "    features_4 = pd.read_csv(os.path.join(prefix,'csv/thermal_drift_features_lab_05_05.csv'))\n",
        "    features_5 = pd.read_csv(os.path.join(prefix,'csv/thermal_drift_features_lab_05_06.csv'))\n",
        "\n",
        "    # Read all the CSV files containing the X1, Y1, Z1 \n",
        "    targets_1 = pd.read_csv(os.path.join(prefix,'csv/thermal_drift_targets_lab_05_02.csv'))\n",
        "    targets_2 = pd.read_csv(os.path.join(prefix,'csv/thermal_drift_targets_lab_05_03.csv'))\n",
        "    targets_3 = pd.read_csv(os.path.join(prefix,'csv/thermal_drift_targets_lab_05_04.csv'))\n",
        "    targets_4 = pd.read_csv(os.path.join(prefix,'csv/thermal_drift_targets_lab_05_05.csv'))\n",
        "    targets_5 = pd.read_csv(os.path.join(prefix,'csv/thermal_drift_targets_lab_05_06.csv'))\n",
        "\n",
        "    features = [features_1, features_2, features_3, features_4, features_5]\n",
        "    targets = [targets_1,targets_2,targets_3,targets_4,targets_5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "if not skip:\n",
        "    for feature, target in zip(features, targets):\n",
        "        feature.drop([\n",
        "            \"name\", \"tags\",\n",
        "            \"2\\\"Tray1 Vacuum Sensor\", \"2\\\"Tray2 Vacuum Sensor\", \"2\\\"Tray3 Vacuum Sensor\",\n",
        "            \"Avg Oven Temperature\", \"Chuck Temp [Cdeg]\", \"Chuck Temp2 [Cdeg]\",\n",
        "            \"Chuck1 Vacuum Sensor\", \"Contrast\", \"Device State\",\n",
        "            \"Dispenser1 Pressure Sensor\", \"Machine Room Temp\", \"Main Air\", \"Main Vacuum\",\n",
        "            \"Oven Temperature\", \"PE_Rx\", \"PE_Ry\", \"PE_Rz\", \"PE_X1\", \"PE_Y1\", \"PE_Z1\",\n",
        "            \"PUT1 Flow Sensor\", \"PUT2 Flow Sensor1\", \"PUT2 Flow Sensor2\",\n",
        "            \"PUT2 Flow Sensor3\", \"PUT2 Flow Sensor4\", \"PUT2 Flow Sensor5\",\n",
        "            \"Photodiode\", \"Pixel Power\", \"Preciser1 Vacuum Sensor\",\n",
        "            \"Tec FIB1 Holder\", \"Tec FIB1 Plate\", \"Tec FIB2 Holder\", \"Tec FIB2 Plate\",\n",
        "            \"Torque11\",\"Torque2\",\"Torque3\",\"Torque4\",\"Torque5\",\"Torque6\"\n",
        "        ], axis=1, inplace=True)\n",
        "        if 'name' in target.keys() and 'tags' in target.keys():\n",
        "\n",
        "            target.drop(['name', 'tags'], axis=1, inplace=True)\n",
        "            \n",
        "            \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "qUZH1JpDfNY0",
        "outputId": "694acf4b-ac9a-401f-f4ef-d6b8105ebf1b"
      },
      "outputs": [],
      "source": [
        "if not skip:\n",
        "    print(features[1]) # Print the features_1 table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "OtsO4hF1fHUU",
        "outputId": "3b3e33b6-a0eb-474b-814a-67338bee9fdd"
      },
      "outputs": [],
      "source": [
        "if not skip:\n",
        "\n",
        "    print(targets[1]) # Print the target_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "H7L8dLyMmesB"
      },
      "outputs": [],
      "source": [
        "if not skip:\n",
        "    # Put X1, Y1, Z1 on the same row of X1 eliminating the NAN values\n",
        "    fixed_targets = [] # Create a list of target in which we put X1, Y1, Z1 in the same row\n",
        "    for target in targets:\n",
        "        fixed_targets.append(transform_dataframe(target)) # iterate over target_1,2,3 ... and append in fixed_targets\n",
        "        \n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "23LmYWUfmqDM",
        "outputId": "fc9873f7-b53c-4dbc-a2bd-b0cf9fab7f2c"
      },
      "outputs": [],
      "source": [
        "if not skip:\n",
        "\n",
        "    print(fixed_targets[1]) # Print the fixed_target_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "DOVEQQeQr36x"
      },
      "outputs": [],
      "source": [
        "if not skip:\n",
        "    # Merge of targets with features in one single dataframe\n",
        "    complete_numbers_list = [] # List of the table with columns that are numbers (0,1,2..) in which we unify both features and targets merging on closest time row\n",
        "    for fixed_target, feature in zip(fixed_targets, features):\n",
        "        complete_numbers_list.append(merge_on_closest_time(fixed_target.reset_index(), feature.reset_index()))\n",
        "\n",
        "    trainig_number_list = []\n",
        "    testing_number_list = []\n",
        "    for i in range(len(complete_numbers_list)):\n",
        "        part_numbers_list = complete_numbers_list[:i] + complete_numbers_list[i+1:]\n",
        "        trainig_number_list.append(pd.concat(part_numbers_list))\n",
        "        testing_number_list.append(complete_numbers_list[i])\n",
        "        \n",
        "    complete_numbers_dataframe = pd.concat(complete_numbers_list)\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "if not skip: \n",
        "    print(complete_numbers_list) # Print of one example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "m39ldRHjsbJH"
      },
      "outputs": [],
      "source": [
        "if not skip:\n",
        "\n",
        "    complete = complete_numbers_dataframe.rename(columns={\n",
        "        0: 'id',\n",
        "        1: 'time',\n",
        "        2: 'X1',\n",
        "        3: 'Y1',\n",
        "        4: 'Z1',\n",
        "        5: 'to_remove',\n",
        "        6: 'time_2',\n",
        "        7: 'Temp1',\n",
        "        8: 'Temp2',\n",
        "        9: 'Temp3',\n",
        "        10: 'Temp4'\n",
        "        })\n",
        "    complete.drop(['time', 'to_remove', 'time_2'], axis=1, inplace=True)\n",
        "    training_list = []\n",
        "    testing_list = []\n",
        "    for training, testing in zip(trainig_number_list, testing_number_list):\n",
        "        training_tmp = training.rename(columns={\n",
        "            0: 'id',\n",
        "            1: 'time',\n",
        "            2: 'X1',\n",
        "            3: 'Y1',\n",
        "            4: 'Z1',\n",
        "            5: 'to_remove',\n",
        "            6: 'time_2',\n",
        "            7: 'Temp1',\n",
        "            8: 'Temp2',\n",
        "            9: 'Temp3',\n",
        "            10: 'Temp4'\n",
        "            })\n",
        "        training_tmp.drop(['time', 'to_remove', 'time_2'], axis=1, inplace=True)\n",
        "        training_list.append(training_tmp)\n",
        "        \n",
        "        testing_tmp = testing.rename(columns={\n",
        "            0: 'id',\n",
        "            1: 'time',\n",
        "            2: 'X1',\n",
        "            3: 'Y1',\n",
        "            4: 'Z1',\n",
        "            5: 'to_remove',\n",
        "            6: 'time_2',\n",
        "            7: 'Temp1',\n",
        "            8: 'Temp2',\n",
        "            9: 'Temp3',\n",
        "            10: 'Temp4'\n",
        "            })\n",
        "        testing_tmp.drop(['time', 'to_remove', 'time_2'], axis=1, inplace=True)\n",
        "        testing_list.append(testing_tmp)\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "if not skip:\n",
        "\n",
        "    print(training_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "if not skip:\n",
        "\n",
        "    # Save the features and targets in file npy\n",
        "    for i, (testing, training) in enumerate(zip(testing_list, training_list)):\n",
        "\n",
        "        # Transform the training and test data in float\n",
        "        training.astype(float) \n",
        "        testing.astype(float) \n",
        "\n",
        "        # Take from dataframe the values of the columns of temperatures and positions saving into smallest dataframe of training/test\n",
        "        X_train = training[['Temp1','Temp2', 'Temp3', 'Temp4']] \n",
        "        Y_train = training[['X1', 'Y1', 'Z1']] \n",
        "        X_test = testing[['Temp1','Temp2', 'Temp3', 'Temp4']] \n",
        "        Y_test = testing[['X1', 'Y1', 'Z1']] \n",
        "\n",
        "        # Transform the X, Y from dataframe in numpy array both for test and train\n",
        "        X_train = X_train.values.astype(np.float32) \n",
        "        Y_train = Y_train.values.astype(np.float32) \n",
        "        X_test = X_test.values.astype(np.float32) \n",
        "        Y_test = Y_test.values.astype(np.float32) \n",
        "\n",
        "        # Do the gradient of the positions both for test and train\n",
        "        Y_train = my_gradient(Y_train, window_size=hyper_parameters['window_size']) \n",
        "        Y_test = my_gradient(Y_test, window_size=hyper_parameters['window_size']) \n",
        " \n",
        "\n",
        "        # Apply the scaling\n",
        "        if hyper_parameters['norm'] != 'Not':\n",
        "            if hyper_parameters['norm'] == 'Minmax':\n",
        "                scaler = MinMaxScaler()\n",
        "            elif hyper_parameters['norm'] == 'Std':\n",
        "                scaler = StandardScaler()\n",
        "\n",
        "            X_train = scaler.fit_transform(X_train)\n",
        "            X_test = scaler.fit_transform(X_test)\n",
        "            Y_train = scaler.fit_transform(Y_train)\n",
        "            Y_test = scaler.fit_transform(Y_test)\n",
        "        else:\n",
        "            print(\"Using Raw Data!\")\n",
        "    \n",
        "        \n",
        "        # Save the features and targets in file npy\n",
        "        np.save(prefix+'/data'+'/X'+'training'+str(i)+str(hyper_parameters['norm'])+'.npy',X_train)  \n",
        "        np.save(prefix+'/data'+'/Y'+str(hyper_parameters['window_size'])+'training'+str(i)+str(hyper_parameters['norm'])+'.npy',Y_train)\n",
        "        np.save(prefix+'/data'+'/X'+'testing'+str(i)+str(hyper_parameters['norm'])+'.npy',X_test)\n",
        "        np.save(prefix+'/data'+'/Y'+str(hyper_parameters['window_size'])+'testing'+str(i)+str(hyper_parameters['norm'])+'.npy',Y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "if not skip:\n",
        "\n",
        "    targets_1['time'] = pd.to_datetime(targets_1['time'], unit='ns')\n",
        "\n",
        "    # Reshape the DataFrame using melt()\n",
        "    targets_melted = targets_1.reset_index().melt(id_vars=['time'], value_vars=['X1', 'Y1', 'Z1'], var_name='variable', value_name='value')\n",
        "\n",
        "    # Drop rows where 'value' is NaN (to keep only the non-null entries)\n",
        "    targets_melted = targets_melted.dropna(subset=['value'])\n",
        "\n",
        "    # Plot the data\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    for var in targets_melted['variable'].unique():\n",
        "        # Filter data for each variable and plot\n",
        "        temp_df = targets_melted[targets_melted['variable'] == var]\n",
        "        plt.plot(temp_df['time'], temp_df['value'], label=var)\n",
        "\n",
        "    # Add labels and title\n",
        "    plt.xlabel('Time')\n",
        "    plt.ylabel('Values')\n",
        "    plt.title('Plot of X1, Y1, Z1 over Time')\n",
        "    plt.legend(title='Variable')\n",
        "\n",
        "    # Show the plot\n",
        "    plt.show()\n",
        "\n",
        "    #targets.plot(y='X1',x='time')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "if not skip:\n",
        "\n",
        "    # Convert 'time' to datetime (nanoseconds to datetime)\n",
        "    features_1['time'] = pd.to_datetime(features_1['time'], unit='ns')\n",
        "\n",
        "    # Set 'time' as the index\n",
        "    features_1.set_index('time', inplace=True)\n",
        "\n",
        "    # Optionally, you can plot X1, Y1, Z1 directly\n",
        "    features_1[['Temp Sensor 1', 'Temp Sensor 2', 'Temp Sensor 3', 'Temp Sensor 4', ]].plot()\n",
        "\n",
        "    # Add labels and title\n",
        "    plt.xlabel('Time')\n",
        "    plt.ylabel('Values')\n",
        "    plt.title('Plot of Temp Sensor 1, Temp Sensor 2, Temp Sensor 3, Temp Sensor 4 over Time')\n",
        "\n",
        "    # Show the plot\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 8.2750964e-01  3.6703822e-01  5.5890518e-01  9.1104820e-02]\n",
            " [ 8.2750964e-01  6.2521166e-01  5.1233166e-01  1.4015545e-01]\n",
            " [ 8.2750964e-01  8.8338506e-01  5.5890518e-01  1.4015545e-01]\n",
            " ...\n",
            " [ 3.4184408e-01  7.9732728e-01  2.2581613e-05 -4.4845200e-01]\n",
            " [ 3.4184408e-01  7.1126944e-01 -4.6550971e-02 -3.5035077e-01]\n",
            " [ 3.4184408e-01  7.1126944e-01  2.2581613e-05 -4.4845200e-01]]\n",
            "[[1.62778128 0.52317057 3.71087109]\n",
            " [1.21107403 0.58705623 4.16294433]\n",
            " [0.85172156 0.63696138 4.30145188]\n",
            " ...\n",
            " [1.48545645 0.79269374 0.93879646]\n",
            " [1.46527607 0.79906461 0.99458422]\n",
            " [1.45607098 0.83136138 0.98304193]]\n",
            "0\n",
            "15880\n",
            "0\n",
            "15859\n"
          ]
        }
      ],
      "source": [
        "X = np.load(prefix+'/data'+'/X'+'training'+str(hyper_parameters['file'])+str(hyper_parameters['norm'])+'.npy')\n",
        "Y = np.load(prefix+'/data'+'/Y'+str(hyper_parameters['window_size'])+'training'+str(hyper_parameters['file'])+str(hyper_parameters['norm'])+'.npy')\n",
        "\n",
        "print(X)\n",
        "print(Y)\n",
        "\n",
        "splitPerc = [0.7,0.3]\n",
        "splitted_X = split(X, splitPerc)\n",
        "splitted_Y = split(Y, splitPerc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnlFgCAkol0x"
      },
      "source": [
        "# MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "datasetTrain = thermal_dataset((splitted_X[0],splitted_Y[0]), hyper_parameters['timesteps'], device)\n",
        "datasetVal = thermal_dataset((splitted_X[1],splitted_Y[1]), hyper_parameters['timesteps'], device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "BbEyWHlGEJHm"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Autoencoder type: Convolutional\n",
            "3\n",
            "Ensemble Model Summary: ModuleList(\n",
            "  (0): mlp(\n",
            "    (linear_layers): ModuleList(\n",
            "      (0): Linear(in_features=178, out_features=118, bias=True)\n",
            "      (1): Linear(in_features=118, out_features=59, bias=True)\n",
            "      (2): Linear(in_features=59, out_features=35, bias=True)\n",
            "      (3): Linear(in_features=35, out_features=22, bias=True)\n",
            "      (4): Linear(in_features=22, out_features=17, bias=True)\n",
            "      (5): Linear(in_features=17, out_features=3, bias=True)\n",
            "    )\n",
            "  )\n",
            ") ModuleList(\n",
            "  (0): ARIMA(\n",
            "    (PD): TwoPolynomialOperation(\n",
            "      (first_poly): BiasOnePolynomial()\n",
            "      (second_poly): Polynomial()\n",
            "    )\n",
            "    (Q): BiasOnePolynomial()\n",
            "    (PDS): TwoPolynomialOperation(\n",
            "      (first_poly): BiasOnePolynomial()\n",
            "      (second_poly): Polynomial()\n",
            "    )\n",
            "    (QS): BiasOnePolynomial()\n",
            "  )\n",
            ") ModuleList(\n",
            "  (0): lstm(\n",
            "    (lstm): LSTM(178, 3, batch_first=True)\n",
            "  )\n",
            ")\n",
            "3\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "complete_model_autoencoder(\n",
              "  (extractor): conv_autoencoder(\n",
              "    (encoder): conv_encoder(\n",
              "      (conv_layers): ModuleList(\n",
              "        (0): Conv1d(4, 5, kernel_size=(5,), stride=(1,), padding=same)\n",
              "        (1): Conv1d(5, 6, kernel_size=(5,), stride=(1,), padding=same)\n",
              "        (2): Conv1d(6, 7, kernel_size=(5,), stride=(1,), padding=same)\n",
              "      )\n",
              "      (pooling_layers): ModuleList(\n",
              "        (0-2): 3 x MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      )\n",
              "      (norm_layers): ModuleList(\n",
              "        (0): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (1): BatchNorm1d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): BatchNorm1d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (decoder): conv_decoder(\n",
              "      (conv_layers): ModuleList(\n",
              "        (0): Conv1d(7, 6, kernel_size=(5,), stride=(1,), padding=same)\n",
              "        (1): Conv1d(6, 5, kernel_size=(5,), stride=(1,), padding=same)\n",
              "        (2): Conv1d(5, 4, kernel_size=(5,), stride=(1,), padding=same)\n",
              "      )\n",
              "      (upsample_layers): ModuleList(\n",
              "        (0-2): 3 x Upsample(scale_factor=2.0, mode='linear')\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (ensemble): ensemble_model(\n",
              "    (models): ModuleList(\n",
              "      (0): mlp(\n",
              "        (linear_layers): ModuleList(\n",
              "          (0): Linear(in_features=178, out_features=118, bias=True)\n",
              "          (1): Linear(in_features=118, out_features=59, bias=True)\n",
              "          (2): Linear(in_features=59, out_features=35, bias=True)\n",
              "          (3): Linear(in_features=35, out_features=22, bias=True)\n",
              "          (4): Linear(in_features=22, out_features=17, bias=True)\n",
              "          (5): Linear(in_features=17, out_features=3, bias=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (arima_models): ModuleList(\n",
              "      (0): ARIMA(\n",
              "        (PD): TwoPolynomialOperation(\n",
              "          (first_poly): BiasOnePolynomial()\n",
              "          (second_poly): Polynomial()\n",
              "        )\n",
              "        (Q): BiasOnePolynomial()\n",
              "        (PDS): TwoPolynomialOperation(\n",
              "          (first_poly): BiasOnePolynomial()\n",
              "          (second_poly): Polynomial()\n",
              "        )\n",
              "        (QS): BiasOnePolynomial()\n",
              "      )\n",
              "    )\n",
              "    (rnn_models): ModuleList(\n",
              "      (0): lstm(\n",
              "        (lstm): LSTM(178, 3, batch_first=True)\n",
              "      )\n",
              "    )\n",
              "    (rnn_linear_models): ModuleList(\n",
              "      (0): linear(\n",
              "        (linear_layer): Linear(in_features=3, out_features=3, bias=False)\n",
              "      )\n",
              "    )\n",
              "    (voting_mlp): mlp(\n",
              "      (linear_layers): ModuleList(\n",
              "        (0): Linear(in_features=9, out_features=12, bias=True)\n",
              "        (1): Linear(in_features=12, out_features=3, bias=True)\n",
              "      )\n",
              "    )\n",
              "    (voting_linear): Linear(in_features=9, out_features=3, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Training, Test and Validation Dataloader initialization\n",
        "loaderTrain = DataLoader(datasetTrain, shuffle=True, batch_size=hyper_parameters['batch_size'])\n",
        "loaderVal = DataLoader(datasetVal, shuffle=True, batch_size=hyper_parameters['batch_size'])\n",
        "\n",
        "# Model Initialization (True if you want to use the Ensemble model, False in you want to use a single LSTM model)\n",
        "if hyper_parameters['ensemble'] == False:\n",
        "    model = lstm_only(hidden_dim=hyper_parameters['hidden_dim'],\n",
        "                      timesteps=hyper_parameters['timesteps'] ,\n",
        "                      input_dim=4, \n",
        "                      output_dim=3).to(device)\n",
        "    \n",
        "elif hyper_parameters['ensemble'] == True:\n",
        "    if hyper_parameters['extractor_type'] == 'conv':\n",
        "        model = complete_model_autoencoder(ensemble_model, \n",
        "                                           device, \n",
        "                                           autoencoder_dim=conv_autoencoder_dict['in_kern_out'], \n",
        "                                           pooling_kernel_size=conv_autoencoder_dict['pooling_kernel_size'], \n",
        "                                           padding=conv_autoencoder_dict['padding'], \n",
        "                                           pooling=conv_autoencoder_dict['pooling'], \n",
        "                                           scale_factor = conv_autoencoder_dict['scale_factor'], \n",
        "                                           upsample_mode=conv_autoencoder_dict['upsample_mode'], \n",
        "                                           dropout=conv_autoencoder_dict['dropout'],\n",
        "                                           mode=hyper_parameters['mode'],\n",
        "                                           heterogeneous=hyper_parameters['heterogeneous'],\n",
        "                                           timesteps=hyper_parameters['timesteps']\n",
        "                                           ).to(device)\n",
        "    \n",
        "    elif hyper_parameters['extractor_type'] == 'lstm':\n",
        "        model = complete_model_autoencoder(\n",
        "                                    model_dict=ensemble_model, \n",
        "                                    device=device, \n",
        "                                    timesteps=hyper_parameters['timesteps'],\n",
        "                                    autoencoder_dim=lstm_autoencoder_dict['in_hidd'], \n",
        "                                    dropout=lstm_autoencoder_dict['dropout'],\n",
        "                                    extractor_type=hyper_parameters['extractor_type'],\n",
        "                                    heterogeneous=hyper_parameters['heterogeneous']\n",
        "                                    ).to(device)\n",
        "    else:\n",
        "        model = complete_model(\n",
        "                               hidden_dim=hyper_parameters['hidden_dim'], \n",
        "                               input_dim=4, \n",
        "                               model_dict=ensemble_model, \n",
        "                               device=device, \n",
        "                               mode=hyper_parameters['mode'], \n",
        "                               extractor_type=hyper_parameters['extractor_type']\n",
        "                               ).to(device)\n",
        "\n",
        "# Definition of the optimizer and loss function\n",
        "\n",
        "if hyper_parameters['ensemble'] == False:\n",
        "    optimizer = optim.Adam(model.parameters(), lr=hyper_parameters['lr'])\n",
        "elif hyper_parameters['ensemble'] == True:\n",
        "\n",
        "\n",
        "    models, arima, rnn_ = model.get_models()\n",
        "    list_models = models + arima + rnn_ \n",
        "    optimizer = [optim.Adam(model.extractor.parameters(), lr=hyper_parameters['lr']*hyper_parameters['lr_multipliers_extractor'])]\n",
        "    for sub_model in list_models: \n",
        "        for model_type, multiplier in hyper_parameters['lr_multipliers_ensemble'].items():\n",
        "            if isinstance(sub_model, model_type):\n",
        "                optimizer.append(optim.Adam(model.parameters(), lr=hyper_parameters['lr']*multiplier, weight_decay=hyper_parameters['weight_decay']))\n",
        "                break\n",
        "    print(len(optimizer))\n",
        "\n",
        "hyper_parameters['lr_multipliers_ensemble'] = {\n",
        "        'mlp': hyper_parameters['lr_multipliers_ensemble'][mlp],\n",
        "        'linear': hyper_parameters['lr_multipliers_ensemble'][linear],\n",
        "        'rnn': hyper_parameters['lr_multipliers_ensemble'][rnn],\n",
        "        'lstm': hyper_parameters['lr_multipliers_ensemble'][lstm],\n",
        "        'cnn': hyper_parameters['lr_multipliers_ensemble'][cnn]\n",
        "    }\n",
        "\n",
        "\n",
        "loss_fn = nn.MSELoss()\n",
        "if hyper_parameters['ensemble'] == False:\n",
        "    scheduler = ExponentialLR(optimizer, gamma=0.85)\n",
        "elif hyper_parameters['ensemble'] == True:\n",
        "    scheduler = [ExponentialLR(opti, gamma=0.85) for opti in optimizer]\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCH 1/100:\n",
            "Model saved to results/training_2025-03-03_16-17/model.pt\n",
            "Weights of the Ensemble models: [0.0015385015867650509, 0.9972772002220154, 0.0011842987732961774]\n",
            "train MODEL: LOSS 0.669712388948 MAE X1:0.1101, Y1:0.0429, Z1:0.1167 R2 X1:0.9788, Y1:0.9876, Z1:0.9747 RMSE X1:0.154047, Y1:0.131129, Z1:0.170016\n",
            "train AUTOENCODER: LOSS 0.476499333016 MAE temp1:0.5028, temp2:0.5619, temp3:0.4902, temp4:0.5998 R2 temp1:0.5752, temp2:0.4739, temp3:0.6019, temp4:0.0220 RMSE temp1:0.670267, temp2:0.744525, temp3:0.652961, temp4:0.854213\n",
            "valid MODEL: LOSS 0.098543632489 MAE X1:0.1010, Y1:0.0346, Z1:0.0882 R2 X1:0.9766, Y1:0.9855, Z1:0.9770 RMSE X1:0.128195, Y1:0.043919, Z1:0.112561\n",
            "valid AUTOENCODER: LOSS 0.731638399454 MAE temp1:0.6120, temp2:0.6037, temp3:0.6081, temp4:0.5998 R2 temp1:0.0049, temp2:0.1470, temp3:0.0005, temp4:0.0220 RMSE temp1:0.859843, temp2:0.848865, temp3:0.855902, temp4:0.854213\n",
            "EPOCH 2/100:\n",
            "Model saved to results/training_2025-03-03_16-17/model.pt\n",
            "Weights of the Ensemble models: [0.014704889617860317, 0.9814873933792114, 0.003807661822065711]\n",
            "train MODEL: LOSS 0.426449736580 MAE X1:0.1095, Y1:0.0423, Z1:0.1153 R2 X1:0.9790, Y1:0.9881, Z1:0.9757 RMSE X1:0.153296, Y1:0.128417, Z1:0.166584\n",
            "train AUTOENCODER: LOSS 0.387649365010 MAE temp1:0.4296, temp2:0.5070, temp3:0.4180, temp4:0.5607 R2 temp1:0.6606, temp2:0.5426, temp3:0.6762, temp4:0.0727 RMSE temp1:0.599264, temp2:0.694269, temp3:0.589087, temp4:0.831764\n",
            "valid MODEL: LOSS 0.048668565372 MAE X1:0.1010, Y1:0.0536, Z1:0.0862 R2 X1:0.9766, Y1:0.9650, Z1:0.9778 RMSE X1:0.128175, Y1:0.068254, Z1:0.110552\n",
            "valid AUTOENCODER: LOSS 0.692264793011 MAE temp1:0.5486, temp2:0.5905, temp3:0.5387, temp4:0.5607 R2 temp1:0.0636, temp2:0.1730, temp3:0.0665, temp4:0.0727 RMSE temp1:0.834083, temp2:0.835810, temp3:0.827146, temp4:0.831764\n",
            "EPOCH 3/100:\n",
            "Weights of the Ensemble models: [0.004304531030356884, 0.9932221174240112, 0.002473365282639861]\n",
            "train MODEL: LOSS 0.363583895288 MAE X1:0.1094, Y1:0.0421, Z1:0.1153 R2 X1:0.9795, Y1:0.9881, Z1:0.9758 RMSE X1:0.151586, Y1:0.128117, Z1:0.166054\n",
            "train AUTOENCODER: LOSS 0.194719087753 MAE temp1:0.2698, temp2:0.3830, temp3:0.2605, temp4:0.1601 R2 temp1:0.8415, temp2:0.7253, temp3:0.8546, temp4:0.9364 RMSE temp1:0.404585, temp2:0.535245, temp3:0.393208, temp4:0.197892\n",
            "valid MODEL: LOSS 0.051211593816 MAE X1:0.1010, Y1:0.0328, Z1:0.0877 R2 X1:0.9766, Y1:0.9869, Z1:0.9773 RMSE X1:0.128171, Y1:0.041683, Z1:0.111805\n",
            "valid AUTOENCODER: LOSS 0.062821266743 MAE temp1:0.1136, temp2:0.2800, temp3:0.1206, temp4:0.1601 R2 temp1:0.9542, temp2:0.8388, temp3:0.9545, temp4:0.9364 RMSE temp1:0.149568, temp2:0.364729, temp3:0.154046, temp4:0.197892\n",
            "EPOCH 4/100:\n",
            "Model saved to results/training_2025-03-03_16-17/model.pt\n",
            "Weights of the Ensemble models: [0.025089863687753677, 0.9724932312965393, 0.0024168724194169044]\n",
            "train MODEL: LOSS 0.331802723268 MAE X1:0.1091, Y1:0.0400, Z1:0.1141 R2 X1:0.9796, Y1:0.9892, Z1:0.9769 RMSE X1:0.150987, Y1:0.122083, Z1:0.162222\n",
            "train AUTOENCODER: LOSS 0.059337225833 MAE temp1:0.1233, temp2:0.2625, temp3:0.1269, temp4:0.1433 R2 temp1:0.9687, temp2:0.8858, temp3:0.9704, temp4:0.9374 RMSE temp1:0.159512, temp2:0.340575, temp3:0.162730, temp4:0.195629\n",
            "valid MODEL: LOSS 0.038026086055 MAE X1:0.1010, Y1:0.0335, Z1:0.0861 R2 X1:0.9766, Y1:0.9864, Z1:0.9780 RMSE X1:0.128165, Y1:0.042542, Z1:0.110036\n",
            "valid AUTOENCODER: LOSS 0.053206207947 MAE temp1:0.0914, temp2:0.2545, temp3:0.1063, temp4:0.1433 R2 temp1:0.9640, temp2:0.8705, temp3:0.9591, temp4:0.9374 RMSE temp1:0.121199, temp2:0.326818, temp3:0.139527, temp4:0.195629\n",
            "EPOCH 5/100:\n",
            "Model saved to results/training_2025-03-03_16-17/model.pt\n",
            "Weights of the Ensemble models: [0.07100970298051834, 0.9268551468849182, 0.0021351489704102278]\n",
            "train MODEL: LOSS 0.306484514427 MAE X1:0.1094, Y1:0.0405, Z1:0.1143 R2 X1:0.9791, Y1:0.9883, Z1:0.9764 RMSE X1:0.152849, Y1:0.127445, Z1:0.164180\n",
            "train AUTOENCODER: LOSS 0.051880883534 MAE temp1:0.1121, temp2:0.2482, temp3:0.1191, temp4:0.1443 R2 temp1:0.9767, temp2:0.8989, temp3:0.9744, temp4:0.9381 RMSE temp1:0.143071, temp2:0.324283, temp3:0.151994, temp4:0.194864\n",
            "valid MODEL: LOSS 0.035161780981 MAE X1:0.1008, Y1:0.0343, Z1:0.0874 R2 X1:0.9767, Y1:0.9857, Z1:0.9775 RMSE X1:0.127895, Y1:0.043595, Z1:0.111475\n",
            "valid AUTOENCODER: LOSS 0.052608835153 MAE temp1:0.0924, temp2:0.2544, temp3:0.1045, temp4:0.1443 R2 temp1:0.9645, temp2:0.8709, temp3:0.9606, temp4:0.9381 RMSE temp1:0.121556, temp2:0.326658, temp3:0.135943, temp4:0.194864\n",
            "EPOCH 6/100:\n",
            "Weights of the Ensemble models: [0.13221214711666107, 0.866346538066864, 0.0014413496246561408]\n",
            "train MODEL: LOSS 0.291301334397 MAE X1:0.1093, Y1:0.0402, Z1:0.1144 R2 X1:0.9796, Y1:0.9900, Z1:0.9771 RMSE X1:0.151175, Y1:0.117346, Z1:0.161659\n",
            "train AUTOENCODER: LOSS 0.055414160834 MAE temp1:0.1242, temp2:0.2507, temp3:0.1284, temp4:0.1349 R2 temp1:0.9730, temp2:0.8971, temp3:0.9713, temp4:0.9379 RMSE temp1:0.158819, temp2:0.327368, temp3:0.164691, temp4:0.195438\n",
            "valid MODEL: LOSS 0.036115704606 MAE X1:0.1010, Y1:0.0373, Z1:0.0847 R2 X1:0.9766, Y1:0.9832, Z1:0.9787 RMSE X1:0.128093, Y1:0.047309, Z1:0.108272\n",
            "valid AUTOENCODER: LOSS 0.050576188960 MAE temp1:0.0945, temp2:0.2419, temp3:0.1048, temp4:0.1349 R2 temp1:0.9641, temp2:0.8818, temp3:0.9599, temp4:0.9379 RMSE temp1:0.122959, temp2:0.311717, temp3:0.138355, temp4:0.195438\n",
            "EPOCH 7/100:\n",
            "Model saved to results/training_2025-03-03_16-17/model.pt\n",
            "Weights of the Ensemble models: [0.019779089838266373, 0.978327214717865, 0.001893687411211431]\n",
            "train MODEL: LOSS 0.310229338405 MAE X1:0.1092, Y1:0.0412, Z1:0.1134 R2 X1:0.9795, Y1:0.9891, Z1:0.9774 RMSE X1:0.151391, Y1:0.122717, Z1:0.160470\n",
            "train AUTOENCODER: LOSS 0.051747173131 MAE temp1:0.1139, temp2:0.2440, temp3:0.1181, temp4:0.1593 R2 temp1:0.9765, temp2:0.9018, temp3:0.9750, temp4:0.9278 RMSE temp1:0.146597, temp2:0.319658, temp3:0.151918, temp4:0.215672\n",
            "valid MODEL: LOSS 0.032998341637 MAE X1:0.1010, Y1:0.0332, Z1:0.0858 R2 X1:0.9766, Y1:0.9866, Z1:0.9782 RMSE X1:0.128081, Y1:0.042216, Z1:0.109580\n",
            "valid AUTOENCODER: LOSS 0.054619079742 MAE temp1:0.0947, temp2:0.2500, temp3:0.1197, temp4:0.1593 R2 temp1:0.9632, temp2:0.8782, temp3:0.9533, temp4:0.9278 RMSE temp1:0.126515, temp2:0.316591, temp3:0.158634, temp4:0.215672\n",
            "EPOCH 8/100:\n",
            "Weights of the Ensemble models: [0.0586710050702095, 0.9367431402206421, 0.004585830494761467]\n",
            "train MODEL: LOSS 0.263253665739 MAE X1:0.1095, Y1:0.0407, Z1:0.1144 R2 X1:0.9792, Y1:0.9896, Z1:0.9766 RMSE X1:0.152577, Y1:0.119864, Z1:0.163442\n",
            "train AUTOENCODER: LOSS 0.050142874220 MAE temp1:0.1141, temp2:0.2376, temp3:0.1224, temp4:0.1500 R2 temp1:0.9768, temp2:0.9071, temp3:0.9737, temp4:0.9270 RMSE temp1:0.146280, temp2:0.310761, temp3:0.157824, temp4:0.215904\n",
            "valid MODEL: LOSS 0.033139066269 MAE X1:0.1010, Y1:0.0363, Z1:0.0870 R2 X1:0.9766, Y1:0.9840, Z1:0.9777 RMSE X1:0.128175, Y1:0.046174, Z1:0.110967\n",
            "valid AUTOENCODER: LOSS 0.052417975062 MAE temp1:0.1071, temp2:0.2251, temp3:0.1168, temp4:0.1500 R2 temp1:0.9582, temp2:0.8944, temp3:0.9520, temp4:0.9270 RMSE temp1:0.140739, temp2:0.292980, temp3:0.159381, temp4:0.215904\n",
            "EPOCH 9/100:\n",
            "Model saved to results/training_2025-03-03_16-17/model.pt\n",
            "Weights of the Ensemble models: [0.02943054772913456, 0.9692174196243286, 0.001352023216895759]\n",
            "train MODEL: LOSS 0.252011503574 MAE X1:0.1092, Y1:0.0401, Z1:0.1136 R2 X1:0.9793, Y1:0.9879, Z1:0.9768 RMSE X1:0.152153, Y1:0.129235, Z1:0.162581\n",
            "train AUTOENCODER: LOSS 0.046602609838 MAE temp1:0.1055, temp2:0.2349, temp3:0.1120, temp4:0.1546 R2 temp1:0.9796, temp2:0.9085, temp3:0.9770, temp4:0.9305 RMSE temp1:0.135042, temp2:0.308272, temp3:0.145236, temp4:0.210457\n",
            "valid MODEL: LOSS 0.032356964209 MAE X1:0.1011, Y1:0.0332, Z1:0.0855 R2 X1:0.9765, Y1:0.9867, Z1:0.9784 RMSE X1:0.128252, Y1:0.042124, Z1:0.109202\n",
            "valid AUTOENCODER: LOSS 0.049331076300 MAE temp1:0.0861, temp2:0.2300, temp3:0.1053, temp4:0.1546 R2 temp1:0.9668, temp2:0.8923, temp3:0.9592, temp4:0.9305 RMSE temp1:0.114094, temp2:0.297090, temp3:0.142292, temp4:0.210457\n",
            "EPOCH 10/100:\n",
            "Model saved to results/training_2025-03-03_16-17/model.pt\n",
            "Weights of the Ensemble models: [0.07788799703121185, 0.9202102422714233, 0.001901765470393002]\n",
            "train MODEL: LOSS 0.313579887993 MAE X1:0.1091, Y1:0.0399, Z1:0.1136 R2 X1:0.9797, Y1:0.9900, Z1:0.9775 RMSE X1:0.150782, Y1:0.117886, Z1:0.160116\n",
            "train AUTOENCODER: LOSS 0.047756415642 MAE temp1:0.1074, temp2:0.2362, temp3:0.1159, temp4:0.1429 R2 temp1:0.9789, temp2:0.9076, temp3:0.9762, temp4:0.9319 RMSE temp1:0.138240, temp2:0.309979, temp3:0.148827, temp4:0.207646\n",
            "valid MODEL: LOSS 0.031544117758 MAE X1:0.1010, Y1:0.0329, Z1:0.0853 R2 X1:0.9766, Y1:0.9869, Z1:0.9784 RMSE X1:0.128096, Y1:0.041747, Z1:0.109039\n",
            "valid AUTOENCODER: LOSS 0.048974552550 MAE temp1:0.0977, temp2:0.2204, temp3:0.1090, temp4:0.1429 R2 temp1:0.9632, temp2:0.8981, temp3:0.9572, temp4:0.9319 RMSE temp1:0.127465, temp2:0.288204, temp3:0.147557, temp4:0.207646\n",
            "EPOCH 11/100:\n",
            "Weights of the Ensemble models: [0.027179645374417305, 0.9711324572563171, 0.0016878744354471564]\n",
            "train MODEL: LOSS 0.240733949107 MAE X1:0.1088, Y1:0.0391, Z1:0.1135 R2 X1:0.9797, Y1:0.9888, Z1:0.9771 RMSE X1:0.150838, Y1:0.124440, Z1:0.161596\n",
            "train AUTOENCODER: LOSS 0.047607498003 MAE temp1:0.1086, temp2:0.2372, temp3:0.1156, temp4:0.1390 R2 temp1:0.9788, temp2:0.9067, temp3:0.9765, temp4:0.9347 RMSE temp1:0.139101, temp2:0.311578, temp3:0.148332, temp4:0.203095\n",
            "valid MODEL: LOSS 0.033275249772 MAE X1:0.1009, Y1:0.0338, Z1:0.0852 R2 X1:0.9766, Y1:0.9862, Z1:0.9785 RMSE X1:0.128084, Y1:0.042793, Z1:0.108919\n",
            "valid AUTOENCODER: LOSS 0.048828696975 MAE temp1:0.1068, temp2:0.2188, temp3:0.1162, temp4:0.1390 R2 temp1:0.9613, temp2:0.8981, temp3:0.9567, temp4:0.9347 RMSE temp1:0.136444, temp2:0.288458, temp3:0.150813, temp4:0.203095\n",
            "EPOCH 12/100:\n",
            "Model saved to results/training_2025-03-03_16-17/model.pt\n",
            "Weights of the Ensemble models: [0.19164584577083588, 0.8052716851234436, 0.0030824223067611456]\n",
            "train MODEL: LOSS 0.234495582149 MAE X1:0.1089, Y1:0.0390, Z1:0.1128 R2 X1:0.9804, Y1:0.9906, Z1:0.9780 RMSE X1:0.148195, Y1:0.113926, Z1:0.158400\n",
            "train AUTOENCODER: LOSS 0.046354343814 MAE temp1:0.1043, temp2:0.2347, temp3:0.1116, temp4:0.1531 R2 temp1:0.9800, temp2:0.9085, temp3:0.9777, temp4:0.9370 RMSE temp1:0.133997, temp2:0.308518, temp3:0.143788, temp4:0.201751\n",
            "valid MODEL: LOSS 0.029886313284 MAE X1:0.1015, Y1:0.0327, Z1:0.0853 R2 X1:0.9764, Y1:0.9870, Z1:0.9785 RMSE X1:0.128737, Y1:0.041607, Z1:0.108945\n",
            "valid AUTOENCODER: LOSS 0.049000484152 MAE temp1:0.0912, temp2:0.2376, temp3:0.1025, temp4:0.1531 R2 temp1:0.9688, temp2:0.8828, temp3:0.9632, temp4:0.9370 RMSE temp1:0.119932, temp2:0.311849, temp3:0.138933, temp4:0.201751\n",
            "EPOCH 13/100:\n",
            "Weights of the Ensemble models: [0.09688997268676758, 0.9008742570877075, 0.0022357632406055927]\n",
            "train MODEL: LOSS 0.232630810730 MAE X1:0.1088, Y1:0.0390, Z1:0.1127 R2 X1:0.9799, Y1:0.9898, Z1:0.9778 RMSE X1:0.150085, Y1:0.119054, Z1:0.159206\n",
            "train AUTOENCODER: LOSS 0.047374347826 MAE temp1:0.1083, temp2:0.2393, temp3:0.1126, temp4:0.1418 R2 temp1:0.9786, temp2:0.9056, temp3:0.9773, temp4:0.9352 RMSE temp1:0.140158, temp2:0.313685, temp3:0.145523, temp4:0.202754\n",
            "valid MODEL: LOSS 0.031166085114 MAE X1:0.1013, Y1:0.0333, Z1:0.0851 R2 X1:0.9765, Y1:0.9866, Z1:0.9785 RMSE X1:0.128472, Y1:0.042295, Z1:0.108805\n",
            "valid AUTOENCODER: LOSS 0.048335377700 MAE temp1:0.1077, temp2:0.2197, temp3:0.1137, temp4:0.1418 R2 temp1:0.9618, temp2:0.8979, temp3:0.9582, temp4:0.9352 RMSE temp1:0.136872, temp2:0.289074, temp3:0.147941, temp4:0.202754\n",
            "EPOCH 14/100:\n",
            "Weights of the Ensemble models: [0.10195192694664001, 0.8965432047843933, 0.0015048275236040354]\n",
            "train MODEL: LOSS 0.228975316810 MAE X1:0.1090, Y1:0.0389, Z1:0.1128 R2 X1:0.9800, Y1:0.9903, Z1:0.9778 RMSE X1:0.149578, Y1:0.115756, Z1:0.159032\n",
            "train AUTOENCODER: LOSS 0.046453117784 MAE temp1:0.1060, temp2:0.2362, temp3:0.1122, temp4:0.1331 R2 temp1:0.9796, temp2:0.9076, temp3:0.9778, temp4:0.9394 RMSE temp1:0.136406, temp2:0.310139, temp3:0.144109, temp4:0.195200\n",
            "valid MODEL: LOSS 0.029944568299 MAE X1:0.1012, Y1:0.0336, Z1:0.0847 R2 X1:0.9765, Y1:0.9863, Z1:0.9787 RMSE X1:0.128348, Y1:0.042735, Z1:0.108270\n",
            "valid AUTOENCODER: LOSS 0.046205611183 MAE temp1:0.0850, temp2:0.2279, temp3:0.0999, temp4:0.1331 R2 temp1:0.9691, temp2:0.8941, temp3:0.9634, temp4:0.9394 RMSE temp1:0.111968, temp2:0.295093, temp3:0.134111, temp4:0.195200\n",
            "EPOCH 15/100:\n",
            "Weights of the Ensemble models: [0.17811115086078644, 0.8196700215339661, 0.0022187926806509495]\n",
            "train MODEL: LOSS 0.226466088676 MAE X1:0.1085, Y1:0.0386, Z1:0.1124 R2 X1:0.9801, Y1:0.9905, Z1:0.9780 RMSE X1:0.149235, Y1:0.114572, Z1:0.158449\n",
            "train AUTOENCODER: LOSS 0.046003556119 MAE temp1:0.1072, temp2:0.2349, temp3:0.1127, temp4:0.1361 R2 temp1:0.9795, temp2:0.9083, temp3:0.9778, temp4:0.9350 RMSE temp1:0.137044, temp2:0.309067, temp3:0.144274, temp4:0.203099\n",
            "valid MODEL: LOSS 0.030040738531 MAE X1:0.1012, Y1:0.0335, Z1:0.0850 R2 X1:0.9765, Y1:0.9864, Z1:0.9786 RMSE X1:0.128313, Y1:0.042475, Z1:0.108690\n",
            "valid AUTOENCODER: LOSS 0.047500869116 MAE temp1:0.0945, temp2:0.2211, temp3:0.1074, temp4:0.1361 R2 temp1:0.9652, temp2:0.8986, temp3:0.9592, temp4:0.9350 RMSE temp1:0.124355, temp2:0.287904, temp3:0.145010, temp4:0.203099\n",
            "EPOCH 16/100:\n",
            "Model saved to results/training_2025-03-03_16-17/model.pt\n",
            "Weights of the Ensemble models: [0.3072837293148041, 0.6908374428749084, 0.0018788864836096764]\n",
            "train MODEL: LOSS 0.223446200482 MAE X1:0.1087, Y1:0.0384, Z1:0.1127 R2 X1:0.9799, Y1:0.9903, Z1:0.9779 RMSE X1:0.150173, Y1:0.116101, Z1:0.158971\n",
            "train AUTOENCODER: LOSS 0.046693560217 MAE temp1:0.1069, temp2:0.2356, temp3:0.1118, temp4:0.1417 R2 temp1:0.9790, temp2:0.9081, temp3:0.9774, temp4:0.9378 RMSE temp1:0.139559, temp2:0.309338, temp3:0.146070, temp4:0.199092\n",
            "valid MODEL: LOSS 0.029796900514 MAE X1:0.1013, Y1:0.0331, Z1:0.0851 R2 X1:0.9765, Y1:0.9867, Z1:0.9785 RMSE X1:0.128440, Y1:0.042146, Z1:0.108793\n",
            "valid AUTOENCODER: LOSS 0.046476097921 MAE temp1:0.0817, temp2:0.2320, temp3:0.1006, temp4:0.1417 R2 temp1:0.9707, temp2:0.8920, temp3:0.9636, temp4:0.9378 RMSE temp1:0.107999, temp2:0.298508, temp3:0.135350, temp4:0.199092\n",
            "EPOCH 17/100:\n",
            "Weights of the Ensemble models: [0.10607777535915375, 0.8923274278640747, 0.0015948020154610276]\n",
            "train MODEL: LOSS 0.221449288990 MAE X1:0.1087, Y1:0.0388, Z1:0.1122 R2 X1:0.9804, Y1:0.9899, Z1:0.9781 RMSE X1:0.148358, Y1:0.118006, Z1:0.158220\n",
            "train AUTOENCODER: LOSS 0.044688345925 MAE temp1:0.1032, temp2:0.2324, temp3:0.1090, temp4:0.1333 R2 temp1:0.9804, temp2:0.9100, temp3:0.9787, temp4:0.9387 RMSE temp1:0.133063, temp2:0.305939, temp3:0.140715, temp4:0.197361\n",
            "valid MODEL: LOSS 0.030275711432 MAE X1:0.1011, Y1:0.0331, Z1:0.0852 R2 X1:0.9766, Y1:0.9868, Z1:0.9785 RMSE X1:0.128164, Y1:0.041949, Z1:0.108941\n",
            "valid AUTOENCODER: LOSS 0.045659175143 MAE temp1:0.0850, temp2:0.2254, temp3:0.1015, temp4:0.1333 R2 temp1:0.9697, temp2:0.8966, temp3:0.9632, temp4:0.9387 RMSE temp1:0.111663, temp2:0.291675, temp3:0.136273, temp4:0.197361\n",
            "EPOCH 18/100:\n",
            "Model saved to results/training_2025-03-03_16-17/model.pt\n",
            "Weights of the Ensemble models: [0.08017449080944061, 0.9184940457344055, 0.0013314083917066455]\n",
            "train MODEL: LOSS 0.219522870176 MAE X1:0.1084, Y1:0.0385, Z1:0.1121 R2 X1:0.9807, Y1:0.9913, Z1:0.9785 RMSE X1:0.147027, Y1:0.109896, Z1:0.156699\n",
            "train AUTOENCODER: LOSS 0.044074909281 MAE temp1:0.1019, temp2:0.2315, temp3:0.1076, temp4:0.1379 R2 temp1:0.9810, temp2:0.9110, temp3:0.9791, temp4:0.9363 RMSE temp1:0.131327, temp2:0.304425, temp3:0.139670, temp4:0.201420\n",
            "valid MODEL: LOSS 0.029663226209 MAE X1:0.1013, Y1:0.0330, Z1:0.0852 R2 X1:0.9765, Y1:0.9867, Z1:0.9785 RMSE X1:0.128398, Y1:0.042000, Z1:0.108837\n",
            "valid AUTOENCODER: LOSS 0.046336028295 MAE temp1:0.0878, temp2:0.2223, temp3:0.1029, temp4:0.1379 R2 temp1:0.9682, temp2:0.8982, temp3:0.9616, temp4:0.9363 RMSE temp1:0.115970, temp2:0.288999, temp3:0.139703, temp4:0.201420\n",
            "EPOCH 19/100:\n",
            "Model saved to results/training_2025-03-03_16-17/model.pt\n",
            "Weights of the Ensemble models: [0.17535503208637238, 0.8218643069267273, 0.0027806954458355904]\n",
            "train MODEL: LOSS 0.218180242445 MAE X1:0.1082, Y1:0.0380, Z1:0.1121 R2 X1:0.9811, Y1:0.9920, Z1:0.9785 RMSE X1:0.145640, Y1:0.105133, Z1:0.156716\n",
            "train AUTOENCODER: LOSS 0.044935008631 MAE temp1:0.1039, temp2:0.2315, temp3:0.1109, temp4:0.1371 R2 temp1:0.9804, temp2:0.9109, temp3:0.9782, temp4:0.9368 RMSE temp1:0.133783, temp2:0.304527, temp3:0.143044, temp4:0.200636\n",
            "valid MODEL: LOSS 0.029526623396 MAE X1:0.1015, Y1:0.0335, Z1:0.0853 R2 X1:0.9764, Y1:0.9863, Z1:0.9785 RMSE X1:0.128701, Y1:0.042629, Z1:0.108939\n",
            "valid AUTOENCODER: LOSS 0.045739760909 MAE temp1:0.0864, temp2:0.2216, temp3:0.1005, temp4:0.1371 R2 temp1:0.9690, temp2:0.8991, temp3:0.9627, temp4:0.9368 RMSE temp1:0.113699, temp2:0.287803, temp3:0.137021, temp4:0.200636\n",
            "EPOCH 20/100:\n",
            "Weights of the Ensemble models: [0.16088226437568665, 0.8369501233100891, 0.0021675825119018555]\n",
            "train MODEL: LOSS 0.217411930493 MAE X1:0.1085, Y1:0.0383, Z1:0.1123 R2 X1:0.9805, Y1:0.9909, Z1:0.9782 RMSE X1:0.147826, Y1:0.111972, Z1:0.157853\n",
            "train AUTOENCODER: LOSS 0.046831281495 MAE temp1:0.1076, temp2:0.2343, temp3:0.1132, temp4:0.1433 R2 temp1:0.9790, temp2:0.9091, temp3:0.9773, temp4:0.9356 RMSE temp1:0.139687, temp2:0.307755, temp3:0.146867, temp4:0.203069\n",
            "valid MODEL: LOSS 0.029922836174 MAE X1:0.1014, Y1:0.0327, Z1:0.0850 R2 X1:0.9765, Y1:0.9870, Z1:0.9786 RMSE X1:0.128474, Y1:0.041624, Z1:0.108724\n",
            "valid AUTOENCODER: LOSS 0.046171752020 MAE temp1:0.0837, temp2:0.2241, temp3:0.1006, temp4:0.1433 R2 temp1:0.9696, temp2:0.8976, temp3:0.9626, temp4:0.9356 RMSE temp1:0.111341, temp2:0.290096, temp3:0.137531, temp4:0.203069\n",
            "EPOCH 21/100:\n",
            "Weights of the Ensemble models: [0.2368243932723999, 0.7605603337287903, 0.002615240402519703]\n",
            "train MODEL: LOSS 0.216005921845 MAE X1:0.1080, Y1:0.0377, Z1:0.1119 R2 X1:0.9811, Y1:0.9913, Z1:0.9786 RMSE X1:0.145681, Y1:0.109739, Z1:0.156346\n",
            "train AUTOENCODER: LOSS 0.044004154722 MAE temp1:0.0998, temp2:0.2295, temp3:0.1066, temp4:0.1364 R2 temp1:0.9814, temp2:0.9119, temp3:0.9793, temp4:0.9397 RMSE temp1:0.129437, temp2:0.302746, temp3:0.139020, temp4:0.196312\n",
            "valid MODEL: LOSS 0.029680625536 MAE X1:0.1012, Y1:0.0333, Z1:0.0851 R2 X1:0.9765, Y1:0.9866, Z1:0.9786 RMSE X1:0.128305, Y1:0.042291, Z1:0.108710\n",
            "valid AUTOENCODER: LOSS 0.045255162825 MAE temp1:0.0819, temp2:0.2276, temp3:0.1003, temp4:0.1364 R2 temp1:0.9715, temp2:0.8947, temp3:0.9646, temp4:0.9397 RMSE temp1:0.107705, temp2:0.294855, temp3:0.134281, temp4:0.196312\n",
            "EPOCH 22/100:\n",
            "Model saved to results/training_2025-03-03_16-17/model.pt\n",
            "Weights of the Ensemble models: [0.2653103768825531, 0.7320593595504761, 0.002630272414535284]\n",
            "train MODEL: LOSS 0.215186333795 MAE X1:0.1079, Y1:0.0378, Z1:0.1116 R2 X1:0.9815, Y1:0.9928, Z1:0.9788 RMSE X1:0.144050, Y1:0.100132, Z1:0.155616\n",
            "train AUTOENCODER: LOSS 0.043880141250 MAE temp1:0.1015, temp2:0.2299, temp3:0.1086, temp4:0.1313 R2 temp1:0.9813, temp2:0.9117, temp3:0.9792, temp4:0.9384 RMSE temp1:0.130083, temp2:0.303134, temp3:0.139402, temp4:0.197973\n",
            "valid MODEL: LOSS 0.029402305300 MAE X1:0.1014, Y1:0.0330, Z1:0.0851 R2 X1:0.9764, Y1:0.9867, Z1:0.9785 RMSE X1:0.128584, Y1:0.042001, Z1:0.108769\n",
            "valid AUTOENCODER: LOSS 0.045131358246 MAE temp1:0.0931, temp2:0.2166, temp3:0.1042, temp4:0.1313 R2 temp1:0.9677, temp2:0.9018, temp3:0.9624, temp4:0.9384 RMSE temp1:0.120128, temp2:0.283744, temp3:0.138811, temp4:0.197973\n",
            "EPOCH 23/100:\n",
            "Weights of the Ensemble models: [0.10598714649677277, 0.8929486870765686, 0.0010641678236424923]\n",
            "train MODEL: LOSS 0.214604132659 MAE X1:0.1080, Y1:0.0376, Z1:0.1117 R2 X1:0.9810, Y1:0.9914, Z1:0.9788 RMSE X1:0.145999, Y1:0.109015, Z1:0.155691\n",
            "train AUTOENCODER: LOSS 0.045457989819 MAE temp1:0.1060, temp2:0.2331, temp3:0.1117, temp4:0.1360 R2 temp1:0.9799, temp2:0.9103, temp3:0.9780, temp4:0.9394 RMSE temp1:0.136458, temp2:0.305734, temp3:0.144504, temp4:0.196691\n",
            "valid MODEL: LOSS 0.029608743838 MAE X1:0.1012, Y1:0.0332, Z1:0.0849 R2 X1:0.9765, Y1:0.9866, Z1:0.9786 RMSE X1:0.128316, Y1:0.042286, Z1:0.108522\n",
            "valid AUTOENCODER: LOSS 0.045104753942 MAE temp1:0.0830, temp2:0.2245, temp3:0.1006, temp4:0.1360 R2 temp1:0.9710, temp2:0.8967, temp3:0.9643, temp4:0.9394 RMSE temp1:0.109234, temp2:0.291846, temp3:0.134569, temp4:0.196691\n",
            "EPOCH 24/100:\n",
            "Weights of the Ensemble models: [0.12320031225681305, 0.8751745820045471, 0.0016250743065029383]\n",
            "train MODEL: LOSS 0.213959835920 MAE X1:0.1081, Y1:0.0377, Z1:0.1118 R2 X1:0.9812, Y1:0.9918, Z1:0.9787 RMSE X1:0.145272, Y1:0.106421, Z1:0.155880\n",
            "train AUTOENCODER: LOSS 0.045356388534 MAE temp1:0.1042, temp2:0.2320, temp3:0.1095, temp4:0.1427 R2 temp1:0.9805, temp2:0.9105, temp3:0.9788, temp4:0.9386 RMSE temp1:0.133662, temp2:0.305284, temp3:0.140974, temp4:0.198611\n",
            "valid MODEL: LOSS 0.029714208240 MAE X1:0.1012, Y1:0.0334, Z1:0.0849 R2 X1:0.9765, Y1:0.9865, Z1:0.9786 RMSE X1:0.128344, Y1:0.042435, Z1:0.108520\n",
            "valid AUTOENCODER: LOSS 0.045118734527 MAE temp1:0.0831, temp2:0.2238, temp3:0.1002, temp4:0.1427 R2 temp1:0.9712, temp2:0.8964, temp3:0.9646, temp4:0.9386 RMSE temp1:0.109306, temp2:0.292324, temp3:0.134242, temp4:0.198611\n",
            "EPOCH 25/100:\n",
            "Weights of the Ensemble models: [0.13838060200214386, 0.8603742718696594, 0.001245148596353829]\n",
            "train MODEL: LOSS 0.213374811976 MAE X1:0.1079, Y1:0.0378, Z1:0.1117 R2 X1:0.9809, Y1:0.9909, Z1:0.9787 RMSE X1:0.146202, Y1:0.112332, Z1:0.156076\n",
            "train AUTOENCODER: LOSS 0.044326649258 MAE temp1:0.1031, temp2:0.2309, temp3:0.1102, temp4:0.1309 R2 temp1:0.9807, temp2:0.9112, temp3:0.9787, temp4:0.9387 RMSE temp1:0.132731, temp2:0.304034, temp3:0.141408, temp4:0.197609\n",
            "valid MODEL: LOSS 0.029760501204 MAE X1:0.1013, Y1:0.0330, Z1:0.0850 R2 X1:0.9765, Y1:0.9868, Z1:0.9786 RMSE X1:0.128451, Y1:0.041956, Z1:0.108602\n",
            "valid AUTOENCODER: LOSS 0.045068909486 MAE temp1:0.0930, temp2:0.2165, temp3:0.1051, temp4:0.1309 R2 temp1:0.9679, temp2:0.9020, temp3:0.9624, temp4:0.9387 RMSE temp1:0.119928, temp2:0.283566, temp3:0.139201, temp4:0.197609\n",
            "EPOCH 26/100:\n",
            "Weights of the Ensemble models: [0.32811856269836426, 0.6690739989280701, 0.0028074742294847965]\n",
            "train MODEL: LOSS 0.212946336807 MAE X1:0.1081, Y1:0.0378, Z1:0.1118 R2 X1:0.9804, Y1:0.9895, Z1:0.9783 RMSE X1:0.148161, Y1:0.120779, Z1:0.157412\n",
            "train AUTOENCODER: LOSS 0.045340927738 MAE temp1:0.1019, temp2:0.2307, temp3:0.1087, temp4:0.1306 R2 temp1:0.9809, temp2:0.9114, temp3:0.9789, temp4:0.9394 RMSE temp1:0.132181, temp2:0.303768, temp3:0.140906, temp4:0.196614\n",
            "valid MODEL: LOSS 0.029627288692 MAE X1:0.1014, Y1:0.0330, Z1:0.0851 R2 X1:0.9764, Y1:0.9868, Z1:0.9786 RMSE X1:0.128535, Y1:0.041950, Z1:0.108690\n",
            "valid AUTOENCODER: LOSS 0.045053133884 MAE temp1:0.0996, temp2:0.2140, temp3:0.1100, temp4:0.1306 R2 temp1:0.9664, temp2:0.9028, temp3:0.9617, temp4:0.9394 RMSE temp1:0.126348, temp2:0.282466, temp3:0.142016, temp4:0.196614\n",
            "EPOCH 27/100:\n",
            "Model saved to results/training_2025-03-03_16-17/model.pt\n",
            "Weights of the Ensemble models: [0.16859354078769684, 0.830267608165741, 0.0011388476705178618]\n",
            "train MODEL: LOSS 0.212565537933 MAE X1:0.1077, Y1:0.0375, Z1:0.1115 R2 X1:0.9816, Y1:0.9927, Z1:0.9790 RMSE X1:0.143688, Y1:0.100204, Z1:0.154870\n",
            "train AUTOENCODER: LOSS 0.045539658637 MAE temp1:0.1056, temp2:0.2319, temp3:0.1129, temp4:0.1350 R2 temp1:0.9803, temp2:0.9110, temp3:0.9781, temp4:0.9396 RMSE temp1:0.134998, temp2:0.304443, temp3:0.144214, temp4:0.196320\n",
            "valid MODEL: LOSS 0.029358871711 MAE X1:0.1016, Y1:0.0330, Z1:0.0850 R2 X1:0.9764, Y1:0.9867, Z1:0.9786 RMSE X1:0.128737, Y1:0.042085, Z1:0.108593\n",
            "valid AUTOENCODER: LOSS 0.044629871845 MAE temp1:0.0860, temp2:0.2202, temp3:0.1014, temp4:0.1350 R2 temp1:0.9703, temp2:0.8991, temp3:0.9642, temp4:0.9396 RMSE temp1:0.112337, temp2:0.288179, temp3:0.134950, temp4:0.196320\n",
            "EPOCH 28/100:\n",
            "Weights of the Ensemble models: [0.2939247786998749, 0.7035359144210815, 0.0025392856914550066]\n",
            "train MODEL: LOSS 0.212170681195 MAE X1:0.1076, Y1:0.0374, Z1:0.1112 R2 X1:0.9815, Y1:0.9920, Z1:0.9790 RMSE X1:0.144061, Y1:0.105327, Z1:0.154680\n",
            "train AUTOENCODER: LOSS 0.044809302856 MAE temp1:0.1039, temp2:0.2314, temp3:0.1095, temp4:0.1372 R2 temp1:0.9805, temp2:0.9108, temp3:0.9788, temp4:0.9389 RMSE temp1:0.133639, temp2:0.304816, temp3:0.141330, temp4:0.197614\n",
            "valid MODEL: LOSS 0.029362453076 MAE X1:0.1013, Y1:0.0329, Z1:0.0850 R2 X1:0.9765, Y1:0.9868, Z1:0.9786 RMSE X1:0.128397, Y1:0.041941, Z1:0.108686\n",
            "valid AUTOENCODER: LOSS 0.044778942919 MAE temp1:0.0830, temp2:0.2229, temp3:0.0983, temp4:0.1372 R2 temp1:0.9709, temp2:0.8981, temp3:0.9646, temp4:0.9389 RMSE temp1:0.109322, temp2:0.289592, temp3:0.133240, temp4:0.197614\n",
            "EPOCH 29/100:\n",
            "Weights of the Ensemble models: [0.16663330793380737, 0.8322064876556396, 0.0011602039448916912]\n",
            "train MODEL: LOSS 0.212002919416 MAE X1:0.1076, Y1:0.0370, Z1:0.1115 R2 X1:0.9816, Y1:0.9927, Z1:0.9791 RMSE X1:0.143647, Y1:0.100350, Z1:0.154567\n",
            "train AUTOENCODER: LOSS 0.043866734832 MAE temp1:0.1025, temp2:0.2304, temp3:0.1084, temp4:0.1309 R2 temp1:0.9812, temp2:0.9115, temp3:0.9793, temp4:0.9403 RMSE temp1:0.130896, temp2:0.303582, temp3:0.139222, temp4:0.195062\n",
            "valid MODEL: LOSS 0.029530399336 MAE X1:0.1013, Y1:0.0330, Z1:0.0850 R2 X1:0.9765, Y1:0.9867, Z1:0.9786 RMSE X1:0.128405, Y1:0.041995, Z1:0.108643\n",
            "valid AUTOENCODER: LOSS 0.044491956297 MAE temp1:0.0893, temp2:0.2188, temp3:0.1030, temp4:0.1309 R2 temp1:0.9696, temp2:0.9002, temp3:0.9639, temp4:0.9403 RMSE temp1:0.115502, temp2:0.286511, temp3:0.135996, temp4:0.195062\n",
            "EPOCH 30/100:\n",
            "Model saved to results/training_2025-03-03_16-17/model.pt\n",
            "Weights of the Ensemble models: [0.17886967957019806, 0.8188410997390747, 0.002289205091074109]\n",
            "train MODEL: LOSS 0.211774176107 MAE X1:0.1074, Y1:0.0374, Z1:0.1112 R2 X1:0.9816, Y1:0.9917, Z1:0.9790 RMSE X1:0.143544, Y1:0.107197, Z1:0.154847\n",
            "train AUTOENCODER: LOSS 0.044349676238 MAE temp1:0.1000, temp2:0.2299, temp3:0.1067, temp4:0.1491 R2 temp1:0.9815, temp2:0.9118, temp3:0.9795, temp4:0.9361 RMSE temp1:0.129388, temp2:0.303016, temp3:0.138339, temp4:0.203116\n",
            "valid MODEL: LOSS 0.029313529054 MAE X1:0.1012, Y1:0.0331, Z1:0.0849 R2 X1:0.9765, Y1:0.9866, Z1:0.9786 RMSE X1:0.128329, Y1:0.042189, Z1:0.108506\n",
            "valid AUTOENCODER: LOSS 0.046056641839 MAE temp1:0.0814, temp2:0.2281, temp3:0.1004, temp4:0.1491 R2 temp1:0.9711, temp2:0.8951, temp3:0.9638, temp4:0.9361 RMSE temp1:0.107927, temp2:0.294023, temp3:0.135561, temp4:0.203116\n",
            "EPOCH 31/100:\n",
            "Model saved to results/training_2025-03-03_16-17/model.pt\n",
            "Weights of the Ensemble models: [0.2828427851200104, 0.715951681137085, 0.0012055758852511644]\n",
            "train MODEL: LOSS 0.211601855293 MAE X1:0.1076, Y1:0.0372, Z1:0.1113 R2 X1:0.9818, Y1:0.9926, Z1:0.9792 RMSE X1:0.142790, Y1:0.100986, Z1:0.154196\n",
            "train AUTOENCODER: LOSS 0.041972116717 MAE temp1:0.0952, temp2:0.2278, temp3:0.1011, temp4:0.1391 R2 temp1:0.9830, temp2:0.9130, temp3:0.9811, temp4:0.9381 RMSE temp1:0.122574, temp2:0.300828, temp3:0.131428, temp4:0.199032\n",
            "valid MODEL: LOSS 0.029270457104 MAE X1:0.1013, Y1:0.0330, Z1:0.0850 R2 X1:0.9764, Y1:0.9867, Z1:0.9786 RMSE X1:0.128541, Y1:0.042075, Z1:0.108604\n",
            "valid AUTOENCODER: LOSS 0.045182659506 MAE temp1:0.0824, temp2:0.2242, temp3:0.0988, temp4:0.1391 R2 temp1:0.9708, temp2:0.8976, temp3:0.9642, temp4:0.9381 RMSE temp1:0.109220, temp2:0.290388, temp3:0.134364, temp4:0.199032\n",
            "EPOCH 32/100:\n",
            "Weights of the Ensemble models: [0.16050246357917786, 0.8374975919723511, 0.001999972853809595]\n",
            "train MODEL: LOSS 0.211328359892 MAE X1:0.1075, Y1:0.0370, Z1:0.1114 R2 X1:0.9818, Y1:0.9927, Z1:0.9791 RMSE X1:0.142847, Y1:0.100183, Z1:0.154577\n",
            "train AUTOENCODER: LOSS 0.045398548366 MAE temp1:0.1055, temp2:0.2316, temp3:0.1114, temp4:0.1301 R2 temp1:0.9802, temp2:0.9105, temp3:0.9782, temp4:0.9388 RMSE temp1:0.135193, temp2:0.305328, temp3:0.143540, temp4:0.197538\n",
            "valid MODEL: LOSS 0.029373689340 MAE X1:0.1014, Y1:0.0330, Z1:0.0850 R2 X1:0.9764, Y1:0.9867, Z1:0.9786 RMSE X1:0.128638, Y1:0.042100, Z1:0.108569\n",
            "valid AUTOENCODER: LOSS 0.044835570483 MAE temp1:0.0979, temp2:0.2133, temp3:0.1063, temp4:0.1301 R2 temp1:0.9667, temp2:0.9037, temp3:0.9621, temp4:0.9388 RMSE temp1:0.124876, temp2:0.280935, temp3:0.140254, temp4:0.197538\n",
            "EPOCH 33/100:\n",
            "Model saved to results/training_2025-03-03_16-17/model.pt\n",
            "Weights of the Ensemble models: [0.18947911262512207, 0.8083312511444092, 0.0021896001417189837]\n",
            "train MODEL: LOSS 0.211053102067 MAE X1:0.1076, Y1:0.0370, Z1:0.1112 R2 X1:0.9815, Y1:0.9926, Z1:0.9790 RMSE X1:0.143828, Y1:0.101519, Z1:0.154760\n",
            "train AUTOENCODER: LOSS 0.044420315433 MAE temp1:0.1026, temp2:0.2308, temp3:0.1094, temp4:0.1385 R2 temp1:0.9809, temp2:0.9113, temp3:0.9788, temp4:0.9371 RMSE temp1:0.132267, temp2:0.303960, temp3:0.141484, temp4:0.200574\n",
            "valid MODEL: LOSS 0.029229657510 MAE X1:0.1013, Y1:0.0331, Z1:0.0849 R2 X1:0.9765, Y1:0.9867, Z1:0.9786 RMSE X1:0.128421, Y1:0.042115, Z1:0.108605\n",
            "valid AUTOENCODER: LOSS 0.045160675565 MAE temp1:0.0845, temp2:0.2206, temp3:0.0986, temp4:0.1385 R2 temp1:0.9698, temp2:0.8999, temp3:0.9636, temp4:0.9371 RMSE temp1:0.112033, temp2:0.286645, temp3:0.135403, temp4:0.200574\n",
            "EPOCH 34/100:\n",
            "Weights of the Ensemble models: [0.1587105244398117, 0.8399598002433777, 0.0013296469114720821]\n",
            "train MODEL: LOSS 0.210906756020 MAE X1:0.1076, Y1:0.0371, Z1:0.1112 R2 X1:0.9814, Y1:0.9928, Z1:0.9790 RMSE X1:0.144252, Y1:0.100126, Z1:0.154821\n",
            "train AUTOENCODER: LOSS 0.043713654962 MAE temp1:0.1002, temp2:0.2296, temp3:0.1068, temp4:0.1306 R2 temp1:0.9816, temp2:0.9120, temp3:0.9797, temp4:0.9384 RMSE temp1:0.129137, temp2:0.302633, temp3:0.137730, temp4:0.198131\n",
            "valid MODEL: LOSS 0.029400712810 MAE X1:0.1013, Y1:0.0331, Z1:0.0849 R2 X1:0.9765, Y1:0.9866, Z1:0.9786 RMSE X1:0.128483, Y1:0.042250, Z1:0.108531\n",
            "valid AUTOENCODER: LOSS 0.044711157966 MAE temp1:0.0938, temp2:0.2143, temp3:0.1028, temp4:0.1306 R2 temp1:0.9677, temp2:0.9034, temp3:0.9627, temp4:0.9384 RMSE temp1:0.120827, temp2:0.281320, temp3:0.138166, temp4:0.198131\n",
            "EPOCH 35/100:\n",
            "Weights of the Ensemble models: [0.1426907628774643, 0.8564892411231995, 0.0008199958247132599]\n",
            "train MODEL: LOSS 0.210771440949 MAE X1:0.1077, Y1:0.0370, Z1:0.1112 R2 X1:0.9817, Y1:0.9930, Z1:0.9791 RMSE X1:0.143353, Y1:0.098700, Z1:0.154352\n",
            "train AUTOENCODER: LOSS 0.043662790209 MAE temp1:0.0997, temp2:0.2299, temp3:0.1047, temp4:0.1298 R2 temp1:0.9817, temp2:0.9119, temp3:0.9800, temp4:0.9401 RMSE temp1:0.128680, temp2:0.302956, temp3:0.136222, temp4:0.195467\n",
            "valid MODEL: LOSS 0.029462976596 MAE X1:0.1014, Y1:0.0330, Z1:0.0851 R2 X1:0.9765, Y1:0.9867, Z1:0.9786 RMSE X1:0.128485, Y1:0.042022, Z1:0.108661\n",
            "valid AUTOENCODER: LOSS 0.044639129478 MAE temp1:0.0955, temp2:0.2153, temp3:0.1066, temp4:0.1298 R2 temp1:0.9679, temp2:0.9022, temp3:0.9629, temp4:0.9401 RMSE temp1:0.121859, temp2:0.283411, temp3:0.138957, temp4:0.195467\n",
            "EPOCH 36/100:\n",
            "Weights of the Ensemble models: [0.29031485319137573, 0.7071405649185181, 0.0025445492938160896]\n",
            "train MODEL: LOSS 0.210720949987 MAE X1:0.1077, Y1:0.0369, Z1:0.1114 R2 X1:0.9813, Y1:0.9928, Z1:0.9790 RMSE X1:0.144568, Y1:0.099698, Z1:0.154967\n",
            "train AUTOENCODER: LOSS 0.044467701426 MAE temp1:0.1038, temp2:0.2311, temp3:0.1099, temp4:0.1354 R2 temp1:0.9806, temp2:0.9110, temp3:0.9787, temp4:0.9409 RMSE temp1:0.133721, temp2:0.304512, temp3:0.141904, temp4:0.194455\n",
            "valid MODEL: LOSS 0.029384110624 MAE X1:0.1013, Y1:0.0330, Z1:0.0849 R2 X1:0.9765, Y1:0.9867, Z1:0.9786 RMSE X1:0.128458, Y1:0.042117, Z1:0.108577\n",
            "valid AUTOENCODER: LOSS 0.044633618771 MAE temp1:0.0817, temp2:0.2261, temp3:0.0991, temp4:0.1354 R2 temp1:0.9720, temp2:0.8955, temp3:0.9655, temp4:0.9409 RMSE temp1:0.107391, temp2:0.293779, temp3:0.132357, temp4:0.194455\n",
            "EPOCH 37/100:\n",
            "Weights of the Ensemble models: [0.28932681679725647, 0.7076292634010315, 0.003043971722945571]\n",
            "train MODEL: LOSS 0.210679468158 MAE X1:0.1074, Y1:0.0367, Z1:0.1112 R2 X1:0.9819, Y1:0.9933, Z1:0.9793 RMSE X1:0.142238, Y1:0.096119, Z1:0.153791\n",
            "train AUTOENCODER: LOSS 0.042350524976 MAE temp1:0.0968, temp2:0.2280, temp3:0.1038, temp4:0.1299 R2 temp1:0.9826, temp2:0.9128, temp3:0.9806, temp4:0.9405 RMSE temp1:0.124725, temp2:0.301257, temp3:0.134028, temp4:0.194835\n",
            "valid MODEL: LOSS 0.029407401498 MAE X1:0.1013, Y1:0.0331, Z1:0.0850 R2 X1:0.9765, Y1:0.9867, Z1:0.9786 RMSE X1:0.128465, Y1:0.042096, Z1:0.108628\n",
            "valid AUTOENCODER: LOSS 0.044342684058 MAE temp1:0.0895, temp2:0.2183, temp3:0.1034, temp4:0.1299 R2 temp1:0.9696, temp2:0.9007, temp3:0.9639, temp4:0.9405 RMSE temp1:0.115635, temp2:0.285791, temp3:0.136226, temp4:0.194835\n",
            "EPOCH 38/100:\n",
            "Weights of the Ensemble models: [0.280513733625412, 0.7183322906494141, 0.0011539894621819258]\n",
            "train MODEL: LOSS 0.210753390656 MAE X1:0.1076, Y1:0.0369, Z1:0.1115 R2 X1:0.9816, Y1:0.9924, Z1:0.9789 RMSE X1:0.143697, Y1:0.102537, Z1:0.155169\n",
            "train AUTOENCODER: LOSS 0.043629915604 MAE temp1:0.1024, temp2:0.2297, temp3:0.1086, temp4:0.1307 R2 temp1:0.9812, temp2:0.9120, temp3:0.9793, temp4:0.9378 RMSE temp1:0.131089, temp2:0.302748, temp3:0.139192, temp4:0.199209\n",
            "valid MODEL: LOSS 0.029296971141 MAE X1:0.1014, Y1:0.0330, Z1:0.0850 R2 X1:0.9764, Y1:0.9867, Z1:0.9786 RMSE X1:0.128527, Y1:0.042054, Z1:0.108608\n",
            "valid AUTOENCODER: LOSS 0.044898156077 MAE temp1:0.0950, temp2:0.2136, temp3:0.1031, temp4:0.1307 R2 temp1:0.9671, temp2:0.9040, temp3:0.9622, temp4:0.9378 RMSE temp1:0.122385, temp2:0.280320, temp3:0.139246, temp4:0.199209\n",
            "EPOCH 39/100:\n",
            "Weights of the Ensemble models: [0.4524332880973816, 0.5464386343955994, 0.001128070056438446]\n",
            "train MODEL: LOSS 0.210738756664 MAE X1:0.1074, Y1:0.0369, Z1:0.1112 R2 X1:0.9817, Y1:0.9930, Z1:0.9790 RMSE X1:0.143199, Y1:0.098285, Z1:0.154809\n",
            "train AUTOENCODER: LOSS 0.045249914510 MAE temp1:0.1072, temp2:0.2324, temp3:0.1138, temp4:0.1346 R2 temp1:0.9796, temp2:0.9105, temp3:0.9779, temp4:0.9406 RMSE temp1:0.137733, temp2:0.305373, temp3:0.145168, temp4:0.194862\n",
            "valid MODEL: LOSS 0.029313895780 MAE X1:0.1013, Y1:0.0331, Z1:0.0849 R2 X1:0.9765, Y1:0.9867, Z1:0.9786 RMSE X1:0.128365, Y1:0.042072, Z1:0.108620\n",
            "valid AUTOENCODER: LOSS 0.044361691349 MAE temp1:0.0850, temp2:0.2217, temp3:0.1002, temp4:0.1346 R2 temp1:0.9711, temp2:0.8981, temp3:0.9651, temp4:0.9406 RMSE temp1:0.110814, temp2:0.289829, temp3:0.133185, temp4:0.194862\n",
            "EPOCH 40/100:\n",
            "Weights of the Ensemble models: [0.3984231948852539, 0.5998966693878174, 0.0016801322344690561]\n",
            "train MODEL: LOSS 0.210553936540 MAE X1:0.1074, Y1:0.0369, Z1:0.1113 R2 X1:0.9819, Y1:0.9931, Z1:0.9791 RMSE X1:0.142578, Y1:0.097614, Z1:0.154345\n",
            "train AUTOENCODER: LOSS 0.043017243125 MAE temp1:0.0990, temp2:0.2296, temp3:0.1044, temp4:0.1319 R2 temp1:0.9819, temp2:0.9119, temp3:0.9802, temp4:0.9402 RMSE temp1:0.127898, temp2:0.303002, temp3:0.135578, temp4:0.195215\n",
            "valid MODEL: LOSS 0.029348506664 MAE X1:0.1013, Y1:0.0330, Z1:0.0852 R2 X1:0.9765, Y1:0.9867, Z1:0.9785 RMSE X1:0.128489, Y1:0.042084, Z1:0.108817\n",
            "valid AUTOENCODER: LOSS 0.044351303807 MAE temp1:0.0889, temp2:0.2180, temp3:0.1019, temp4:0.1319 R2 temp1:0.9697, temp2:0.9006, temp3:0.9642, temp4:0.9402 RMSE temp1:0.115253, temp2:0.285967, temp3:0.135065, temp4:0.195215\n",
            "EPOCH 41/100:\n",
            "Weights of the Ensemble models: [0.3242284953594208, 0.6742271780967712, 0.0015443216543644667]\n",
            "train MODEL: LOSS 0.210392563694 MAE X1:0.1073, Y1:0.0371, Z1:0.1112 R2 X1:0.9819, Y1:0.9931, Z1:0.9791 RMSE X1:0.142439, Y1:0.097738, Z1:0.154339\n",
            "train AUTOENCODER: LOSS 0.043784176090 MAE temp1:0.0987, temp2:0.2286, temp3:0.1052, temp4:0.1449 R2 temp1:0.9822, temp2:0.9125, temp3:0.9801, temp4:0.9386 RMSE temp1:0.126506, temp2:0.301825, temp3:0.135810, temp4:0.198821\n",
            "valid MODEL: LOSS 0.029345134202 MAE X1:0.1013, Y1:0.0330, Z1:0.0850 R2 X1:0.9765, Y1:0.9867, Z1:0.9786 RMSE X1:0.128494, Y1:0.042008, Z1:0.108655\n",
            "valid AUTOENCODER: LOSS 0.045390486574 MAE temp1:0.0804, temp2:0.2290, temp3:0.0996, temp4:0.1449 R2 temp1:0.9722, temp2:0.8939, temp3:0.9651, temp4:0.9386 RMSE temp1:0.106426, temp2:0.296148, temp3:0.133555, temp4:0.198821\n",
            "EPOCH 42/100:\n",
            "Weights of the Ensemble models: [0.1642725169658661, 0.8341910243034363, 0.001536533934995532]\n",
            "train MODEL: LOSS 0.210502348720 MAE X1:0.1072, Y1:0.0367, Z1:0.1112 R2 X1:0.9820, Y1:0.9937, Z1:0.9791 RMSE X1:0.141849, Y1:0.093230, Z1:0.154312\n",
            "train AUTOENCODER: LOSS 0.044945660498 MAE temp1:0.1063, temp2:0.2321, temp3:0.1122, temp4:0.1335 R2 temp1:0.9799, temp2:0.9103, temp3:0.9781, temp4:0.9409 RMSE temp1:0.136394, temp2:0.305681, temp3:0.144255, temp4:0.194194\n",
            "valid MODEL: LOSS 0.029439798771 MAE X1:0.1013, Y1:0.0330, Z1:0.0850 R2 X1:0.9765, Y1:0.9867, Z1:0.9786 RMSE X1:0.128497, Y1:0.042058, Z1:0.108616\n",
            "valid AUTOENCODER: LOSS 0.044356610053 MAE temp1:0.0838, temp2:0.2231, temp3:0.0997, temp4:0.1335 R2 temp1:0.9715, temp2:0.8974, temp3:0.9653, temp4:0.9409 RMSE temp1:0.109465, temp2:0.290923, temp3:0.132717, temp4:0.194194\n",
            "EPOCH 43/100:\n",
            "Weights of the Ensemble models: [0.14828871190547943, 0.8493512868881226, 0.002359960461035371]\n",
            "train MODEL: LOSS 0.210424012204 MAE X1:0.1074, Y1:0.0369, Z1:0.1111 R2 X1:0.9818, Y1:0.9924, Z1:0.9793 RMSE X1:0.142898, Y1:0.102788, Z1:0.153781\n",
            "train AUTOENCODER: LOSS 0.043010168859 MAE temp1:0.0986, temp2:0.2286, temp3:0.1053, temp4:0.1346 R2 temp1:0.9822, temp2:0.9124, temp3:0.9801, temp4:0.9400 RMSE temp1:0.126629, temp2:0.301959, temp3:0.136171, temp4:0.195639\n",
            "valid MODEL: LOSS 0.029360220696 MAE X1:0.1014, Y1:0.0330, Z1:0.0849 R2 X1:0.9764, Y1:0.9867, Z1:0.9786 RMSE X1:0.128523, Y1:0.042074, Z1:0.108567\n",
            "valid AUTOENCODER: LOSS 0.044502687712 MAE temp1:0.0822, temp2:0.2236, temp3:0.0982, temp4:0.1346 R2 temp1:0.9715, temp2:0.8977, temp3:0.9652, temp4:0.9400 RMSE temp1:0.108194, temp2:0.290356, temp3:0.132363, temp4:0.195639\n",
            "EPOCH 44/100:\n",
            "Weights of the Ensemble models: [0.25253063440322876, 0.7464175820350647, 0.0010517359478399158]\n",
            "train MODEL: LOSS 0.210463148932 MAE X1:0.1073, Y1:0.0368, Z1:0.1113 R2 X1:0.9819, Y1:0.9933, Z1:0.9792 RMSE X1:0.142494, Y1:0.096324, Z1:0.154172\n",
            "train AUTOENCODER: LOSS 0.044552626148 MAE temp1:0.1028, temp2:0.2306, temp3:0.1082, temp4:0.1324 R2 temp1:0.9810, temp2:0.9112, temp3:0.9792, temp4:0.9390 RMSE temp1:0.131850, temp2:0.304188, temp3:0.139862, temp4:0.197257\n",
            "valid MODEL: LOSS 0.029293679274 MAE X1:0.1014, Y1:0.0331, Z1:0.0850 R2 X1:0.9764, Y1:0.9867, Z1:0.9786 RMSE X1:0.128595, Y1:0.042115, Z1:0.108565\n",
            "valid AUTOENCODER: LOSS 0.044406037061 MAE temp1:0.0877, temp2:0.2175, temp3:0.0996, temp4:0.1324 R2 temp1:0.9695, temp2:0.9016, temp3:0.9640, temp4:0.9390 RMSE temp1:0.114408, temp2:0.284279, temp3:0.134785, temp4:0.197257\n",
            "EPOCH 45/100:\n",
            "Weights of the Ensemble models: [0.3088153302669525, 0.6887457966804504, 0.0024388551246374846]\n",
            "train MODEL: LOSS 0.210339249953 MAE X1:0.1074, Y1:0.0367, Z1:0.1112 R2 X1:0.9820, Y1:0.9938, Z1:0.9793 RMSE X1:0.142131, Y1:0.092785, Z1:0.153885\n",
            "train AUTOENCODER: LOSS 0.043038975027 MAE temp1:0.0995, temp2:0.2290, temp3:0.1061, temp4:0.1319 R2 temp1:0.9819, temp2:0.9124, temp3:0.9800, temp4:0.9398 RMSE temp1:0.127754, temp2:0.302043, temp3:0.136340, temp4:0.195868\n",
            "valid MODEL: LOSS 0.029327806945 MAE X1:0.1013, Y1:0.0330, Z1:0.0850 R2 X1:0.9765, Y1:0.9867, Z1:0.9786 RMSE X1:0.128487, Y1:0.042062, Z1:0.108621\n",
            "valid AUTOENCODER: LOSS 0.044302498062 MAE temp1:0.0863, temp2:0.2191, temp3:0.0997, temp4:0.1319 R2 temp1:0.9702, temp2:0.9005, temp3:0.9644, temp4:0.9398 RMSE temp1:0.112627, temp2:0.286102, temp3:0.134020, temp4:0.195868\n",
            "EPOCH 46/100:\n",
            "Weights of the Ensemble models: [0.1235494539141655, 0.8756186366081238, 0.0008318867767229676]\n",
            "train MODEL: LOSS 0.210498521916 MAE X1:0.1073, Y1:0.0369, Z1:0.1112 R2 X1:0.9820, Y1:0.9929, Z1:0.9792 RMSE X1:0.141972, Y1:0.099237, Z1:0.154220\n",
            "train AUTOENCODER: LOSS 0.044030247617 MAE temp1:0.1010, temp2:0.2301, temp3:0.1078, temp4:0.1330 R2 temp1:0.9815, temp2:0.9117, temp3:0.9794, temp4:0.9410 RMSE temp1:0.129587, temp2:0.303331, temp3:0.138808, temp4:0.194158\n",
            "valid MODEL: LOSS 0.029450176140 MAE X1:0.1013, Y1:0.0330, Z1:0.0851 R2 X1:0.9764, Y1:0.9867, Z1:0.9786 RMSE X1:0.128552, Y1:0.042011, Z1:0.108686\n",
            "valid AUTOENCODER: LOSS 0.044262978033 MAE temp1:0.0862, temp2:0.2208, temp3:0.1008, temp4:0.1330 R2 temp1:0.9709, temp2:0.8986, temp3:0.9651, temp4:0.9410 RMSE temp1:0.112040, temp2:0.289146, temp3:0.133445, temp4:0.194158\n",
            "EPOCH 47/100:\n",
            "Weights of the Ensemble models: [0.17118680477142334, 0.8270907998085022, 0.0017224149778485298]\n",
            "train MODEL: LOSS 0.210435767568 MAE X1:0.1073, Y1:0.0367, Z1:0.1113 R2 X1:0.9820, Y1:0.9938, Z1:0.9791 RMSE X1:0.141878, Y1:0.092889, Z1:0.154382\n",
            "train AUTOENCODER: LOSS 0.045816700845 MAE temp1:0.1078, temp2:0.2328, temp3:0.1147, temp4:0.1313 R2 temp1:0.9796, temp2:0.9102, temp3:0.9776, temp4:0.9380 RMSE temp1:0.137687, temp2:0.305995, temp3:0.146115, temp4:0.198869\n",
            "valid MODEL: LOSS 0.029324990411 MAE X1:0.1013, Y1:0.0331, Z1:0.0851 R2 X1:0.9764, Y1:0.9867, Z1:0.9786 RMSE X1:0.128542, Y1:0.042055, Z1:0.108722\n",
            "valid AUTOENCODER: LOSS 0.044843588454 MAE temp1:0.0895, temp2:0.2169, temp3:0.1004, temp4:0.1313 R2 temp1:0.9685, temp2:0.9024, temp3:0.9630, temp4:0.9380 RMSE temp1:0.117013, temp2:0.282853, temp3:0.137032, temp4:0.198869\n",
            "EPOCH 48/100:\n",
            "Weights of the Ensemble models: [0.37474068999290466, 0.623857855796814, 0.001401469693519175]\n",
            "train MODEL: LOSS 0.210231204727 MAE X1:0.1075, Y1:0.0370, Z1:0.1112 R2 X1:0.9817, Y1:0.9928, Z1:0.9790 RMSE X1:0.143223, Y1:0.099997, Z1:0.154649\n",
            "train AUTOENCODER: LOSS 0.044427657320 MAE temp1:0.1027, temp2:0.2307, temp3:0.1092, temp4:0.1346 R2 temp1:0.9809, temp2:0.9114, temp3:0.9790, temp4:0.9415 RMSE temp1:0.132377, temp2:0.303776, temp3:0.140517, temp4:0.193472\n",
            "valid MODEL: LOSS 0.029405772471 MAE X1:0.1013, Y1:0.0330, Z1:0.0850 R2 X1:0.9765, Y1:0.9867, Z1:0.9786 RMSE X1:0.128496, Y1:0.042016, Z1:0.108739\n",
            "valid AUTOENCODER: LOSS 0.044393606197 MAE temp1:0.0837, temp2:0.2247, temp3:0.1002, temp4:0.1346 R2 temp1:0.9718, temp2:0.8959, temp3:0.9656, temp4:0.9415 RMSE temp1:0.109325, temp2:0.293333, temp3:0.132690, temp4:0.193472\n",
            "EPOCH 49/100:\n",
            "Weights of the Ensemble models: [0.248229518532753, 0.7497912645339966, 0.001979175955057144]\n",
            "train MODEL: LOSS 0.229703857894 MAE X1:0.1073, Y1:0.0368, Z1:0.1110 R2 X1:0.9820, Y1:0.9933, Z1:0.9794 RMSE X1:0.142050, Y1:0.096371, Z1:0.153194\n",
            "train AUTOENCODER: LOSS 0.043480803709 MAE temp1:0.1005, temp2:0.2293, temp3:0.1074, temp4:0.1350 R2 temp1:0.9817, temp2:0.9123, temp3:0.9796, temp4:0.9390 RMSE temp1:0.128848, temp2:0.302207, temp3:0.137982, temp4:0.197394\n",
            "valid MODEL: LOSS 0.029318601968 MAE X1:0.1014, Y1:0.0330, Z1:0.0850 R2 X1:0.9764, Y1:0.9867, Z1:0.9786 RMSE X1:0.128516, Y1:0.042063, Z1:0.108610\n",
            "valid AUTOENCODER: LOSS 0.044374468092 MAE temp1:0.0874, temp2:0.2176, temp3:0.0996, temp4:0.1350 R2 temp1:0.9698, temp2:0.9012, temp3:0.9643, temp4:0.9390 RMSE temp1:0.113980, temp2:0.284992, temp3:0.134299, temp4:0.197394\n",
            "EPOCH 50/100:\n",
            "Weights of the Ensemble models: [0.2774541974067688, 0.7197829484939575, 0.0027629078831523657]\n",
            "train MODEL: LOSS 0.210423773034 MAE X1:0.1076, Y1:0.0373, Z1:0.1112 R2 X1:0.9813, Y1:0.9916, Z1:0.9790 RMSE X1:0.144814, Y1:0.107827, Z1:0.154946\n",
            "train AUTOENCODER: LOSS 0.042714062718 MAE temp1:0.0981, temp2:0.2286, temp3:0.1043, temp4:0.1410 R2 temp1:0.9822, temp2:0.9127, temp3:0.9803, temp4:0.9392 RMSE temp1:0.126611, temp2:0.301485, temp3:0.135041, temp4:0.197494\n",
            "valid MODEL: LOSS 0.029315981871 MAE X1:0.1014, Y1:0.0331, Z1:0.0850 R2 X1:0.9764, Y1:0.9867, Z1:0.9786 RMSE X1:0.128558, Y1:0.042081, Z1:0.108676\n",
            "valid AUTOENCODER: LOSS 0.045038086004 MAE temp1:0.0804, temp2:0.2274, temp3:0.0985, temp4:0.1410 R2 temp1:0.9720, temp2:0.8952, temp3:0.9652, temp4:0.9392 RMSE temp1:0.106395, temp2:0.294140, temp3:0.132675, temp4:0.197494\n",
            "EPOCH 51/100:\n",
            "Weights of the Ensemble models: [0.31940776109695435, 0.6783661246299744, 0.002226044423878193]\n",
            "train MODEL: LOSS 0.210155472550 MAE X1:0.1072, Y1:0.0369, Z1:0.1111 R2 X1:0.9822, Y1:0.9935, Z1:0.9793 RMSE X1:0.141247, Y1:0.095204, Z1:0.153747\n",
            "train AUTOENCODER: LOSS 0.045192498834 MAE temp1:0.0979, temp2:0.2283, temp3:0.1041, temp4:0.1294 R2 temp1:0.9821, temp2:0.9125, temp3:0.9801, temp4:0.9403 RMSE temp1:0.127081, temp2:0.301915, temp3:0.136107, temp4:0.195193\n",
            "valid MODEL: LOSS 0.029364356986 MAE X1:0.1014, Y1:0.0331, Z1:0.0850 R2 X1:0.9765, Y1:0.9866, Z1:0.9787 RMSE X1:0.128480, Y1:0.042166, Z1:0.108486\n",
            "valid AUTOENCODER: LOSS 0.044586188948 MAE temp1:0.0990, temp2:0.2140, temp3:0.1081, temp4:0.1294 R2 temp1:0.9671, temp2:0.9028, temp3:0.9627, temp4:0.9403 RMSE temp1:0.125351, temp2:0.282560, temp3:0.140027, temp4:0.195193\n",
            "EPOCH 52/100:\n",
            "Weights of the Ensemble models: [0.2631339728832245, 0.7355064153671265, 0.0013596005737781525]\n",
            "train MODEL: LOSS 0.210526908297 MAE X1:0.1075, Y1:0.0369, Z1:0.1113 R2 X1:0.9812, Y1:0.9918, Z1:0.9789 RMSE X1:0.145087, Y1:0.106398, Z1:0.155248\n",
            "train AUTOENCODER: LOSS 0.042858561801 MAE temp1:0.0977, temp2:0.2286, temp3:0.1037, temp4:0.1316 R2 temp1:0.9823, temp2:0.9126, temp3:0.9803, temp4:0.9407 RMSE temp1:0.126105, temp2:0.301662, temp3:0.135137, temp4:0.194407\n",
            "valid MODEL: LOSS 0.029347586302 MAE X1:0.1015, Y1:0.0331, Z1:0.0850 R2 X1:0.9764, Y1:0.9867, Z1:0.9786 RMSE X1:0.128635, Y1:0.042074, Z1:0.108678\n",
            "valid AUTOENCODER: LOSS 0.044180576045 MAE temp1:0.0865, temp2:0.2198, temp3:0.1007, temp4:0.1316 R2 temp1:0.9705, temp2:0.8996, temp3:0.9648, temp4:0.9407 RMSE temp1:0.112493, temp2:0.287590, temp3:0.133749, temp4:0.194407\n",
            "EPOCH 53/100:\n",
            "Weights of the Ensemble models: [0.17481938004493713, 0.8234577775001526, 0.0017228673677891493]\n",
            "train MODEL: LOSS 0.210263605860 MAE X1:0.1074, Y1:0.0368, Z1:0.1110 R2 X1:0.9817, Y1:0.9926, Z1:0.9791 RMSE X1:0.143151, Y1:0.101212, Z1:0.154603\n",
            "train AUTOENCODER: LOSS 0.044091819996 MAE temp1:0.1030, temp2:0.2308, temp3:0.1093, temp4:0.1412 R2 temp1:0.9809, temp2:0.9112, temp3:0.9791, temp4:0.9378 RMSE temp1:0.132115, temp2:0.304082, temp3:0.140170, temp4:0.199695\n",
            "valid MODEL: LOSS 0.029310879083 MAE X1:0.1012, Y1:0.0331, Z1:0.0849 R2 X1:0.9765, Y1:0.9867, Z1:0.9786 RMSE X1:0.128354, Y1:0.042101, Z1:0.108555\n",
            "valid AUTOENCODER: LOSS 0.045229735856 MAE temp1:0.0814, temp2:0.2256, temp3:0.0982, temp4:0.1412 R2 temp1:0.9711, temp2:0.8970, temp3:0.9644, temp4:0.9378 RMSE temp1:0.108051, temp2:0.291266, temp3:0.133702, temp4:0.199695\n",
            "EPOCH 54/100:\n",
            "Weights of the Ensemble models: [0.33717119693756104, 0.6607601642608643, 0.0020686283241957426]\n",
            "train MODEL: LOSS 0.210188713706 MAE X1:0.1076, Y1:0.0370, Z1:0.1109 R2 X1:0.9817, Y1:0.9929, Z1:0.9792 RMSE X1:0.143159, Y1:0.099453, Z1:0.154184\n",
            "train AUTOENCODER: LOSS 0.043860621570 MAE temp1:0.1004, temp2:0.2298, temp3:0.1060, temp4:0.1451 R2 temp1:0.9816, temp2:0.9117, temp3:0.9798, temp4:0.9397 RMSE temp1:0.129422, temp2:0.303331, temp3:0.137374, temp4:0.197268\n",
            "valid MODEL: LOSS 0.029348898536 MAE X1:0.1014, Y1:0.0331, Z1:0.0850 R2 X1:0.9764, Y1:0.9866, Z1:0.9786 RMSE X1:0.128585, Y1:0.042173, Z1:0.108643\n",
            "valid AUTOENCODER: LOSS 0.045528092923 MAE temp1:0.0806, temp2:0.2316, temp3:0.1005, temp4:0.1451 R2 temp1:0.9727, temp2:0.8915, temp3:0.9655, temp4:0.9397 RMSE temp1:0.106478, temp2:0.299834, temp3:0.133650, temp4:0.197268\n",
            "EPOCH 55/100:\n",
            "Weights of the Ensemble models: [0.057407692074775696, 0.9418560266494751, 0.0007362893666140735]\n",
            "train MODEL: LOSS 0.210493663386 MAE X1:0.1075, Y1:0.0372, Z1:0.1112 R2 X1:0.9816, Y1:0.9919, Z1:0.9790 RMSE X1:0.143723, Y1:0.105896, Z1:0.154686\n",
            "train AUTOENCODER: LOSS 0.044499567379 MAE temp1:0.1042, temp2:0.2317, temp3:0.1109, temp4:0.1323 R2 temp1:0.9807, temp2:0.9110, temp3:0.9788, temp4:0.9408 RMSE temp1:0.133094, temp2:0.304566, temp3:0.141497, temp4:0.194241\n",
            "valid MODEL: LOSS 0.029430005771 MAE X1:0.1013, Y1:0.0331, Z1:0.0850 R2 X1:0.9765, Y1:0.9866, Z1:0.9786 RMSE X1:0.128505, Y1:0.042157, Z1:0.108592\n",
            "valid AUTOENCODER: LOSS 0.044333280136 MAE temp1:0.0844, temp2:0.2223, temp3:0.1002, temp4:0.1323 R2 temp1:0.9711, temp2:0.8981, temp3:0.9650, temp4:0.9408 RMSE temp1:0.110317, temp2:0.289781, temp3:0.133360, temp4:0.194241\n",
            "EPOCH 56/100:\n",
            "Weights of the Ensemble models: [0.1785154938697815, 0.8202171921730042, 0.0012672975426539779]\n",
            "train MODEL: LOSS 0.210388015205 MAE X1:0.1075, Y1:0.0373, Z1:0.1114 R2 X1:0.9814, Y1:0.9910, Z1:0.9788 RMSE X1:0.144366, Y1:0.111471, Z1:0.155463\n",
            "train AUTOENCODER: LOSS 0.044277763114 MAE temp1:0.1027, temp2:0.2305, temp3:0.1087, temp4:0.1348 R2 temp1:0.9810, temp2:0.9114, temp3:0.9791, temp4:0.9392 RMSE temp1:0.131758, temp2:0.303771, temp3:0.140364, temp4:0.197098\n",
            "valid MODEL: LOSS 0.029310740674 MAE X1:0.1014, Y1:0.0331, Z1:0.0849 R2 X1:0.9764, Y1:0.9867, Z1:0.9786 RMSE X1:0.128561, Y1:0.042133, Z1:0.108599\n",
            "valid AUTOENCODER: LOSS 0.044498086835 MAE temp1:0.0857, temp2:0.2192, temp3:0.0993, temp4:0.1348 R2 temp1:0.9702, temp2:0.9003, temp3:0.9644, temp4:0.9392 RMSE temp1:0.112345, temp2:0.286320, temp3:0.134080, temp4:0.197098\n",
            "EPOCH 57/100:\n",
            "Weights of the Ensemble models: [0.23525868356227875, 0.7634130120277405, 0.0013282907893881202]\n",
            "train MODEL: LOSS 0.210228787615 MAE X1:0.1072, Y1:0.0365, Z1:0.1113 R2 X1:0.9820, Y1:0.9936, Z1:0.9792 RMSE X1:0.141975, Y1:0.093817, Z1:0.154188\n",
            "train AUTOENCODER: LOSS 0.043684651114 MAE temp1:0.1020, temp2:0.2300, temp3:0.1084, temp4:0.1357 R2 temp1:0.9813, temp2:0.9117, temp3:0.9793, temp4:0.9392 RMSE temp1:0.130655, temp2:0.303316, temp3:0.139314, temp4:0.197043\n",
            "valid MODEL: LOSS 0.029268484921 MAE X1:0.1014, Y1:0.0330, Z1:0.0851 R2 X1:0.9764, Y1:0.9868, Z1:0.9786 RMSE X1:0.128536, Y1:0.041972, Z1:0.108650\n",
            "valid AUTOENCODER: LOSS 0.044716711658 MAE temp1:0.0819, temp2:0.2240, temp3:0.0977, temp4:0.1357 R2 temp1:0.9712, temp2:0.8979, temp3:0.9648, temp4:0.9392 RMSE temp1:0.108301, temp2:0.289964, temp3:0.132825, temp4:0.197043\n",
            "EPOCH 58/100:\n",
            "Weights of the Ensemble models: [0.10043786466121674, 0.8978977799415588, 0.0016643385170027614]\n",
            "train MODEL: LOSS 0.210250666155 MAE X1:0.1074, Y1:0.0368, Z1:0.1113 R2 X1:0.9817, Y1:0.9932, Z1:0.9790 RMSE X1:0.142992, Y1:0.097251, Z1:0.154665\n",
            "train AUTOENCODER: LOSS 0.043159182634 MAE temp1:0.0971, temp2:0.2282, temp3:0.1032, temp4:0.1352 R2 temp1:0.9825, temp2:0.9127, temp3:0.9805, temp4:0.9392 RMSE temp1:0.125360, temp2:0.301439, temp3:0.134271, temp4:0.196999\n",
            "valid MODEL: LOSS 0.029377354667 MAE X1:0.1013, Y1:0.0330, Z1:0.0849 R2 X1:0.9765, Y1:0.9867, Z1:0.9786 RMSE X1:0.128402, Y1:0.042023, Z1:0.108610\n",
            "valid AUTOENCODER: LOSS 0.044663107739 MAE temp1:0.0824, temp2:0.2233, temp3:0.0978, temp4:0.1352 R2 temp1:0.9710, temp2:0.8983, temp3:0.9647, temp4:0.9392 RMSE temp1:0.108769, temp2:0.289320, temp3:0.132938, temp4:0.196999\n",
            "EPOCH 59/100:\n",
            "Weights of the Ensemble models: [0.2423260360956192, 0.7565697431564331, 0.001104152761399746]\n",
            "train MODEL: LOSS 0.210300191456 MAE X1:0.1072, Y1:0.0363, Z1:0.1111 R2 X1:0.9821, Y1:0.9946, Z1:0.9793 RMSE X1:0.141708, Y1:0.086307, Z1:0.153600\n",
            "train AUTOENCODER: LOSS 0.044089687808 MAE temp1:0.1012, temp2:0.2298, temp3:0.1069, temp4:0.1346 R2 temp1:0.9815, temp2:0.9119, temp3:0.9798, temp4:0.9399 RMSE temp1:0.129807, temp2:0.302964, temp3:0.137487, temp4:0.195903\n",
            "valid MODEL: LOSS 0.029313088968 MAE X1:0.1014, Y1:0.0331, Z1:0.0851 R2 X1:0.9764, Y1:0.9867, Z1:0.9786 RMSE X1:0.128559, Y1:0.042117, Z1:0.108728\n",
            "valid AUTOENCODER: LOSS 0.044499393839 MAE temp1:0.0843, temp2:0.2212, temp3:0.0994, temp4:0.1346 R2 temp1:0.9709, temp2:0.8988, temp3:0.9648, temp4:0.9399 RMSE temp1:0.110640, temp2:0.288636, temp3:0.133444, temp4:0.195903\n",
            "EPOCH 60/100:\n",
            "Weights of the Ensemble models: [0.15752172470092773, 0.8401419520378113, 0.0023363784421235323]\n",
            "train MODEL: LOSS 0.210139361781 MAE X1:0.1074, Y1:0.0365, Z1:0.1110 R2 X1:0.9818, Y1:0.9934, Z1:0.9792 RMSE X1:0.142852, Y1:0.095584, Z1:0.153953\n",
            "train AUTOENCODER: LOSS 0.044058909339 MAE temp1:0.1003, temp2:0.2299, temp3:0.1061, temp4:0.1325 R2 temp1:0.9815, temp2:0.9119, temp3:0.9796, temp4:0.9421 RMSE temp1:0.129767, temp2:0.302880, temp3:0.138018, temp4:0.192456\n",
            "valid MODEL: LOSS 0.029436810802 MAE X1:0.1013, Y1:0.0330, Z1:0.0851 R2 X1:0.9765, Y1:0.9867, Z1:0.9786 RMSE X1:0.128497, Y1:0.042009, Z1:0.108719\n",
            "valid AUTOENCODER: LOSS 0.044418158439 MAE temp1:0.0880, temp2:0.2225, temp3:0.1036, temp4:0.1325 R2 temp1:0.9709, temp2:0.8968, temp3:0.9650, temp4:0.9421 RMSE temp1:0.113764, temp2:0.292025, temp3:0.134830, temp4:0.192456\n",
            "EPOCH 61/100:\n",
            "Weights of the Ensemble models: [0.18929460644721985, 0.8092703223228455, 0.0014350336277857423]\n",
            "train MODEL: LOSS 0.210621188455 MAE X1:0.1074, Y1:0.0368, Z1:0.1113 R2 X1:0.9816, Y1:0.9924, Z1:0.9790 RMSE X1:0.143566, Y1:0.102228, Z1:0.154681\n",
            "train AUTOENCODER: LOSS 0.044174882133 MAE temp1:0.1000, temp2:0.2296, temp3:0.1056, temp4:0.1299 R2 temp1:0.9817, temp2:0.9121, temp3:0.9800, temp4:0.9402 RMSE temp1:0.128727, temp2:0.302640, temp3:0.136280, temp4:0.195404\n",
            "valid MODEL: LOSS 0.029373617843 MAE X1:0.1013, Y1:0.0330, Z1:0.0851 R2 X1:0.9764, Y1:0.9867, Z1:0.9786 RMSE X1:0.128546, Y1:0.042008, Z1:0.108692\n",
            "valid AUTOENCODER: LOSS 0.044881031060 MAE temp1:0.1023, temp2:0.2133, temp3:0.1110, temp4:0.1299 R2 temp1:0.9660, temp2:0.9031, temp3:0.9619, temp4:0.9402 RMSE temp1:0.128939, temp2:0.282127, temp3:0.142174, temp4:0.195404\n",
            "EPOCH 62/100:\n",
            "Weights of the Ensemble models: [0.2898436486721039, 0.7080628871917725, 0.0020934250205755234]\n",
            "train MODEL: LOSS 0.210421872265 MAE X1:0.1073, Y1:0.0368, Z1:0.1108 R2 X1:0.9818, Y1:0.9928, Z1:0.9794 RMSE X1:0.142850, Y1:0.099875, Z1:0.153496\n",
            "train AUTOENCODER: LOSS 0.043845196705 MAE temp1:0.1023, temp2:0.2299, temp3:0.1085, temp4:0.1377 R2 temp1:0.9812, temp2:0.9117, temp3:0.9794, temp4:0.9392 RMSE temp1:0.130816, temp2:0.303253, temp3:0.138880, temp4:0.197220\n",
            "valid MODEL: LOSS 0.029358886397 MAE X1:0.1014, Y1:0.0330, Z1:0.0850 R2 X1:0.9764, Y1:0.9867, Z1:0.9786 RMSE X1:0.128615, Y1:0.042080, Z1:0.108590\n",
            "valid AUTOENCODER: LOSS 0.044519529750 MAE temp1:0.0823, temp2:0.2224, temp3:0.0977, temp4:0.1377 R2 temp1:0.9714, temp2:0.8984, temp3:0.9651, temp4:0.9392 RMSE temp1:0.108338, temp2:0.289253, temp3:0.132234, temp4:0.197220\n",
            "EPOCH 63/100:\n",
            "Weights of the Ensemble models: [0.2669822871685028, 0.7307299971580505, 0.002287746872752905]\n",
            "train MODEL: LOSS 0.210214587079 MAE X1:0.1075, Y1:0.0370, Z1:0.1111 R2 X1:0.9815, Y1:0.9921, Z1:0.9790 RMSE X1:0.143925, Y1:0.104506, Z1:0.154933\n",
            "train AUTOENCODER: LOSS 0.043073686741 MAE temp1:0.0996, temp2:0.2303, temp3:0.1046, temp4:0.1307 R2 temp1:0.9819, temp2:0.9117, temp3:0.9802, temp4:0.9394 RMSE temp1:0.127912, temp2:0.303371, temp3:0.135573, temp4:0.196465\n",
            "valid MODEL: LOSS 0.029356821082 MAE X1:0.1014, Y1:0.0330, Z1:0.0850 R2 X1:0.9764, Y1:0.9868, Z1:0.9786 RMSE X1:0.128538, Y1:0.041905, Z1:0.108713\n",
            "valid AUTOENCODER: LOSS 0.044433276957 MAE temp1:0.0874, temp2:0.2185, temp3:0.1002, temp4:0.1307 R2 temp1:0.9696, temp2:0.9011, temp3:0.9639, temp4:0.9394 RMSE temp1:0.114008, temp2:0.284973, temp3:0.135105, temp4:0.196465\n",
            "EPOCH 64/100:\n",
            "Weights of the Ensemble models: [0.325359046459198, 0.672957718372345, 0.0016832008259370923]\n",
            "train MODEL: LOSS 0.210053831669 MAE X1:0.1075, Y1:0.0368, Z1:0.1111 R2 X1:0.9815, Y1:0.9925, Z1:0.9790 RMSE X1:0.143905, Y1:0.101843, Z1:0.154760\n",
            "train AUTOENCODER: LOSS 0.043999825514 MAE temp1:0.1026, temp2:0.2300, temp3:0.1092, temp4:0.1418 R2 temp1:0.9812, temp2:0.9118, temp3:0.9792, temp4:0.9386 RMSE temp1:0.131137, temp2:0.303040, temp3:0.139781, temp4:0.198519\n",
            "valid MODEL: LOSS 0.029270912879 MAE X1:0.1014, Y1:0.0331, Z1:0.0851 R2 X1:0.9764, Y1:0.9867, Z1:0.9786 RMSE X1:0.128579, Y1:0.042079, Z1:0.108718\n",
            "valid AUTOENCODER: LOSS 0.045042256753 MAE temp1:0.0807, temp2:0.2259, temp3:0.0982, temp4:0.1418 R2 temp1:0.9718, temp2:0.8963, temp3:0.9650, temp4:0.9386 RMSE temp1:0.106805, temp2:0.292508, temp3:0.132771, temp4:0.198519\n",
            "EPOCH 65/100:\n",
            "Weights of the Ensemble models: [0.3912903964519501, 0.606974184513092, 0.001735371071845293]\n",
            "train MODEL: LOSS 0.210227041716 MAE X1:0.1073, Y1:0.0370, Z1:0.1112 R2 X1:0.9817, Y1:0.9925, Z1:0.9790 RMSE X1:0.143300, Y1:0.101985, Z1:0.154726\n",
            "train AUTOENCODER: LOSS 0.046990290705 MAE temp1:0.1023, temp2:0.2311, temp3:0.1082, temp4:0.1304 R2 temp1:0.9808, temp2:0.9111, temp3:0.9790, temp4:0.9361 RMSE temp1:0.132735, temp2:0.304337, temp3:0.140404, temp4:0.202380\n",
            "valid MODEL: LOSS 0.029248141612 MAE X1:0.1016, Y1:0.0330, Z1:0.0851 R2 X1:0.9764, Y1:0.9867, Z1:0.9786 RMSE X1:0.128730, Y1:0.042029, Z1:0.108640\n",
            "valid AUTOENCODER: LOSS 0.045888645288 MAE temp1:0.1064, temp2:0.2097, temp3:0.1087, temp4:0.1304 R2 temp1:0.9636, temp2:0.9062, temp3:0.9597, temp4:0.9361 RMSE temp1:0.133881, temp2:0.276610, temp3:0.145822, temp4:0.202380\n",
            "EPOCH 66/100:\n",
            "Weights of the Ensemble models: [0.28770262002944946, 0.7107539176940918, 0.0015434441156685352]\n",
            "train MODEL: LOSS 0.210304176375 MAE X1:0.1075, Y1:0.0370, Z1:0.1111 R2 X1:0.9815, Y1:0.9918, Z1:0.9790 RMSE X1:0.143828, Y1:0.106486, Z1:0.154926\n",
            "train AUTOENCODER: LOSS 0.045400085408 MAE temp1:0.1047, temp2:0.2326, temp3:0.1100, temp4:0.1302 R2 temp1:0.9802, temp2:0.9103, temp3:0.9785, temp4:0.9413 RMSE temp1:0.135197, temp2:0.305685, temp3:0.142768, temp4:0.193787\n",
            "valid MODEL: LOSS 0.029428818621 MAE X1:0.1014, Y1:0.0331, Z1:0.0851 R2 X1:0.9764, Y1:0.9867, Z1:0.9785 RMSE X1:0.128574, Y1:0.042116, Z1:0.108752\n",
            "valid AUTOENCODER: LOSS 0.044499372347 MAE temp1:0.0963, temp2:0.2165, temp3:0.1086, temp4:0.1302 R2 temp1:0.9682, temp2:0.9009, temp3:0.9632, temp4:0.9413 RMSE temp1:0.122336, temp2:0.285657, temp3:0.139246, temp4:0.193787\n",
            "EPOCH 67/100:\n",
            "Weights of the Ensemble models: [0.11901621520519257, 0.8799087405204773, 0.001075062551535666]\n",
            "train MODEL: LOSS 0.210159368332 MAE X1:0.1075, Y1:0.0370, Z1:0.1112 R2 X1:0.9817, Y1:0.9927, Z1:0.9790 RMSE X1:0.143032, Y1:0.100703, Z1:0.154723\n",
            "train AUTOENCODER: LOSS 0.042683378763 MAE temp1:0.0968, temp2:0.2282, temp3:0.1033, temp4:0.1338 R2 temp1:0.9824, temp2:0.9127, temp3:0.9804, temp4:0.9391 RMSE temp1:0.125625, temp2:0.301425, temp3:0.134791, temp4:0.197052\n",
            "valid MODEL: LOSS 0.029354147112 MAE X1:0.1013, Y1:0.0331, Z1:0.0850 R2 X1:0.9765, Y1:0.9867, Z1:0.9786 RMSE X1:0.128401, Y1:0.042129, Z1:0.108549\n",
            "valid AUTOENCODER: LOSS 0.044477367487 MAE temp1:0.0846, temp2:0.2202, temp3:0.0984, temp4:0.1338 R2 temp1:0.9704, temp2:0.9001, temp3:0.9645, temp4:0.9391 RMSE temp1:0.111199, temp2:0.286644, temp3:0.133618, temp4:0.197052\n",
            "EPOCH 68/100:\n",
            "Weights of the Ensemble models: [0.3448242247104645, 0.6545124053955078, 0.0006633681477978826]\n",
            "train MODEL: LOSS 0.269005825322 MAE X1:0.1072, Y1:0.0366, Z1:0.1113 R2 X1:0.9819, Y1:0.9935, Z1:0.9791 RMSE X1:0.142317, Y1:0.094662, Z1:0.154628\n",
            "train AUTOENCODER: LOSS 0.043361512644 MAE temp1:0.0989, temp2:0.2290, temp3:0.1050, temp4:0.1355 R2 temp1:0.9820, temp2:0.9121, temp3:0.9801, temp4:0.9397 RMSE temp1:0.127693, temp2:0.302495, temp3:0.136165, temp4:0.196249\n",
            "valid MODEL: LOSS 0.029309431306 MAE X1:0.1013, Y1:0.0330, Z1:0.0850 R2 X1:0.9765, Y1:0.9867, Z1:0.9786 RMSE X1:0.128440, Y1:0.042028, Z1:0.108696\n",
            "valid AUTOENCODER: LOSS 0.044508348147 MAE temp1:0.0824, temp2:0.2232, temp3:0.0983, temp4:0.1355 R2 temp1:0.9713, temp2:0.8980, temp3:0.9650, temp4:0.9397 RMSE temp1:0.108612, temp2:0.289932, temp3:0.132711, temp4:0.196249\n",
            "EPOCH 69/100:\n",
            "Weights of the Ensemble models: [0.21748831868171692, 0.7807988524436951, 0.0017127786995843053]\n",
            "train MODEL: LOSS 0.210192221127 MAE X1:0.1075, Y1:0.0369, Z1:0.1113 R2 X1:0.9817, Y1:0.9928, Z1:0.9789 RMSE X1:0.143331, Y1:0.099485, Z1:0.155049\n",
            "train AUTOENCODER: LOSS 0.044166621482 MAE temp1:0.1025, temp2:0.2300, temp3:0.1100, temp4:0.1370 R2 temp1:0.9811, temp2:0.9117, temp3:0.9789, temp4:0.9406 RMSE temp1:0.131269, temp2:0.303262, temp3:0.140836, temp4:0.195047\n",
            "valid MODEL: LOSS 0.029331161497 MAE X1:0.1013, Y1:0.0330, Z1:0.0851 R2 X1:0.9765, Y1:0.9867, Z1:0.9785 RMSE X1:0.128415, Y1:0.042015, Z1:0.108829\n",
            "valid AUTOENCODER: LOSS 0.044531487072 MAE temp1:0.0827, temp2:0.2242, temp3:0.0992, temp4:0.1370 R2 temp1:0.9718, temp2:0.8965, temp3:0.9655, temp4:0.9406 RMSE temp1:0.108447, temp2:0.292422, temp3:0.132402, temp4:0.195047\n",
            "EPOCH 70/100:\n",
            "Weights of the Ensemble models: [0.16478335857391357, 0.8340455293655396, 0.0011710814433172345]\n",
            "train MODEL: LOSS 0.210439917031 MAE X1:0.1074, Y1:0.0366, Z1:0.1109 R2 X1:0.9817, Y1:0.9932, Z1:0.9793 RMSE X1:0.143159, Y1:0.096907, Z1:0.153623\n",
            "train AUTOENCODER: LOSS 0.044271776753 MAE temp1:0.1015, temp2:0.2305, temp3:0.1065, temp4:0.1291 R2 temp1:0.9813, temp2:0.9113, temp3:0.9796, temp4:0.9395 RMSE temp1:0.130503, temp2:0.303983, temp3:0.138194, temp4:0.196480\n",
            "valid MODEL: LOSS 0.029366731715 MAE X1:0.1014, Y1:0.0331, Z1:0.0851 R2 X1:0.9765, Y1:0.9867, Z1:0.9786 RMSE X1:0.128467, Y1:0.042080, Z1:0.108687\n",
            "valid AUTOENCODER: LOSS 0.044558801043 MAE temp1:0.0961, temp2:0.2139, temp3:0.1054, temp4:0.1291 R2 temp1:0.9675, temp2:0.9034, temp3:0.9627, temp4:0.9395 RMSE temp1:0.122641, temp2:0.281474, temp3:0.139032, temp4:0.196480\n",
            "EPOCH 71/100:\n",
            "Weights of the Ensemble models: [0.24434851109981537, 0.7547286748886108, 0.0009227822883985937]\n",
            "train MODEL: LOSS 0.233879005206 MAE X1:0.1073, Y1:0.0368, Z1:0.1109 R2 X1:0.9818, Y1:0.9925, Z1:0.9792 RMSE X1:0.142619, Y1:0.101997, Z1:0.153969\n",
            "train AUTOENCODER: LOSS 0.043765549698 MAE temp1:0.1010, temp2:0.2296, temp3:0.1076, temp4:0.1309 R2 temp1:0.9814, temp2:0.9120, temp3:0.9794, temp4:0.9416 RMSE temp1:0.130207, temp2:0.302773, temp3:0.138903, temp4:0.193137\n",
            "valid MODEL: LOSS 0.029444715223 MAE X1:0.1014, Y1:0.0330, Z1:0.0850 R2 X1:0.9765, Y1:0.9867, Z1:0.9786 RMSE X1:0.128490, Y1:0.042053, Z1:0.108645\n",
            "valid AUTOENCODER: LOSS 0.044406413745 MAE temp1:0.0929, temp2:0.2182, temp3:0.1057, temp4:0.1309 R2 temp1:0.9693, temp2:0.8996, temp3:0.9642, temp4:0.9416 RMSE temp1:0.118986, temp2:0.287655, temp3:0.136741, temp4:0.193137\n",
            "EPOCH 72/100:\n",
            "Weights of the Ensemble models: [0.30416446924209595, 0.6950611472129822, 0.0007743772002868354]\n",
            "train MODEL: LOSS 0.210302657267 MAE X1:0.1076, Y1:0.0371, Z1:0.1111 R2 X1:0.9814, Y1:0.9921, Z1:0.9790 RMSE X1:0.144512, Y1:0.104883, Z1:0.154658\n",
            "train AUTOENCODER: LOSS 0.044087298575 MAE temp1:0.1008, temp2:0.2303, temp3:0.1067, temp4:0.1301 R2 temp1:0.9813, temp2:0.9116, temp3:0.9795, temp4:0.9401 RMSE temp1:0.130648, temp2:0.303401, temp3:0.138497, temp4:0.195464\n",
            "valid MODEL: LOSS 0.029343016159 MAE X1:0.1013, Y1:0.0331, Z1:0.0850 R2 X1:0.9765, Y1:0.9867, Z1:0.9786 RMSE X1:0.128465, Y1:0.042106, Z1:0.108683\n",
            "valid AUTOENCODER: LOSS 0.044281216768 MAE temp1:0.0902, temp2:0.2168, temp3:0.1021, temp4:0.1301 R2 temp1:0.9692, temp2:0.9017, temp3:0.9639, temp4:0.9401 RMSE temp1:0.116534, temp2:0.284247, temp3:0.135761, temp4:0.195464\n",
            "EPOCH 73/100:\n",
            "Weights of the Ensemble models: [0.15513493120670319, 0.8439009189605713, 0.0009641299257054925]\n",
            "train MODEL: LOSS 0.210262785305 MAE X1:0.1073, Y1:0.0369, Z1:0.1110 R2 X1:0.9818, Y1:0.9930, Z1:0.9792 RMSE X1:0.142702, Y1:0.098272, Z1:0.154246\n",
            "train AUTOENCODER: LOSS 0.044434466549 MAE temp1:0.1038, temp2:0.2314, temp3:0.1105, temp4:0.1341 R2 temp1:0.9806, temp2:0.9111, temp3:0.9788, temp4:0.9398 RMSE temp1:0.133402, temp2:0.304257, temp3:0.141527, temp4:0.196071\n",
            "valid MODEL: LOSS 0.029347977673 MAE X1:0.1013, Y1:0.0330, Z1:0.0850 R2 X1:0.9765, Y1:0.9867, Z1:0.9786 RMSE X1:0.128436, Y1:0.042083, Z1:0.108601\n",
            "valid AUTOENCODER: LOSS 0.044371681431 MAE temp1:0.0837, temp2:0.2214, temp3:0.0986, temp4:0.1341 R2 temp1:0.9709, temp2:0.8991, temp3:0.9649, temp4:0.9398 RMSE temp1:0.109956, temp2:0.288245, temp3:0.132981, temp4:0.196071\n",
            "EPOCH 74/100:\n",
            "Weights of the Ensemble models: [0.3694745600223541, 0.629064679145813, 0.0014607880730181932]\n",
            "train MODEL: LOSS 0.210479237800 MAE X1:0.1075, Y1:0.0371, Z1:0.1110 R2 X1:0.9817, Y1:0.9925, Z1:0.9793 RMSE X1:0.143103, Y1:0.101604, Z1:0.153852\n",
            "train AUTOENCODER: LOSS 0.043732473627 MAE temp1:0.1002, temp2:0.2295, temp3:0.1070, temp4:0.1348 R2 temp1:0.9817, temp2:0.9122, temp3:0.9797, temp4:0.9379 RMSE temp1:0.128828, temp2:0.302406, temp3:0.137574, temp4:0.199099\n",
            "valid MODEL: LOSS 0.029289632534 MAE X1:0.1014, Y1:0.0330, Z1:0.0851 R2 X1:0.9765, Y1:0.9867, Z1:0.9786 RMSE X1:0.128507, Y1:0.042117, Z1:0.108691\n",
            "valid AUTOENCODER: LOSS 0.044759294878 MAE temp1:0.0860, temp2:0.2191, temp3:0.0986, temp4:0.1348 R2 temp1:0.9696, temp2:0.9010, temp3:0.9637, temp4:0.9379 RMSE temp1:0.113323, temp2:0.285029, temp3:0.135133, temp4:0.199099\n",
            "EPOCH 75/100:\n",
            "Weights of the Ensemble models: [0.3505083918571472, 0.6477563381195068, 0.001735266181640327]\n",
            "train MODEL: LOSS 0.252264931498 MAE X1:0.1071, Y1:0.0363, Z1:0.1110 R2 X1:0.9822, Y1:0.9941, Z1:0.9793 RMSE X1:0.141083, Y1:0.090155, Z1:0.153751\n",
            "train AUTOENCODER: LOSS 0.045087285400 MAE temp1:0.1055, temp2:0.2317, temp3:0.1125, temp4:0.1318 R2 temp1:0.9801, temp2:0.9107, temp3:0.9781, temp4:0.9403 RMSE temp1:0.135926, temp2:0.304992, temp3:0.144268, temp4:0.195119\n",
            "valid MODEL: LOSS 0.029329973631 MAE X1:0.1014, Y1:0.0330, Z1:0.0850 R2 X1:0.9765, Y1:0.9867, Z1:0.9786 RMSE X1:0.128488, Y1:0.042017, Z1:0.108697\n",
            "valid AUTOENCODER: LOSS 0.044264511993 MAE temp1:0.0881, temp2:0.2183, temp3:0.1012, temp4:0.1318 R2 temp1:0.9700, temp2:0.9005, temp3:0.9645, temp4:0.9403 RMSE temp1:0.114350, temp2:0.286069, temp3:0.134516, temp4:0.195119\n",
            "EPOCH 76/100:\n",
            "Weights of the Ensemble models: [0.35229337215423584, 0.6450879573822021, 0.0026186786126345396]\n",
            "train MODEL: LOSS 0.210183418897 MAE X1:0.1077, Y1:0.0371, Z1:0.1113 R2 X1:0.9809, Y1:0.9904, Z1:0.9787 RMSE X1:0.146324, Y1:0.115146, Z1:0.155823\n",
            "train AUTOENCODER: LOSS 0.043371186381 MAE temp1:0.1010, temp2:0.2299, temp3:0.1066, temp4:0.1327 R2 temp1:0.9816, temp2:0.9116, temp3:0.9798, temp4:0.9412 RMSE temp1:0.129207, temp2:0.303449, temp3:0.137377, temp4:0.193736\n",
            "valid MODEL: LOSS 0.029357747748 MAE X1:0.1013, Y1:0.0330, Z1:0.0850 R2 X1:0.9765, Y1:0.9867, Z1:0.9786 RMSE X1:0.128456, Y1:0.042020, Z1:0.108606\n",
            "valid AUTOENCODER: LOSS 0.044170453285 MAE temp1:0.0859, temp2:0.2214, temp3:0.1009, temp4:0.1327 R2 temp1:0.9710, temp2:0.8982, temp3:0.9652, temp4:0.9412 RMSE temp1:0.111660, temp2:0.289750, temp3:0.133348, temp4:0.193736\n",
            "EPOCH 77/100:\n",
            "Weights of the Ensemble models: [0.2803652286529541, 0.7177786827087402, 0.0018560809548944235]\n",
            "train MODEL: LOSS 0.210356121943 MAE X1:0.1077, Y1:0.0371, Z1:0.1113 R2 X1:0.9814, Y1:0.9916, Z1:0.9790 RMSE X1:0.144435, Y1:0.108063, Z1:0.154983\n",
            "train AUTOENCODER: LOSS 0.042570972575 MAE temp1:0.0971, temp2:0.2284, temp3:0.1035, temp4:0.1321 R2 temp1:0.9825, temp2:0.9127, temp3:0.9806, temp4:0.9401 RMSE temp1:0.125291, temp2:0.301558, temp3:0.133959, temp4:0.195501\n",
            "valid MODEL: LOSS 0.029350291078 MAE X1:0.1013, Y1:0.0330, Z1:0.0851 R2 X1:0.9765, Y1:0.9867, Z1:0.9785 RMSE X1:0.128474, Y1:0.042048, Z1:0.108747\n",
            "valid AUTOENCODER: LOSS 0.044208067254 MAE temp1:0.0888, temp2:0.2175, temp3:0.1009, temp4:0.1321 R2 temp1:0.9698, temp2:0.9010, temp3:0.9644, temp4:0.9401 RMSE temp1:0.115044, temp2:0.285298, temp3:0.134462, temp4:0.195501\n",
            "EPOCH 78/100:\n",
            "Weights of the Ensemble models: [0.3687015771865845, 0.6300979852676392, 0.0012004374293610454]\n",
            "train MODEL: LOSS 0.210300488548 MAE X1:0.1074, Y1:0.0373, Z1:0.1111 R2 X1:0.9814, Y1:0.9916, Z1:0.9790 RMSE X1:0.144490, Y1:0.108129, Z1:0.154874\n",
            "train AUTOENCODER: LOSS 0.042621886057 MAE temp1:0.0953, temp2:0.2276, temp3:0.1020, temp4:0.1301 R2 temp1:0.9829, temp2:0.9131, temp3:0.9809, temp4:0.9398 RMSE temp1:0.123286, temp2:0.300807, temp3:0.132583, temp4:0.196012\n",
            "valid MODEL: LOSS 0.029314060910 MAE X1:0.1015, Y1:0.0331, Z1:0.0850 R2 X1:0.9764, Y1:0.9867, Z1:0.9786 RMSE X1:0.128619, Y1:0.042092, Z1:0.108705\n",
            "valid AUTOENCODER: LOSS 0.044521746441 MAE temp1:0.0959, temp2:0.2141, temp3:0.1055, temp4:0.1301 R2 temp1:0.9676, temp2:0.9030, temp3:0.9629, temp4:0.9398 RMSE temp1:0.122607, temp2:0.282150, temp3:0.138615, temp4:0.196012\n",
            "EPOCH 79/100:\n",
            "Weights of the Ensemble models: [0.2315378487110138, 0.7660708427429199, 0.0023913050536066294]\n",
            "train MODEL: LOSS 0.210372012950 MAE X1:0.1074, Y1:0.0367, Z1:0.1113 R2 X1:0.9819, Y1:0.9933, Z1:0.9791 RMSE X1:0.142536, Y1:0.096468, Z1:0.154473\n",
            "train AUTOENCODER: LOSS 0.046215261904 MAE temp1:0.1069, temp2:0.2323, temp3:0.1137, temp4:0.1302 R2 temp1:0.9799, temp2:0.9107, temp3:0.9780, temp4:0.9404 RMSE temp1:0.136747, temp2:0.304997, temp3:0.144768, temp4:0.194955\n",
            "valid MODEL: LOSS 0.029361760244 MAE X1:0.1013, Y1:0.0331, Z1:0.0850 R2 X1:0.9765, Y1:0.9867, Z1:0.9786 RMSE X1:0.128399, Y1:0.042059, Z1:0.108538\n",
            "valid AUTOENCODER: LOSS 0.044305491906 MAE temp1:0.0895, temp2:0.2178, temp3:0.1028, temp4:0.1302 R2 temp1:0.9695, temp2:0.9010, temp3:0.9639, temp4:0.9404 RMSE temp1:0.115822, temp2:0.285321, temp3:0.135892, temp4:0.194955\n",
            "EPOCH 80/100:\n",
            "Weights of the Ensemble models: [0.2954195439815521, 0.7034587860107422, 0.0011216634884476662]\n",
            "train MODEL: LOSS 0.210205285780 MAE X1:0.1076, Y1:0.0370, Z1:0.1113 R2 X1:0.9815, Y1:0.9924, Z1:0.9789 RMSE X1:0.143839, Y1:0.102524, Z1:0.155032\n",
            "train AUTOENCODER: LOSS 0.044377232331 MAE temp1:0.1022, temp2:0.2302, temp3:0.1082, temp4:0.1312 R2 temp1:0.9810, temp2:0.9117, temp3:0.9792, temp4:0.9406 RMSE temp1:0.131988, temp2:0.303214, temp3:0.139682, temp4:0.194600\n",
            "valid MODEL: LOSS 0.029354685416 MAE X1:0.1013, Y1:0.0331, Z1:0.0849 R2 X1:0.9764, Y1:0.9867, Z1:0.9786 RMSE X1:0.128549, Y1:0.042151, Z1:0.108509\n",
            "valid AUTOENCODER: LOSS 0.044235927268 MAE temp1:0.0878, temp2:0.2189, temp3:0.1014, temp4:0.1312 R2 temp1:0.9701, temp2:0.9002, temp3:0.9645, temp4:0.9406 RMSE temp1:0.113915, temp2:0.286689, temp3:0.134487, temp4:0.194600\n",
            "EPOCH 81/100:\n",
            "Weights of the Ensemble models: [0.29517021775245667, 0.7016267776489258, 0.0032030094880610704]\n",
            "train MODEL: LOSS 0.210190410936 MAE X1:0.1074, Y1:0.0369, Z1:0.1110 R2 X1:0.9814, Y1:0.9919, Z1:0.9789 RMSE X1:0.144238, Y1:0.105910, Z1:0.155077\n",
            "train AUTOENCODER: LOSS 0.045388221500 MAE temp1:0.1071, temp2:0.2330, temp3:0.1136, temp4:0.1318 R2 temp1:0.9797, temp2:0.9101, temp3:0.9778, temp4:0.9399 RMSE temp1:0.137352, temp2:0.306090, temp3:0.145530, temp4:0.195794\n",
            "valid MODEL: LOSS 0.029344927090 MAE X1:0.1014, Y1:0.0330, Z1:0.0850 R2 X1:0.9764, Y1:0.9867, Z1:0.9786 RMSE X1:0.128661, Y1:0.042102, Z1:0.108682\n",
            "valid AUTOENCODER: LOSS 0.044255398357 MAE temp1:0.0885, temp2:0.2176, temp3:0.1012, temp4:0.1318 R2 temp1:0.9696, temp2:0.9011, temp3:0.9641, temp4:0.9399 RMSE temp1:0.115004, temp2:0.285187, temp3:0.135036, temp4:0.195794\n",
            "EPOCH 82/100:\n",
            "Weights of the Ensemble models: [0.24949343502521515, 0.7492141723632812, 0.0012924018083140254]\n",
            "train MODEL: LOSS 0.210288268184 MAE X1:0.1075, Y1:0.0370, Z1:0.1113 R2 X1:0.9815, Y1:0.9923, Z1:0.9790 RMSE X1:0.143983, Y1:0.102955, Z1:0.154697\n",
            "train AUTOENCODER: LOSS 0.043255970903 MAE temp1:0.1002, temp2:0.2299, temp3:0.1059, temp4:0.1302 R2 temp1:0.9817, temp2:0.9118, temp3:0.9799, temp4:0.9411 RMSE temp1:0.128974, temp2:0.303100, temp3:0.136880, temp4:0.193866\n",
            "valid MODEL: LOSS 0.029447502098 MAE X1:0.1014, Y1:0.0331, Z1:0.0850 R2 X1:0.9764, Y1:0.9867, Z1:0.9786 RMSE X1:0.128577, Y1:0.042036, Z1:0.108665\n",
            "valid AUTOENCODER: LOSS 0.044224200484 MAE temp1:0.0914, temp2:0.2174, temp3:0.1039, temp4:0.1302 R2 temp1:0.9694, temp2:0.9007, temp3:0.9642, temp4:0.9411 RMSE temp1:0.117480, temp2:0.285974, temp3:0.135946, temp4:0.193866\n",
            "EPOCH 83/100:\n",
            "Weights of the Ensemble models: [0.1109459176659584, 0.8879673480987549, 0.001086770324036479]\n",
            "train MODEL: LOSS 0.210358585501 MAE X1:0.1071, Y1:0.0366, Z1:0.1110 R2 X1:0.9822, Y1:0.9938, Z1:0.9793 RMSE X1:0.141279, Y1:0.092849, Z1:0.153679\n",
            "train AUTOENCODER: LOSS 0.044280209729 MAE temp1:0.1016, temp2:0.2299, temp3:0.1087, temp4:0.1393 R2 temp1:0.9814, temp2:0.9117, temp3:0.9792, temp4:0.9383 RMSE temp1:0.130302, temp2:0.303247, temp3:0.139714, temp4:0.198794\n",
            "valid MODEL: LOSS 0.029331780397 MAE X1:0.1014, Y1:0.0330, Z1:0.0850 R2 X1:0.9764, Y1:0.9867, Z1:0.9786 RMSE X1:0.128613, Y1:0.042055, Z1:0.108660\n",
            "valid AUTOENCODER: LOSS 0.044879987836 MAE temp1:0.0821, temp2:0.2234, temp3:0.0980, temp4:0.1393 R2 temp1:0.9710, temp2:0.8981, temp3:0.9646, temp4:0.9383 RMSE temp1:0.108743, temp2:0.289655, temp3:0.133425, temp4:0.198794\n",
            "EPOCH 84/100:\n",
            "Weights of the Ensemble models: [0.1465662717819214, 0.8522211313247681, 0.0012126101646572351]\n",
            "train MODEL: LOSS 0.210214238854 MAE X1:0.1077, Y1:0.0369, Z1:0.1111 R2 X1:0.9813, Y1:0.9918, Z1:0.9789 RMSE X1:0.144722, Y1:0.106289, Z1:0.155110\n",
            "train AUTOENCODER: LOSS 0.043621034572 MAE temp1:0.1003, temp2:0.2297, temp3:0.1067, temp4:0.1352 R2 temp1:0.9816, temp2:0.9120, temp3:0.9798, temp4:0.9398 RMSE temp1:0.129008, temp2:0.302793, temp3:0.137246, temp4:0.196123\n",
            "valid MODEL: LOSS 0.029321874707 MAE X1:0.1014, Y1:0.0330, Z1:0.0850 R2 X1:0.9764, Y1:0.9867, Z1:0.9786 RMSE X1:0.128527, Y1:0.042009, Z1:0.108527\n",
            "valid AUTOENCODER: LOSS 0.044663389572 MAE temp1:0.0832, temp2:0.2228, temp3:0.0990, temp4:0.1352 R2 temp1:0.9711, temp2:0.8981, temp3:0.9648, temp4:0.9398 RMSE temp1:0.109536, temp2:0.289807, temp3:0.133351, temp4:0.196123\n",
            "EPOCH 85/100:\n",
            "Weights of the Ensemble models: [0.4724205434322357, 0.5259773135185242, 0.0016021854244172573]\n",
            "train MODEL: LOSS 0.210242333732 MAE X1:0.1074, Y1:0.0369, Z1:0.1112 R2 X1:0.9815, Y1:0.9925, Z1:0.9791 RMSE X1:0.143836, Y1:0.101686, Z1:0.154617\n",
            "train AUTOENCODER: LOSS 0.045013505365 MAE temp1:0.1036, temp2:0.2303, temp3:0.1111, temp4:0.1295 R2 temp1:0.9805, temp2:0.9116, temp3:0.9784, temp4:0.9399 RMSE temp1:0.134194, temp2:0.303480, temp3:0.143150, temp4:0.195881\n",
            "valid MODEL: LOSS 0.029313059882 MAE X1:0.1014, Y1:0.0331, Z1:0.0849 R2 X1:0.9765, Y1:0.9867, Z1:0.9786 RMSE X1:0.128513, Y1:0.042119, Z1:0.108515\n",
            "valid AUTOENCODER: LOSS 0.044483407472 MAE temp1:0.0967, temp2:0.2138, temp3:0.1058, temp4:0.1295 R2 temp1:0.9675, temp2:0.9032, temp3:0.9629, temp4:0.9399 RMSE temp1:0.123264, temp2:0.281881, temp3:0.138799, temp4:0.195881\n",
            "EPOCH 86/100:\n",
            "Weights of the Ensemble models: [0.08036942034959793, 0.9183787107467651, 0.0012518401490524411]\n",
            "train MODEL: LOSS 0.210117150999 MAE X1:0.1075, Y1:0.0367, Z1:0.1110 R2 X1:0.9818, Y1:0.9929, Z1:0.9793 RMSE X1:0.142758, Y1:0.099236, Z1:0.153876\n",
            "train AUTOENCODER: LOSS 0.044473037965 MAE temp1:0.1027, temp2:0.2309, temp3:0.1096, temp4:0.1459 R2 temp1:0.9810, temp2:0.9112, temp3:0.9791, temp4:0.9387 RMSE temp1:0.131817, temp2:0.304187, temp3:0.140189, temp4:0.198800\n",
            "valid MODEL: LOSS 0.029396326424 MAE X1:0.1013, Y1:0.0330, Z1:0.0849 R2 X1:0.9765, Y1:0.9867, Z1:0.9786 RMSE X1:0.128479, Y1:0.042055, Z1:0.108609\n",
            "valid AUTOENCODER: LOSS 0.045548813704 MAE temp1:0.0799, temp2:0.2308, temp3:0.0996, temp4:0.1459 R2 temp1:0.9725, temp2:0.8929, temp3:0.9653, temp4:0.9387 RMSE temp1:0.105386, temp2:0.297559, temp3:0.133021, temp4:0.198800\n",
            "EPOCH 87/100:\n",
            "Weights of the Ensemble models: [0.32007044553756714, 0.6786316633224487, 0.0012979194289073348]\n",
            "train MODEL: LOSS 0.210152128291 MAE X1:0.1072, Y1:0.0369, Z1:0.1109 R2 X1:0.9819, Y1:0.9927, Z1:0.9793 RMSE X1:0.142234, Y1:0.100418, Z1:0.153607\n",
            "train AUTOENCODER: LOSS 0.043273372936 MAE temp1:0.0993, temp2:0.2285, temp3:0.1063, temp4:0.1438 R2 temp1:0.9820, temp2:0.9126, temp3:0.9799, temp4:0.9380 RMSE temp1:0.127383, temp2:0.301701, temp3:0.136727, temp4:0.199726\n",
            "valid MODEL: LOSS 0.029287757710 MAE X1:0.1013, Y1:0.0331, Z1:0.0849 R2 X1:0.9765, Y1:0.9867, Z1:0.9786 RMSE X1:0.128449, Y1:0.042086, Z1:0.108576\n",
            "valid AUTOENCODER: LOSS 0.045193258673 MAE temp1:0.0810, temp2:0.2260, temp3:0.0988, temp4:0.1438 R2 temp1:0.9716, temp2:0.8962, temp3:0.9647, temp4:0.9380 RMSE temp1:0.107281, temp2:0.292518, temp3:0.133497, temp4:0.199726\n",
            "EPOCH 88/100:\n",
            "Weights of the Ensemble models: [0.27705052495002747, 0.7204321026802063, 0.002517322776839137]\n",
            "train MODEL: LOSS 0.210204459757 MAE X1:0.1075, Y1:0.0371, Z1:0.1114 R2 X1:0.9812, Y1:0.9912, Z1:0.9787 RMSE X1:0.144930, Y1:0.110238, Z1:0.155944\n",
            "train AUTOENCODER: LOSS 0.045696417230 MAE temp1:0.1070, temp2:0.2323, temp3:0.1140, temp4:0.1309 R2 temp1:0.9797, temp2:0.9104, temp3:0.9778, temp4:0.9371 RMSE temp1:0.137277, temp2:0.305645, temp3:0.145469, temp4:0.200547\n",
            "valid MODEL: LOSS 0.029246135472 MAE X1:0.1015, Y1:0.0331, Z1:0.0849 R2 X1:0.9764, Y1:0.9866, Z1:0.9786 RMSE X1:0.128629, Y1:0.042216, Z1:0.108526\n",
            "valid AUTOENCODER: LOSS 0.045252456545 MAE temp1:0.0996, temp2:0.2115, temp3:0.1052, temp4:0.1309 R2 temp1:0.9657, temp2:0.9051, temp3:0.9612, temp4:0.9371 RMSE temp1:0.127220, temp2:0.278417, temp3:0.141818, temp4:0.200547\n",
            "EPOCH 89/100:\n",
            "Weights of the Ensemble models: [0.24623005092144012, 0.7522555589675903, 0.0015144322533160448]\n",
            "train MODEL: LOSS 0.210478603149 MAE X1:0.1074, Y1:0.0370, Z1:0.1112 R2 X1:0.9814, Y1:0.9915, Z1:0.9790 RMSE X1:0.144519, Y1:0.108310, Z1:0.154792\n",
            "train AUTOENCODER: LOSS 0.044899091064 MAE temp1:0.1031, temp2:0.2307, temp3:0.1094, temp4:0.1358 R2 temp1:0.9809, temp2:0.9114, temp3:0.9790, temp4:0.9409 RMSE temp1:0.132226, temp2:0.303761, temp3:0.140625, temp4:0.194474\n",
            "valid MODEL: LOSS 0.029394432114 MAE X1:0.1013, Y1:0.0330, Z1:0.0850 R2 X1:0.9765, Y1:0.9867, Z1:0.9786 RMSE X1:0.128488, Y1:0.042081, Z1:0.108566\n",
            "valid AUTOENCODER: LOSS 0.044426883786 MAE temp1:0.0833, temp2:0.2239, temp3:0.0997, temp4:0.1358 R2 temp1:0.9718, temp2:0.8966, temp3:0.9655, temp4:0.9409 RMSE temp1:0.109017, temp2:0.292278, temp3:0.132568, temp4:0.194474\n",
            "EPOCH 90/100:\n",
            "Weights of the Ensemble models: [0.3344360589981079, 0.6623071432113647, 0.0032568294554948807]\n",
            "train MODEL: LOSS 0.210169175970 MAE X1:0.1072, Y1:0.0366, Z1:0.1112 R2 X1:0.9820, Y1:0.9936, Z1:0.9791 RMSE X1:0.141929, Y1:0.094310, Z1:0.154566\n",
            "train AUTOENCODER: LOSS 0.042651757358 MAE temp1:0.0980, temp2:0.2294, temp3:0.1030, temp4:0.1369 R2 temp1:0.9822, temp2:0.9121, temp3:0.9805, temp4:0.9402 RMSE temp1:0.126651, temp2:0.302546, temp3:0.134294, temp4:0.195594\n",
            "valid MODEL: LOSS 0.029312303576 MAE X1:0.1013, Y1:0.0331, Z1:0.0850 R2 X1:0.9764, Y1:0.9867, Z1:0.9786 RMSE X1:0.128539, Y1:0.042138, Z1:0.108535\n",
            "valid AUTOENCODER: LOSS 0.044704339825 MAE temp1:0.0805, temp2:0.2269, temp3:0.0980, temp4:0.1369 R2 temp1:0.9721, temp2:0.8956, temp3:0.9655, temp4:0.9402 RMSE temp1:0.106278, temp2:0.293624, temp3:0.131898, temp4:0.195594\n",
            "EPOCH 91/100:\n",
            "Weights of the Ensemble models: [0.10468054562807083, 0.8934328556060791, 0.001886590849608183]\n",
            "train MODEL: LOSS 0.210265227984 MAE X1:0.1074, Y1:0.0370, Z1:0.1111 R2 X1:0.9817, Y1:0.9927, Z1:0.9791 RMSE X1:0.143301, Y1:0.100481, Z1:0.154428\n",
            "train AUTOENCODER: LOSS 0.043355943455 MAE temp1:0.1007, temp2:0.2297, temp3:0.1072, temp4:0.1334 R2 temp1:0.9816, temp2:0.9118, temp3:0.9797, temp4:0.9403 RMSE temp1:0.129145, temp2:0.303028, temp3:0.137554, temp4:0.195113\n",
            "valid MODEL: LOSS 0.029366624112 MAE X1:0.1013, Y1:0.0330, Z1:0.0850 R2 X1:0.9765, Y1:0.9867, Z1:0.9786 RMSE X1:0.128475, Y1:0.042065, Z1:0.108660\n",
            "valid AUTOENCODER: LOSS 0.044341153394 MAE temp1:0.0842, temp2:0.2216, temp3:0.0994, temp4:0.1334 R2 temp1:0.9710, temp2:0.8987, temp3:0.9650, temp4:0.9403 RMSE temp1:0.110188, temp2:0.288933, temp3:0.133045, temp4:0.195113\n",
            "EPOCH 92/100:\n",
            "Weights of the Ensemble models: [0.26541024446487427, 0.7327393889427185, 0.0018503968603909016]\n",
            "train MODEL: LOSS 0.267498565567 MAE X1:0.1075, Y1:0.0367, Z1:0.1111 R2 X1:0.9819, Y1:0.9934, Z1:0.9792 RMSE X1:0.142586, Y1:0.095492, Z1:0.153987\n",
            "train AUTOENCODER: LOSS 0.042680673421 MAE temp1:0.0983, temp2:0.2284, temp3:0.1041, temp4:0.1304 R2 temp1:0.9823, temp2:0.9126, temp3:0.9803, temp4:0.9394 RMSE temp1:0.126239, temp2:0.301684, temp3:0.134988, temp4:0.196610\n",
            "valid MODEL: LOSS 0.029334573362 MAE X1:0.1013, Y1:0.0330, Z1:0.0850 R2 X1:0.9765, Y1:0.9867, Z1:0.9786 RMSE X1:0.128390, Y1:0.042075, Z1:0.108686\n",
            "valid AUTOENCODER: LOSS 0.044424308894 MAE temp1:0.0920, temp2:0.2152, temp3:0.1022, temp4:0.1304 R2 temp1:0.9685, temp2:0.9027, temp3:0.9635, temp4:0.9394 RMSE temp1:0.118706, temp2:0.282526, temp3:0.136603, temp4:0.196610\n",
            "EPOCH 93/100:\n",
            "Weights of the Ensemble models: [0.18704307079315186, 0.8111170530319214, 0.001839917153120041]\n",
            "train MODEL: LOSS 0.210190550304 MAE X1:0.1076, Y1:0.0370, Z1:0.1111 R2 X1:0.9816, Y1:0.9920, Z1:0.9791 RMSE X1:0.143635, Y1:0.104975, Z1:0.154546\n",
            "train AUTOENCODER: LOSS 0.045315314745 MAE temp1:0.1031, temp2:0.2313, temp3:0.1084, temp4:0.1294 R2 temp1:0.9808, temp2:0.9110, temp3:0.9790, temp4:0.9381 RMSE temp1:0.132852, temp2:0.304520, temp3:0.140480, temp4:0.198819\n",
            "valid MODEL: LOSS 0.029367296312 MAE X1:0.1014, Y1:0.0330, Z1:0.0850 R2 X1:0.9764, Y1:0.9867, Z1:0.9786 RMSE X1:0.128597, Y1:0.042072, Z1:0.108621\n",
            "valid AUTOENCODER: LOSS 0.045059142491 MAE temp1:0.1005, temp2:0.2117, temp3:0.1069, temp4:0.1294 R2 temp1:0.9658, temp2:0.9049, temp3:0.9615, temp4:0.9381 RMSE temp1:0.127537, temp2:0.278917, temp3:0.141880, temp4:0.198819\n",
            "EPOCH 94/100:\n",
            "Weights of the Ensemble models: [0.2052302062511444, 0.7933194041252136, 0.0014503936981782317]\n",
            "train MODEL: LOSS 0.210301265511 MAE X1:0.1072, Y1:0.0369, Z1:0.1111 R2 X1:0.9817, Y1:0.9928, Z1:0.9791 RMSE X1:0.143080, Y1:0.099549, Z1:0.154326\n",
            "train AUTOENCODER: LOSS 0.045337433957 MAE temp1:0.1072, temp2:0.2329, temp3:0.1135, temp4:0.1299 R2 temp1:0.9799, temp2:0.9100, temp3:0.9780, temp4:0.9397 RMSE temp1:0.136651, temp2:0.306245, temp3:0.144522, temp4:0.196127\n",
            "valid MODEL: LOSS 0.029376007688 MAE X1:0.1014, Y1:0.0331, Z1:0.0850 R2 X1:0.9764, Y1:0.9867, Z1:0.9786 RMSE X1:0.128551, Y1:0.042112, Z1:0.108594\n",
            "valid AUTOENCODER: LOSS 0.044510337309 MAE temp1:0.0960, temp2:0.2140, temp3:0.1050, temp4:0.1299 R2 temp1:0.9676, temp2:0.9031, temp3:0.9630, temp4:0.9397 RMSE temp1:0.122647, temp2:0.281952, temp3:0.138364, temp4:0.196127\n",
            "EPOCH 95/100:\n",
            "Weights of the Ensemble models: [0.4188717007637024, 0.5797001719474792, 0.0014280860777944326]\n",
            "train MODEL: LOSS 0.240140236494 MAE X1:0.1073, Y1:0.0367, Z1:0.1110 R2 X1:0.9820, Y1:0.9935, Z1:0.9793 RMSE X1:0.141908, Y1:0.095046, Z1:0.153831\n",
            "train AUTOENCODER: LOSS 0.044278046116 MAE temp1:0.1019, temp2:0.2295, temp3:0.1091, temp4:0.1325 R2 temp1:0.9810, temp2:0.9122, temp3:0.9790, temp4:0.9404 RMSE temp1:0.131764, temp2:0.302408, temp3:0.140529, temp4:0.195054\n",
            "valid MODEL: LOSS 0.029345644351 MAE X1:0.1014, Y1:0.0331, Z1:0.0850 R2 X1:0.9765, Y1:0.9866, Z1:0.9786 RMSE X1:0.128437, Y1:0.042163, Z1:0.108559\n",
            "valid AUTOENCODER: LOSS 0.044260369900 MAE temp1:0.0897, temp2:0.2175, temp3:0.1020, temp4:0.1325 R2 temp1:0.9697, temp2:0.9007, temp3:0.9644, temp4:0.9404 RMSE temp1:0.116047, temp2:0.285930, temp3:0.134921, temp4:0.195054\n",
            "EPOCH 96/100:\n",
            "Weights of the Ensemble models: [0.20591895282268524, 0.7921620607376099, 0.0019189765444025397]\n",
            "train MODEL: LOSS 0.210278738681 MAE X1:0.1073, Y1:0.0368, Z1:0.1110 R2 X1:0.9819, Y1:0.9935, Z1:0.9792 RMSE X1:0.142268, Y1:0.095173, Z1:0.154213\n",
            "train AUTOENCODER: LOSS 0.045831766941 MAE temp1:0.1088, temp2:0.2327, temp3:0.1148, temp4:0.1336 R2 temp1:0.9792, temp2:0.9101, temp3:0.9774, temp4:0.9375 RMSE temp1:0.139422, temp2:0.306144, temp3:0.146939, temp4:0.199867\n",
            "valid MODEL: LOSS 0.029280140566 MAE X1:0.1013, Y1:0.0331, Z1:0.0850 R2 X1:0.9765, Y1:0.9867, Z1:0.9786 RMSE X1:0.128506, Y1:0.042077, Z1:0.108581\n",
            "valid AUTOENCODER: LOSS 0.044830836642 MAE temp1:0.0904, temp2:0.2155, temp3:0.1000, temp4:0.1336 R2 temp1:0.9683, temp2:0.9030, temp3:0.9630, temp4:0.9375 RMSE temp1:0.117991, temp2:0.281892, temp3:0.137003, temp4:0.199867\n",
            "EPOCH 97/100:\n",
            "Weights of the Ensemble models: [0.28776657581329346, 0.7111092209815979, 0.0011241781758144498]\n",
            "train MODEL: LOSS 0.210388303764 MAE X1:0.1075, Y1:0.0372, Z1:0.1114 R2 X1:0.9809, Y1:0.9901, Z1:0.9785 RMSE X1:0.146247, Y1:0.116802, Z1:0.156575\n",
            "train AUTOENCODER: LOSS 0.045190477083 MAE temp1:0.1063, temp2:0.2322, temp3:0.1133, temp4:0.1311 R2 temp1:0.9799, temp2:0.9106, temp3:0.9779, temp4:0.9407 RMSE temp1:0.136536, temp2:0.305281, temp3:0.145093, temp4:0.194486\n",
            "valid MODEL: LOSS 0.029340913018 MAE X1:0.1013, Y1:0.0331, Z1:0.0851 R2 X1:0.9765, Y1:0.9867, Z1:0.9786 RMSE X1:0.128439, Y1:0.042086, Z1:0.108640\n",
            "valid AUTOENCODER: LOSS 0.044219498308 MAE temp1:0.0872, temp2:0.2194, temp3:0.1012, temp4:0.1311 R2 temp1:0.9703, temp2:0.8999, temp3:0.9646, temp4:0.9407 RMSE temp1:0.113281, temp2:0.287023, temp3:0.134278, temp4:0.194486\n",
            "EPOCH 98/100:\n",
            "Weights of the Ensemble models: [0.27736783027648926, 0.7198052406311035, 0.0028269654139876366]\n",
            "train MODEL: LOSS 0.210579114125 MAE X1:0.1075, Y1:0.0370, Z1:0.1113 R2 X1:0.9813, Y1:0.9915, Z1:0.9790 RMSE X1:0.144617, Y1:0.108139, Z1:0.154855\n",
            "train AUTOENCODER: LOSS 0.044898793462 MAE temp1:0.1042, temp2:0.2314, temp3:0.1107, temp4:0.1514 R2 temp1:0.9805, temp2:0.9111, temp3:0.9787, temp4:0.9376 RMSE temp1:0.134199, temp2:0.304392, temp3:0.141930, temp4:0.201113\n",
            "valid MODEL: LOSS 0.029333262060 MAE X1:0.1012, Y1:0.0331, Z1:0.0849 R2 X1:0.9765, Y1:0.9866, Z1:0.9786 RMSE X1:0.128412, Y1:0.042202, Z1:0.108504\n",
            "valid AUTOENCODER: LOSS 0.046390049016 MAE temp1:0.0808, temp2:0.2352, temp3:0.1021, temp4:0.1514 R2 temp1:0.9724, temp2:0.8902, temp3:0.9648, temp4:0.9376 RMSE temp1:0.106245, temp2:0.301532, temp3:0.135010, temp4:0.201113\n",
            "EPOCH 99/100:\n",
            "Weights of the Ensemble models: [0.2585366666316986, 0.7385872602462769, 0.0028760326094925404]\n",
            "train MODEL: LOSS 0.210384698825 MAE X1:0.1074, Y1:0.0367, Z1:0.1111 R2 X1:0.9816, Y1:0.9922, Z1:0.9791 RMSE X1:0.143415, Y1:0.104041, Z1:0.154455\n",
            "train AUTOENCODER: LOSS 0.045051691212 MAE temp1:0.1050, temp2:0.2315, temp3:0.1117, temp4:0.1332 R2 temp1:0.9802, temp2:0.9109, temp3:0.9782, temp4:0.9396 RMSE temp1:0.135515, temp2:0.304635, temp3:0.143918, temp4:0.196300\n",
            "valid MODEL: LOSS 0.029283027021 MAE X1:0.1013, Y1:0.0330, Z1:0.0850 R2 X1:0.9765, Y1:0.9867, Z1:0.9786 RMSE X1:0.128467, Y1:0.042063, Z1:0.108600\n",
            "valid AUTOENCODER: LOSS 0.044438865322 MAE temp1:0.0859, temp2:0.2195, temp3:0.0997, temp4:0.1332 R2 temp1:0.9703, temp2:0.9002, temp3:0.9644, temp4:0.9396 RMSE temp1:0.112342, temp2:0.286552, temp3:0.134139, temp4:0.196300\n",
            "EPOCH 100/100:\n",
            "Weights of the Ensemble models: [0.16267509758472443, 0.8364622592926025, 0.000862654356751591]\n",
            "train MODEL: LOSS 0.210149131565 MAE X1:0.1076, Y1:0.0368, Z1:0.1114 R2 X1:0.9816, Y1:0.9931, Z1:0.9789 RMSE X1:0.143613, Y1:0.097997, Z1:0.155251\n",
            "train AUTOENCODER: LOSS 0.044957302451 MAE temp1:0.1032, temp2:0.2303, temp3:0.1098, temp4:0.1466 R2 temp1:0.9810, temp2:0.9118, temp3:0.9790, temp4:0.9383 RMSE temp1:0.132038, temp2:0.303142, temp3:0.140612, temp4:0.199526\n",
            "valid MODEL: LOSS 0.029329788011 MAE X1:0.1014, Y1:0.0330, Z1:0.0851 R2 X1:0.9764, Y1:0.9867, Z1:0.9785 RMSE X1:0.128528, Y1:0.042064, Z1:0.108777\n",
            "valid AUTOENCODER: LOSS 0.045321963441 MAE temp1:0.0801, temp2:0.2281, temp3:0.0994, temp4:0.1466 R2 temp1:0.9723, temp2:0.8944, temp3:0.9652, temp4:0.9383 RMSE temp1:0.105932, temp2:0.295343, temp3:0.133121, temp4:0.199526\n"
          ]
        }
      ],
      "source": [
        "if hyper_parameters['pretrain']:\n",
        "    model.load('./results/training_2025-02-25_17-35/autoencoder.pt',autoencoder=hyper_parameters['pretrain'])\n",
        "\n",
        "train(\n",
        "    num_epochs=hyper_parameters['num_epochs'],\n",
        "    loss_fn=loss_fn,\n",
        "    model=model,\n",
        "    optimizer=optimizer,\n",
        "    scheduler=scheduler,\n",
        "    training_dataloader=loaderTrain,\n",
        "    validation_dataloader=loaderVal,\n",
        "    hyperparams=hyper_parameters,\n",
        "    model_dict = ensemble_model,\n",
        "    autoencoder_dict=autoencoder_dict,\n",
        "    complete=hyper_parameters['ensemble'],\n",
        "    autoencoder_train=autoencoder_train\n",
        ")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.20"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
