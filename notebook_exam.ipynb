{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3O4mXmBol0t"
      },
      "source": [
        "# IMPORT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "try:\n",
        "    import google.colab # type: ignore\n",
        "    colab = True\n",
        "except:\n",
        "    colab = False\n",
        "\n",
        "if colab:\n",
        "    !git clone \"https://github.com/cybernetic-m/eai-project.git\" # type: ignore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "9gQw18CXol0v"
      },
      "outputs": [],
      "source": [
        "# Model\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torch import optim\n",
        "from torch.optim.lr_scheduler import ExponentialLR \n",
        "\n",
        "# Others\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        " \n",
        "# Our files\n",
        "if colab:\n",
        "    sys.path.append('/content/eai-project/training')\n",
        "    sys.path.append('/content/eai-project/preprocessing')\n",
        "    sys.path.append('/content/eai-project/dataset')\n",
        "    sys.path.append('/content/eai-project/utils')\n",
        "    sys.path.append('/content/eai-project/models')\n",
        "    sys.path.append('/content/eai-project/testing')\n",
        "    from train import train\n",
        "    from preprocessing import *\n",
        "    from thermal_dataset import thermal_dataset \n",
        "    from utils import *\n",
        "    from complete_model import complete_model \n",
        "    from lstm_only import lstm_only\n",
        "    from testing import test\n",
        "    prefix = '/content'\n",
        "        \n",
        "else:\n",
        "    from training.train import train\n",
        "    from preprocessing.preprocessing import *\n",
        "    from dataset.thermal_dataset import thermal_dataset\n",
        "    from utils.csv_utils import *\n",
        "    from models.complete_model import complete_model\n",
        "    from models.lstm_only import lstm_only\n",
        "    from testing.test import test\n",
        "    prefix = '.'\n",
        "    \n",
        "pd.set_option('display.max_columns', None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "hyper_parameters = {'num_epochs': 30,\n",
        "                    'batch_size': 256,\n",
        "                    'hidden_dim' : 3,\n",
        "                    'lr': 0.000001,\n",
        "                    'mode': 'auto-weighted', #average, mlp, linear, auto-weighted\n",
        "                    'extractor_type': 'lstm', #lstm, rnn\n",
        "                    'ensemble': True,\n",
        "                    'timesteps': 170,\n",
        "                    'window_size':25,\n",
        "                    'norm':True,\n",
        "                    'file':1\n",
        "                        }\n",
        "\n",
        "ensemble_model = {'mlp': [{'layer_dim_list': [3,4,3]}],  \n",
        "              'ARIMA': [{'p': 2, 'd': 0, 'q': 2, 'ps': 0, 'ds': 0, 'qs': 0, 's': 1}],\n",
        "              'linear_regressor': [{'in_features': 3, 'out_features': 3}]\n",
        "              }\n",
        "\n",
        "ensemble_model1 = { \n",
        "              'ARIMA': [{'p': 2, 'd': 0, 'q': 2, 'ps': 0, 'ds': 0, 'qs': 0, 's': 1}],\n",
        "              'linear_regressor': [{'in_features': 3, 'out_features': 3}, {'in_features': 3, 'out_features': 3}]\n",
        "              }\n",
        "\n",
        "ensemble_model2 = {\n",
        "              'mlp': [{'layer_dim_list': [3,4,3]}],  \n",
        "              'linear_regressor': [{'in_features': 3, 'out_features': 3}, {'in_features': 3, 'out_features': 3}]\n",
        "              }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "skip = False\n",
        "test_flag = True\n",
        "#if os.path.exists(prefix+'/X'+str(hyper_parameters['window_size'])+'testing'+str(hyper_parameters['file'])+str(hyper_parameters['norm'])+'.npy') and os.path.exists(prefix+'/X'+str(hyper_parameters['window_size'])+'training'+str(hyper_parameters['file'])+str(hyper_parameters['norm'])+'.npy'):\n",
        "#    skip = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Reproducibility and Device Setting**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set a seed for reproducibility purposes\n",
        "seed = 46\n",
        "torch.manual_seed(seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "np.random.seed(seed)\n",
        "\n",
        "# Set the device (cuda for Nvidia GPUs, mps for M1, M2 .. Apple Silicon)\n",
        "if torch.cuda.is_available():\n",
        "    device = \"cuda\"\n",
        "elif torch.backends.mps.is_available():\n",
        "    device = \"mps\"\n",
        "else:\n",
        "    device = \"cpu\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFQrCrM-ol0w"
      },
      "source": [
        "# DATASET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1mHN7T9Rol0x",
        "outputId": "6d8b8eef-3135-4b49-f113-9ac4548ea7aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CSV file already downloaded!\n",
            "CSV file already unzipped!\n"
          ]
        }
      ],
      "source": [
        "link_zipped_csv = 'https://drive.google.com/file/d/1MssQF4pI_rZqiiDBP4XaLTT1ZaN6ykLm/view?usp=drive_link'\n",
        "gdrive_link = 'https://drive.google.com/uc?id='\n",
        "csv_dir = './csv'\n",
        "zipped_file = './csv.zip'\n",
        "\n",
        "download_csv(\n",
        "    link_zipped_csv,\n",
        "    gdrive_link,\n",
        "    zipped_file\n",
        ")\n",
        "\n",
        "unzip_csv(\n",
        "    zipped_file,\n",
        "    csv_dir,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "eKLx-ldvGxvs"
      },
      "outputs": [],
      "source": [
        "if not skip:\n",
        "\n",
        "    path = '/content/csv/thermal_drift_features_lab_05_02.csv'\n",
        "\n",
        "    # Read all the CSV files containing the Temperatures\n",
        "    features_1 = pd.read_csv(os.path.join(prefix,'csv/thermal_drift_features_lab_05_02.csv'))\n",
        "    features_2 = pd.read_csv(os.path.join(prefix, 'csv/thermal_drift_features_lab_05_03.csv'))\n",
        "    features_3 = pd.read_csv(os.path.join(prefix,'csv/thermal_drift_features_lab_05_04.csv'))\n",
        "    features_4 = pd.read_csv(os.path.join(prefix,'csv/thermal_drift_features_lab_05_05.csv'))\n",
        "    features_5 = pd.read_csv(os.path.join(prefix,'csv/thermal_drift_features_lab_05_06.csv'))\n",
        "\n",
        "    # Read all the CSV files containing the X1, Y1, Z1 \n",
        "    targets_1 = pd.read_csv(os.path.join(prefix,'csv/thermal_drift_targets_lab_05_02.csv'))\n",
        "    targets_2 = pd.read_csv(os.path.join(prefix,'csv/thermal_drift_targets_lab_05_03.csv'))\n",
        "    targets_3 = pd.read_csv(os.path.join(prefix,'csv/thermal_drift_targets_lab_05_04.csv'))\n",
        "    targets_4 = pd.read_csv(os.path.join(prefix,'csv/thermal_drift_targets_lab_05_05.csv'))\n",
        "    targets_5 = pd.read_csv(os.path.join(prefix,'csv/thermal_drift_targets_lab_05_06.csv'))\n",
        "    \n",
        "    # Normalized columns files for X1, Y1, Z1 for the plot\n",
        "    targets_norm_1= normalize_columns(targets_1, ['X1','Y1','Z1'], -1, 1)\n",
        "    targets_norm_2= normalize_columns(targets_2, ['X1','Y1','Z1'], -1, 1)\n",
        "    targets_norm_3= normalize_columns(targets_3, ['X1','Y1','Z1'], -1, 1)\n",
        "    targets_norm_4= normalize_columns(targets_4, ['X1','Y1','Z1'], -1, 1)\n",
        "    targets_norm_5= normalize_columns(targets_5, ['X1','Y1','Z1'], -1, 1)\n",
        "    \n",
        "    features_norm_1= normalize_columns(features_1, ['Temp Sensor 1','Temp Sensor 2', 'Temp Sensor 3', 'Temp Sensor 4'], -1, 1)\n",
        "    features_norm_2= normalize_columns(features_2, ['Temp Sensor 1','Temp Sensor 2', 'Temp Sensor 3', 'Temp Sensor 4'], -1, 1)\n",
        "    features_norm_3= normalize_columns(features_3, ['Temp Sensor 1','Temp Sensor 2', 'Temp Sensor 3', 'Temp Sensor 4'], -1, 1)\n",
        "    features_norm_4= normalize_columns(features_4, ['Temp Sensor 1','Temp Sensor 2', 'Temp Sensor 3', 'Temp Sensor 4'], -1, 1)\n",
        "    features_norm_5= normalize_columns(features_5, ['Temp Sensor 1','Temp Sensor 2', 'Temp Sensor 3', 'Temp Sensor 4'], -1, 1)\n",
        "\n",
        "    # Create a list of features and targets to use for the next drop\n",
        "    if hyper_parameters['norm']:\n",
        "        features = [features_norm_1, features_norm_2, features_norm_3, features_norm_4, features_norm_5]\n",
        "        targets = [targets_norm_1,targets_norm_2,targets_norm_3,targets_norm_4,targets_norm_4]\n",
        "    else:\n",
        "        features = [features_1, features_2, features_3, features_4, features_5]\n",
        "        targets = [targets_1,targets_2,targets_3,targets_4,targets_5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "if not skip:\n",
        "    for feature, target in zip(features, targets):\n",
        "        feature.drop([\n",
        "            \"name\", \"tags\",\n",
        "            \"2\\\"Tray1 Vacuum Sensor\", \"2\\\"Tray2 Vacuum Sensor\", \"2\\\"Tray3 Vacuum Sensor\",\n",
        "            \"Avg Oven Temperature\", \"Chuck Temp [Cdeg]\", \"Chuck Temp2 [Cdeg]\",\n",
        "            \"Chuck1 Vacuum Sensor\", \"Contrast\", \"Device State\",\n",
        "            \"Dispenser1 Pressure Sensor\", \"Machine Room Temp\", \"Main Air\", \"Main Vacuum\",\n",
        "            \"Oven Temperature\", \"PE_Rx\", \"PE_Ry\", \"PE_Rz\", \"PE_X1\", \"PE_Y1\", \"PE_Z1\",\n",
        "            \"PUT1 Flow Sensor\", \"PUT2 Flow Sensor1\", \"PUT2 Flow Sensor2\",\n",
        "            \"PUT2 Flow Sensor3\", \"PUT2 Flow Sensor4\", \"PUT2 Flow Sensor5\",\n",
        "            \"Photodiode\", \"Pixel Power\", \"Preciser1 Vacuum Sensor\",\n",
        "            \"Tec FIB1 Holder\", \"Tec FIB1 Plate\", \"Tec FIB2 Holder\", \"Tec FIB2 Plate\",\n",
        "            \"Torque11\",\"Torque2\",\"Torque3\",\"Torque4\",\"Torque5\",\"Torque6\"\n",
        "        ], axis=1, inplace=True)\n",
        "        if 'name' in target.keys() and 'tags' in target.keys():\n",
        "\n",
        "            target.drop(['name', 'tags'], axis=1, inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "qUZH1JpDfNY0",
        "outputId": "694acf4b-ac9a-401f-f4ef-d6b8105ebf1b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                        time  Temp Sensor 1  Temp Sensor 2  Temp Sensor 3  \\\n",
            "0        1714687200035019000       0.901639       0.627907       0.935484   \n",
            "1        1714687200090637000       0.901639       0.627907       0.935484   \n",
            "2        1714687200177338000       0.901639       0.627907       0.935484   \n",
            "3        1714687200228517000       0.901639       0.627907       0.935484   \n",
            "4        1714687200279903000       0.901639       0.627907       0.935484   \n",
            "...                      ...            ...            ...            ...   \n",
            "1248011  1714773599360645000       0.672131       0.674419       0.483871   \n",
            "1248012  1714773599473292000       0.672131       0.674419       0.483871   \n",
            "1248013  1714773599580569000       0.672131       0.674419       0.483871   \n",
            "1248014  1714773599762038000       0.672131       0.674419       0.483871   \n",
            "1248015  1714773599869383000       0.672131       0.674419       0.483871   \n",
            "\n",
            "         Temp Sensor 4  \n",
            "0             0.911765  \n",
            "1             0.911765  \n",
            "2             0.911765  \n",
            "3             0.911765  \n",
            "4             0.911765  \n",
            "...                ...  \n",
            "1248011       0.294118  \n",
            "1248012       0.294118  \n",
            "1248013       0.294118  \n",
            "1248014       0.294118  \n",
            "1248015       0.294118  \n",
            "\n",
            "[1248016 rows x 5 columns]\n"
          ]
        }
      ],
      "source": [
        "if not skip:\n",
        "    print(features[1]) # Print the features_1 table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "OtsO4hF1fHUU",
        "outputId": "3b3e33b6-a0eb-474b-814a-67338bee9fdd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                      time        X1        Y1        Z1\n",
            "0      1714687207558354000  0.877249       NaN       NaN\n",
            "1      1714687207564731000       NaN -0.876387       NaN\n",
            "2      1714687207615696000       NaN       NaN  0.698630\n",
            "3      1714687218845182000  0.870077       NaN       NaN\n",
            "4      1714687218860796000       NaN -0.877755       NaN\n",
            "...                    ...       ...       ...       ...\n",
            "23104  1714773578301848000       NaN  0.955317       NaN\n",
            "23105  1714773578313892000       NaN       NaN -0.287671\n",
            "23106  1714773589691570000 -0.004000       NaN       NaN\n",
            "23107  1714773589700556000       NaN  0.944901       NaN\n",
            "23108  1714773589724371000       NaN       NaN -0.315068\n",
            "\n",
            "[23109 rows x 4 columns]\n"
          ]
        }
      ],
      "source": [
        "if not skip:\n",
        "\n",
        "    print(targets[1]) # Print the target_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "H7L8dLyMmesB"
      },
      "outputs": [],
      "source": [
        "if not skip:\n",
        "    # Put X1, Y1, Z1 on the same row of X1 eliminating the NAN values\n",
        "    fixed_targets = [] # Create a list of target in which we put X1, Y1, Z1 in the same row\n",
        "    for target in targets:\n",
        "        fixed_targets.append(transform_dataframe(target)) # iterate over target_1,2,3 ... and append in fixed_targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "23LmYWUfmqDM",
        "outputId": "fc9873f7-b53c-4dbc-a2bd-b0cf9fab7f2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              time        X1        Y1        Z1\n",
            "0     1.714687e+18  0.877249 -0.876387  0.698630\n",
            "1     1.714687e+18  0.870077 -0.877755  0.726027\n",
            "2     1.714687e+18  0.862210 -0.874809  0.753425\n",
            "3     1.714687e+18  0.882294 -0.881475  0.753425\n",
            "4     1.714687e+18  0.872267 -0.881519  0.726027\n",
            "...            ...       ...       ...       ...\n",
            "7698  1.714774e+18  0.031200  0.951937 -0.260274\n",
            "7699  1.714774e+18  0.006015  0.966296 -0.287671\n",
            "7700  1.714774e+18  0.023985  0.957713 -0.260274\n",
            "7701  1.714774e+18  0.011520  0.955317 -0.287671\n",
            "7702  1.714774e+18 -0.004000  0.944901 -0.315068\n",
            "\n",
            "[7703 rows x 4 columns]\n"
          ]
        }
      ],
      "source": [
        "if not skip:\n",
        "\n",
        "    print(fixed_targets[1]) # Print the fixed_target_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "DOVEQQeQr36x"
      },
      "outputs": [],
      "source": [
        "if not skip:\n",
        "    # Merge of targets with features in one single dataframe\n",
        "    complete_numbers_list = [] # List of the table with columns that are numbers (0,1,2..) in which we unify both features and targets merging on closest time row\n",
        "    for fixed_target, feature in zip(fixed_targets, features):\n",
        "        complete_numbers_list.append(merge_on_closest_time(fixed_target.reset_index(), feature.reset_index()))\n",
        "\n",
        "    trainig_number_list = []\n",
        "    testing_number_list = []\n",
        "    for i in range(len(complete_numbers_list)):\n",
        "        part_numbers_list = complete_numbers_list[:i] + complete_numbers_list[i+1:]\n",
        "        trainig_number_list.append(pd.concat(part_numbers_list))\n",
        "        testing_number_list.append(complete_numbers_list[i])\n",
        "        \n",
        "    complete_numbers_dataframe = pd.concat(complete_numbers_list)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[        0                             1         2         3         4   \\\n",
            "0        0 2024-05-02 09:00:01.106507008 -1.000000  0.736636  0.177570   \n",
            "1        1 2024-05-02 09:00:12.382008064 -0.981332  0.687808  0.177570   \n",
            "2        2 2024-05-02 09:00:23.632736000 -0.945775  0.688676  0.140187   \n",
            "3        3 2024-05-02 09:00:34.970393088 -0.929981  0.667533  0.102804   \n",
            "4        4 2024-05-02 09:00:46.143995904 -0.905817  0.700378  0.028037   \n",
            "...    ...                           ...       ...       ...       ...   \n",
            "4166  4166 2024-05-02 21:59:11.262568960 -0.121050 -0.919412 -0.906542   \n",
            "4167  4167 2024-05-02 21:59:22.587275008 -0.129462 -0.926667 -0.981308   \n",
            "4168  4168 2024-05-02 21:59:33.874593024 -0.164806 -0.904891 -0.962617   \n",
            "4169  4169 2024-05-02 21:59:45.187085056 -0.131839 -0.894467 -0.962617   \n",
            "4170  4170 2024-05-02 21:59:56.406018048 -0.117183 -0.916946 -0.981308   \n",
            "\n",
            "          5                          6         7         8         9        10  \n",
            "0          7 2024-05-02 09:00:01.084386  0.037037 -0.135135 -0.135135 -0.56250  \n",
            "1        116 2024-05-02 09:00:12.370171  0.037037 -0.027027 -0.162162 -0.53125  \n",
            "2        224 2024-05-02 09:00:23.593553  0.037037  0.081081 -0.135135 -0.53125  \n",
            "3        394 2024-05-02 09:00:34.913803  0.061728 -0.189189 -0.162162 -0.56250  \n",
            "4        513 2024-05-02 09:00:46.071475 -0.012346 -0.369369 -0.135135 -0.59375  \n",
            "...      ...                        ...       ...       ...       ...      ...  \n",
            "4166  663118 2024-05-02 21:59:11.322660 -0.777778 -0.657658 -0.594595 -0.62500  \n",
            "4167  663306 2024-05-02 21:59:22.566420 -0.802469 -0.657658 -0.621622 -0.59375  \n",
            "4168  663496 2024-05-02 21:59:33.824338 -0.802469 -0.621622 -0.648649 -0.59375  \n",
            "4169  663690 2024-05-02 21:59:45.091467 -0.777778 -0.693694 -0.594595 -0.62500  \n",
            "4170  663883 2024-05-02 21:59:56.393854 -0.777778 -0.603604 -0.648649 -0.59375  \n",
            "\n",
            "[4171 rows x 11 columns],         0                             1         2         3         4   \\\n",
            "0        0 2024-05-02 22:00:07.558353920  0.877249 -0.876387  0.698630   \n",
            "1        1 2024-05-02 22:00:18.845181952  0.870077 -0.877755  0.726027   \n",
            "2        2 2024-05-02 22:00:30.068317952  0.862210 -0.874809  0.753425   \n",
            "3        3 2024-05-02 22:00:41.120892928  0.882294 -0.881475  0.753425   \n",
            "4        4 2024-05-02 22:00:52.412800000  0.872267 -0.881519  0.726027   \n",
            "...    ...                           ...       ...       ...       ...   \n",
            "7698  7698 2024-05-03 21:59:04.562355968  0.031200  0.951937 -0.260274   \n",
            "7699  7699 2024-05-03 21:59:15.860919040  0.006015  0.966296 -0.287671   \n",
            "7700  7700 2024-05-03 21:59:27.268246016  0.023985  0.957713 -0.260274   \n",
            "7701  7701 2024-05-03 21:59:38.297178880  0.011520  0.955317 -0.287671   \n",
            "7702  7702 2024-05-03 21:59:49.691569920 -0.004000  0.944901 -0.315068   \n",
            "\n",
            "           5                          6         7         8         9   \\\n",
            "0         126 2024-05-02 22:00:07.503343  0.868852  0.558140  0.935484   \n",
            "1         313 2024-05-02 22:00:18.791876  0.868852  0.441860  0.967742   \n",
            "2         504 2024-05-02 22:00:29.999573  0.868852  0.465116  1.000000   \n",
            "3         698 2024-05-02 22:00:41.067291  0.868852  0.534884  0.967742   \n",
            "4         881 2024-05-02 22:00:52.377394  0.868852  0.558140  0.967742   \n",
            "...       ...                        ...       ...       ...       ...   \n",
            "7698  1247452 2024-05-03 21:59:04.509883  0.770492  0.697674  0.516129   \n",
            "7699  1247582 2024-05-03 21:59:15.811676  0.737705  0.697674  0.483871   \n",
            "7700  1247695 2024-05-03 21:59:27.276122  0.737705  0.651163  0.483871   \n",
            "7701  1247803 2024-05-03 21:59:38.287447  0.737705  0.651163  0.516129   \n",
            "7702  1247914 2024-05-03 21:59:49.637146  0.704918  0.674419  0.516129   \n",
            "\n",
            "            10  \n",
            "0     0.970588  \n",
            "1     0.941176  \n",
            "2     0.911765  \n",
            "3     0.941176  \n",
            "4     0.941176  \n",
            "...        ...  \n",
            "7698  0.294118  \n",
            "7699  0.323529  \n",
            "7700  0.264706  \n",
            "7701  0.323529  \n",
            "7702  0.264706  \n",
            "\n",
            "[7703 rows x 11 columns],         0                             1         2         3         4   \\\n",
            "0        0 2024-05-03 22:00:00.806608896 -0.964673  0.770367 -0.161290   \n",
            "1        1 2024-05-03 22:00:12.139475968 -0.969318  0.772216 -0.193548   \n",
            "2        2 2024-05-03 22:00:23.436060928 -0.963659  0.760225 -0.193548   \n",
            "3        3 2024-05-03 22:00:34.574426880 -1.000000  0.785506 -0.225806   \n",
            "4        4 2024-05-03 22:00:45.872439040 -0.967534  0.767182 -0.258065   \n",
            "...    ...                           ...       ...       ...       ...   \n",
            "7701  7701 2024-05-04 21:59:04.890872064  0.883855 -0.006777  0.129032   \n",
            "7702  7702 2024-05-04 21:59:16.392517120  0.866557 -0.004007  0.161290   \n",
            "7703  7703 2024-05-04 21:59:27.605668096  0.833310 -0.003034  0.193548   \n",
            "7704  7704 2024-05-04 21:59:38.756178944  0.835042 -0.022488  0.161290   \n",
            "7705  7705 2024-05-04 21:59:49.924619008  0.852728 -0.026009  0.129032   \n",
            "\n",
            "           5                          6         7         8         9   \\\n",
            "0           4 2024-05-03 22:00:00.733662 -0.230769  0.010309 -0.214286   \n",
            "1         113 2024-05-03 22:00:12.123842 -0.230769  0.030928 -0.250000   \n",
            "2         222 2024-05-03 22:00:23.422349 -0.230769  0.113402 -0.285714   \n",
            "3         330 2024-05-03 22:00:34.537499 -0.169231  0.113402 -0.214286   \n",
            "4         439 2024-05-03 22:00:45.826007 -0.200000  0.154639 -0.285714   \n",
            "...       ...                        ...       ...       ...       ...   \n",
            "7701  1220857 2024-05-04 21:59:04.945278  0.692308  0.752577  0.857143   \n",
            "7702  1221059 2024-05-04 21:59:16.386339  0.692308  0.670103  0.892857   \n",
            "7703  1221256 2024-05-04 21:59:27.568396  0.692308  0.505155  0.892857   \n",
            "7704  1221458 2024-05-04 21:59:38.694467  0.630769  0.505155  0.857143   \n",
            "7705  1221654 2024-05-04 21:59:49.863334  0.630769  0.525773  0.821429   \n",
            "\n",
            "            10  \n",
            "0    -0.416667  \n",
            "1    -0.458333  \n",
            "2    -0.500000  \n",
            "3    -0.500000  \n",
            "4    -0.458333  \n",
            "...        ...  \n",
            "7701  0.833333  \n",
            "7702  0.833333  \n",
            "7703  0.833333  \n",
            "7704  0.916667  \n",
            "7705  0.875000  \n",
            "\n",
            "[7706 rows x 11 columns],         0                             1         2         3         4   \\\n",
            "0        0 2024-05-04 22:00:00.978973952  0.806544 -0.112016  0.820896   \n",
            "1        1 2024-05-04 22:00:12.289274112  0.853903 -0.111010  0.820896   \n",
            "2        2 2024-05-04 22:00:23.554449920  0.851871 -0.120305  0.820896   \n",
            "3        3 2024-05-04 22:00:34.724033024  0.900468 -0.130772  0.820896   \n",
            "4        4 2024-05-04 22:00:45.985085952  0.887881 -0.115704  0.791045   \n",
            "...    ...                           ...       ...       ...       ...   \n",
            "7705  7705 2024-05-05 21:59:04.667956992  0.133007 -0.331885  0.522388   \n",
            "7706  7706 2024-05-05 21:59:15.946153984  0.148633 -0.334070  0.582090   \n",
            "7707  7707 2024-05-05 21:59:27.116512000  0.177016 -0.346153  0.582090   \n",
            "7708  7708 2024-05-05 21:59:38.566606080  0.116749 -0.339384  0.552239   \n",
            "7709  7709 2024-05-05 21:59:49.873264128  0.111034 -0.374823  0.552239   \n",
            "\n",
            "           5                          6         7         8         9   \\\n",
            "0          10 2024-05-04 22:00:00.984446  0.639344  0.474747  0.647059   \n",
            "1         208 2024-05-04 22:00:12.253526  0.672131  0.535354  0.725490   \n",
            "2         398 2024-05-04 22:00:23.494861  0.737705  0.515152  0.725490   \n",
            "3         585 2024-05-04 22:00:34.671760  0.704918  0.535354  0.686275   \n",
            "4         780 2024-05-04 22:00:46.006695  0.704918  0.595960  0.686275   \n",
            "...       ...                        ...       ...       ...       ...   \n",
            "7705  1248196 2024-05-05 21:59:04.678878  0.114754  0.393939  0.098039   \n",
            "7706  1248302 2024-05-05 21:59:15.918328  0.114754  0.373737  0.098039   \n",
            "7707  1248409 2024-05-05 21:59:27.131349  0.114754  0.353535  0.098039   \n",
            "7708  1248520 2024-05-05 21:59:38.501826  0.049180  0.252525  0.058824   \n",
            "7709  1248628 2024-05-05 21:59:49.884184 -0.016393  0.252525 -0.019608   \n",
            "\n",
            "            10  \n",
            "0     0.727273  \n",
            "1     0.727273  \n",
            "2     0.772727  \n",
            "3     0.772727  \n",
            "4     0.772727  \n",
            "...        ...  \n",
            "7705  0.181818  \n",
            "7706  0.045455  \n",
            "7707  0.000000  \n",
            "7708  0.045455  \n",
            "7709  0.045455  \n",
            "\n",
            "[7710 rows x 11 columns],         0                             1         2         3         4   5   \\\n",
            "0        0 2024-05-04 22:00:00.978973952  0.806544 -0.112016  0.820896   0   \n",
            "1        1 2024-05-04 22:00:12.289274112  0.853903 -0.111010  0.820896   0   \n",
            "2        2 2024-05-04 22:00:23.554449920  0.851871 -0.120305  0.820896   0   \n",
            "3        3 2024-05-04 22:00:34.724033024  0.900468 -0.130772  0.820896   0   \n",
            "4        4 2024-05-04 22:00:45.985085952  0.887881 -0.115704  0.791045   0   \n",
            "...    ...                           ...       ...       ...       ...  ..   \n",
            "7705  7705 2024-05-05 21:59:04.667956992  0.133007 -0.331885  0.522388   0   \n",
            "7706  7706 2024-05-05 21:59:15.946153984  0.148633 -0.334070  0.582090   0   \n",
            "7707  7707 2024-05-05 21:59:27.116512000  0.177016 -0.346153  0.582090   0   \n",
            "7708  7708 2024-05-05 21:59:38.566606080  0.116749 -0.339384  0.552239   0   \n",
            "7709  7709 2024-05-05 21:59:49.873264128  0.111034 -0.374823  0.552239   0   \n",
            "\n",
            "                             6         7         8         9     10  \n",
            "0    2024-05-05 22:00:00.016189  0.470588  0.285714  0.703704  0.92  \n",
            "1    2024-05-05 22:00:00.016189  0.470588  0.285714  0.703704  0.92  \n",
            "2    2024-05-05 22:00:00.016189  0.470588  0.285714  0.703704  0.92  \n",
            "3    2024-05-05 22:00:00.016189  0.470588  0.285714  0.703704  0.92  \n",
            "4    2024-05-05 22:00:00.016189  0.470588  0.285714  0.703704  0.92  \n",
            "...                         ...       ...       ...       ...   ...  \n",
            "7705 2024-05-05 22:00:00.016189  0.470588  0.285714  0.703704  0.92  \n",
            "7706 2024-05-05 22:00:00.016189  0.470588  0.285714  0.703704  0.92  \n",
            "7707 2024-05-05 22:00:00.016189  0.470588  0.285714  0.703704  0.92  \n",
            "7708 2024-05-05 22:00:00.016189  0.470588  0.285714  0.703704  0.92  \n",
            "7709 2024-05-05 22:00:00.016189  0.470588  0.285714  0.703704  0.92  \n",
            "\n",
            "[7710 rows x 11 columns]]\n"
          ]
        }
      ],
      "source": [
        "if not skip: \n",
        "    print(complete_numbers_list) # Print of one example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "m39ldRHjsbJH"
      },
      "outputs": [],
      "source": [
        "if not skip:\n",
        "\n",
        "    complete = complete_numbers_dataframe.rename(columns={\n",
        "        0: 'id',\n",
        "        1: 'time',\n",
        "        2: 'X1',\n",
        "        3: 'Y1',\n",
        "        4: 'Z1',\n",
        "        5: 'to_remove',\n",
        "        6: 'time_2',\n",
        "        7: 'Temp1',\n",
        "        8: 'Temp2',\n",
        "        9: 'Temp3',\n",
        "        10: 'Temp4'\n",
        "        })\n",
        "    complete.drop(['time', 'to_remove', 'time_2'], axis=1, inplace=True)\n",
        "    training_list = []\n",
        "    testing_list = []\n",
        "    for training, testing in zip(trainig_number_list, testing_number_list):\n",
        "        training_tmp = training.rename(columns={\n",
        "            0: 'id',\n",
        "            1: 'time',\n",
        "            2: 'X1',\n",
        "            3: 'Y1',\n",
        "            4: 'Z1',\n",
        "            5: 'to_remove',\n",
        "            6: 'time_2',\n",
        "            7: 'Temp1',\n",
        "            8: 'Temp2',\n",
        "            9: 'Temp3',\n",
        "            10: 'Temp4'\n",
        "            })\n",
        "        training_tmp.drop(['time', 'to_remove', 'time_2'], axis=1, inplace=True)\n",
        "        training_list.append(training_tmp)\n",
        "        \n",
        "        testing_tmp = testing.rename(columns={\n",
        "            0: 'id',\n",
        "            1: 'time',\n",
        "            2: 'X1',\n",
        "            3: 'Y1',\n",
        "            4: 'Z1',\n",
        "            5: 'to_remove',\n",
        "            6: 'time_2',\n",
        "            7: 'Temp1',\n",
        "            8: 'Temp2',\n",
        "            9: 'Temp3',\n",
        "            10: 'Temp4'\n",
        "            })\n",
        "        testing_tmp.drop(['time', 'to_remove', 'time_2'], axis=1, inplace=True)\n",
        "        testing_list.append(testing_tmp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[        id        X1        Y1        Z1     Temp1     Temp2     Temp3  \\\n",
            "0        0  0.877249 -0.876387  0.698630  0.868852  0.558140  0.935484   \n",
            "1        1  0.870077 -0.877755  0.726027  0.868852  0.441860  0.967742   \n",
            "2        2  0.862210 -0.874809  0.753425  0.868852  0.465116  1.000000   \n",
            "3        3  0.882294 -0.881475  0.753425  0.868852  0.534884  0.967742   \n",
            "4        4  0.872267 -0.881519  0.726027  0.868852  0.558140  0.967742   \n",
            "...    ...       ...       ...       ...       ...       ...       ...   \n",
            "7705  7705  0.133007 -0.331885  0.522388  0.470588  0.285714  0.703704   \n",
            "7706  7706  0.148633 -0.334070  0.582090  0.470588  0.285714  0.703704   \n",
            "7707  7707  0.177016 -0.346153  0.582090  0.470588  0.285714  0.703704   \n",
            "7708  7708  0.116749 -0.339384  0.552239  0.470588  0.285714  0.703704   \n",
            "7709  7709  0.111034 -0.374823  0.552239  0.470588  0.285714  0.703704   \n",
            "\n",
            "         Temp4  \n",
            "0     0.970588  \n",
            "1     0.941176  \n",
            "2     0.911765  \n",
            "3     0.941176  \n",
            "4     0.941176  \n",
            "...        ...  \n",
            "7705  0.920000  \n",
            "7706  0.920000  \n",
            "7707  0.920000  \n",
            "7708  0.920000  \n",
            "7709  0.920000  \n",
            "\n",
            "[30829 rows x 8 columns],         id        X1        Y1        Z1     Temp1     Temp2     Temp3  \\\n",
            "0        0 -1.000000  0.736636  0.177570  0.037037 -0.135135 -0.135135   \n",
            "1        1 -0.981332  0.687808  0.177570  0.037037 -0.027027 -0.162162   \n",
            "2        2 -0.945775  0.688676  0.140187  0.037037  0.081081 -0.135135   \n",
            "3        3 -0.929981  0.667533  0.102804  0.061728 -0.189189 -0.162162   \n",
            "4        4 -0.905817  0.700378  0.028037 -0.012346 -0.369369 -0.135135   \n",
            "...    ...       ...       ...       ...       ...       ...       ...   \n",
            "7705  7705  0.133007 -0.331885  0.522388  0.470588  0.285714  0.703704   \n",
            "7706  7706  0.148633 -0.334070  0.582090  0.470588  0.285714  0.703704   \n",
            "7707  7707  0.177016 -0.346153  0.582090  0.470588  0.285714  0.703704   \n",
            "7708  7708  0.116749 -0.339384  0.552239  0.470588  0.285714  0.703704   \n",
            "7709  7709  0.111034 -0.374823  0.552239  0.470588  0.285714  0.703704   \n",
            "\n",
            "        Temp4  \n",
            "0    -0.56250  \n",
            "1    -0.53125  \n",
            "2    -0.53125  \n",
            "3    -0.56250  \n",
            "4    -0.59375  \n",
            "...       ...  \n",
            "7705  0.92000  \n",
            "7706  0.92000  \n",
            "7707  0.92000  \n",
            "7708  0.92000  \n",
            "7709  0.92000  \n",
            "\n",
            "[27297 rows x 8 columns],         id        X1        Y1        Z1     Temp1     Temp2     Temp3  \\\n",
            "0        0 -1.000000  0.736636  0.177570  0.037037 -0.135135 -0.135135   \n",
            "1        1 -0.981332  0.687808  0.177570  0.037037 -0.027027 -0.162162   \n",
            "2        2 -0.945775  0.688676  0.140187  0.037037  0.081081 -0.135135   \n",
            "3        3 -0.929981  0.667533  0.102804  0.061728 -0.189189 -0.162162   \n",
            "4        4 -0.905817  0.700378  0.028037 -0.012346 -0.369369 -0.135135   \n",
            "...    ...       ...       ...       ...       ...       ...       ...   \n",
            "7705  7705  0.133007 -0.331885  0.522388  0.470588  0.285714  0.703704   \n",
            "7706  7706  0.148633 -0.334070  0.582090  0.470588  0.285714  0.703704   \n",
            "7707  7707  0.177016 -0.346153  0.582090  0.470588  0.285714  0.703704   \n",
            "7708  7708  0.116749 -0.339384  0.552239  0.470588  0.285714  0.703704   \n",
            "7709  7709  0.111034 -0.374823  0.552239  0.470588  0.285714  0.703704   \n",
            "\n",
            "        Temp4  \n",
            "0    -0.56250  \n",
            "1    -0.53125  \n",
            "2    -0.53125  \n",
            "3    -0.56250  \n",
            "4    -0.59375  \n",
            "...       ...  \n",
            "7705  0.92000  \n",
            "7706  0.92000  \n",
            "7707  0.92000  \n",
            "7708  0.92000  \n",
            "7709  0.92000  \n",
            "\n",
            "[27294 rows x 8 columns],         id        X1        Y1        Z1     Temp1     Temp2     Temp3  \\\n",
            "0        0 -1.000000  0.736636  0.177570  0.037037 -0.135135 -0.135135   \n",
            "1        1 -0.981332  0.687808  0.177570  0.037037 -0.027027 -0.162162   \n",
            "2        2 -0.945775  0.688676  0.140187  0.037037  0.081081 -0.135135   \n",
            "3        3 -0.929981  0.667533  0.102804  0.061728 -0.189189 -0.162162   \n",
            "4        4 -0.905817  0.700378  0.028037 -0.012346 -0.369369 -0.135135   \n",
            "...    ...       ...       ...       ...       ...       ...       ...   \n",
            "7705  7705  0.133007 -0.331885  0.522388  0.470588  0.285714  0.703704   \n",
            "7706  7706  0.148633 -0.334070  0.582090  0.470588  0.285714  0.703704   \n",
            "7707  7707  0.177016 -0.346153  0.582090  0.470588  0.285714  0.703704   \n",
            "7708  7708  0.116749 -0.339384  0.552239  0.470588  0.285714  0.703704   \n",
            "7709  7709  0.111034 -0.374823  0.552239  0.470588  0.285714  0.703704   \n",
            "\n",
            "        Temp4  \n",
            "0    -0.56250  \n",
            "1    -0.53125  \n",
            "2    -0.53125  \n",
            "3    -0.56250  \n",
            "4    -0.59375  \n",
            "...       ...  \n",
            "7705  0.92000  \n",
            "7706  0.92000  \n",
            "7707  0.92000  \n",
            "7708  0.92000  \n",
            "7709  0.92000  \n",
            "\n",
            "[27290 rows x 8 columns],         id        X1        Y1        Z1     Temp1     Temp2     Temp3  \\\n",
            "0        0 -1.000000  0.736636  0.177570  0.037037 -0.135135 -0.135135   \n",
            "1        1 -0.981332  0.687808  0.177570  0.037037 -0.027027 -0.162162   \n",
            "2        2 -0.945775  0.688676  0.140187  0.037037  0.081081 -0.135135   \n",
            "3        3 -0.929981  0.667533  0.102804  0.061728 -0.189189 -0.162162   \n",
            "4        4 -0.905817  0.700378  0.028037 -0.012346 -0.369369 -0.135135   \n",
            "...    ...       ...       ...       ...       ...       ...       ...   \n",
            "7705  7705  0.133007 -0.331885  0.522388  0.114754  0.393939  0.098039   \n",
            "7706  7706  0.148633 -0.334070  0.582090  0.114754  0.373737  0.098039   \n",
            "7707  7707  0.177016 -0.346153  0.582090  0.114754  0.353535  0.098039   \n",
            "7708  7708  0.116749 -0.339384  0.552239  0.049180  0.252525  0.058824   \n",
            "7709  7709  0.111034 -0.374823  0.552239 -0.016393  0.252525 -0.019608   \n",
            "\n",
            "         Temp4  \n",
            "0    -0.562500  \n",
            "1    -0.531250  \n",
            "2    -0.531250  \n",
            "3    -0.562500  \n",
            "4    -0.593750  \n",
            "...        ...  \n",
            "7705  0.181818  \n",
            "7706  0.045455  \n",
            "7707  0.000000  \n",
            "7708  0.045455  \n",
            "7709  0.045455  \n",
            "\n",
            "[27290 rows x 8 columns]]\n"
          ]
        }
      ],
      "source": [
        "if not skip:\n",
        "\n",
        "    print(training_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "25\n",
            "error\n",
            "error\n",
            "errors: 0\n",
            "training0\n",
            "X 30829\n",
            "1.0\n",
            "Y 30804\n",
            "1.0\n",
            "errors: 0\n",
            "testing0\n",
            "X 4171\n",
            "1.0\n",
            "Y 4146\n",
            "1.0\n",
            "error\n",
            "error\n",
            "errors: 0\n",
            "training1\n",
            "X 27297\n",
            "1.0\n",
            "Y 27272\n",
            "1.0\n",
            "errors: 0\n",
            "testing1\n",
            "X 7703\n",
            "1.0\n",
            "Y 7678\n",
            "1.0\n",
            "errors: 0\n",
            "training2\n",
            "X 27294\n",
            "1.0\n",
            "Y 27269\n",
            "1.0\n",
            "error\n",
            "error\n",
            "errors: 0\n",
            "testing2\n",
            "X 7706\n",
            "1.0\n",
            "Y 7681\n",
            "1.0\n",
            "error\n",
            "error\n",
            "errors: 0\n",
            "training3\n",
            "X 27290\n",
            "1.0\n",
            "Y 27265\n",
            "1.0\n",
            "errors: 0\n",
            "testing3\n",
            "X 7710\n",
            "1.0\n",
            "Y 7685\n",
            "1.0\n",
            "error\n",
            "error\n",
            "errors: 0\n",
            "training4\n",
            "X 27290\n",
            "1.0\n",
            "Y 27265\n",
            "1.0\n",
            "errors: 0\n",
            "testing4\n",
            "X 7710\n",
            "-1.0\n",
            "Y 7685\n",
            "1.0\n"
          ]
        }
      ],
      "source": [
        "if not skip:\n",
        "    '''\n",
        "    complete.astype(float)\n",
        "\n",
        "    X = complete[['Temp1','Temp2', 'Temp3', 'Temp4']]\n",
        "    Y = complete[['X1', 'Y1', 'Z1']]\n",
        "\n",
        "    Y = Y.values.astype(np.float32)\n",
        "    Y = my_gradient(Y, window_size=hyper_parameters['window_size'])\n",
        "    \n",
        "     \n",
        "    X = X.values.astype(np.float32)\n",
        "    X /= 100\n",
        "    X = X[len(X):20]\n",
        "    '''\n",
        "    print(hyper_parameters['window_size'])\n",
        "    # Save the features and targets in file npy\n",
        "    #np.save(prefix+'/X'+str(hyper_parameters['window_size'])+'.npy',X)\n",
        "    #np.save(prefix+'/Y'+str(hyper_parameters['window_size'])+'.npy',Y)\n",
        "    for i, (testing, training) in enumerate(zip(testing_list, training_list)):\n",
        "        trainingx = normalize_columns(training, ['Temp1','Temp2', 'Temp3', 'Temp4'],-1,1)\n",
        "        trainingy = normalize_columns(training, ['X1', 'Y1', 'Z1'],-1,1)\n",
        "        training.astype(float)\n",
        "        #print(training)\n",
        "        X = trainingx[['Temp1','Temp2', 'Temp3', 'Temp4']]\n",
        "        Y = trainingy[['X1', 'Y1', 'Z1']]\n",
        "        \n",
        "        Y = Y.values.astype(np.float32)\n",
        "        Y = my_gradient(Y, window_size=hyper_parameters['window_size'])\n",
        "        Y = normalize_array(Y,-1,1)\n",
        "        \n",
        "        X = X.values.astype(np.float32)\n",
        "        print('training'+str(i))\n",
        "        print('X',len(X))\n",
        "        print(np.max(X))\n",
        "        print('Y',len(Y))\n",
        "        print(np.max(Y))\n",
        "        # Save the features and targets in file npy\n",
        "        np.save(prefix+'/X'+str(hyper_parameters['window_size'])+'training'+str(i)+str(hyper_parameters['norm'])+'.npy',X)\n",
        "        np.save(prefix+'/Y'+str(hyper_parameters['window_size'])+'training'+str(i)+str(hyper_parameters['norm'])+'.npy',Y)\n",
        "        testingx = normalize_columns(testing, ['Temp1','Temp2', 'Temp3', 'Temp4'],-1,1)\n",
        "        testingy = normalize_columns(testing, ['X1', 'Y1', 'Z1'],-1,1)\n",
        "        testing.astype(float)\n",
        "\n",
        "        X = testingx[['Temp1','Temp2', 'Temp3', 'Temp4']]\n",
        "        Y = testingy[['X1', 'Y1', 'Z1']]\n",
        "\n",
        "        Y = Y.values.astype(np.float32)\n",
        "        Y = my_gradient(Y, window_size=hyper_parameters['window_size'])\n",
        "        Y = normalize_array(Y,-1,1)\n",
        "        \n",
        "        X = X.values.astype(np.float32)\n",
        "        print('testing'+str(i))\n",
        "        print('X',len(X))\n",
        "        print(np.max(X))\n",
        "        print('Y',len(Y))\n",
        "        print(np.max(Y))     \n",
        "        # Save the features and targets in file npy\n",
        "        np.save(prefix+'/X'+str(hyper_parameters['window_size'])+'testing'+str(i)+str(hyper_parameters['norm'])+'.npy',X)\n",
        "        np.save(prefix+'/Y'+str(hyper_parameters['window_size'])+'testing'+str(i)+str(hyper_parameters['norm'])+'.npy',Y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if not skip:\n",
        "\n",
        "    targets_norm_1['time'] = pd.to_datetime(targets_norm_1['time'], unit='ns')\n",
        "\n",
        "    # Reshape the DataFrame using melt()\n",
        "    targets_melted = targets_norm_1.reset_index().melt(id_vars=['time'], value_vars=['X1', 'Y1', 'Z1'], var_name='variable', value_name='value')\n",
        "\n",
        "    # Drop rows where 'value' is NaN (to keep only the non-null entries)\n",
        "    targets_melted = targets_melted.dropna(subset=['value'])\n",
        "\n",
        "    # Plot the data\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    for var in targets_melted['variable'].unique():\n",
        "        # Filter data for each variable and plot\n",
        "        temp_df = targets_melted[targets_melted['variable'] == var]\n",
        "        plt.plot(temp_df['time'], temp_df['value'], label=var)\n",
        "\n",
        "    # Add labels and title\n",
        "    plt.xlabel('Time')\n",
        "    plt.ylabel('Values')\n",
        "    plt.title('Plot of X1, Y1, Z1 over Time')\n",
        "    plt.legend(title='Variable')\n",
        "\n",
        "    # Show the plot\n",
        "    plt.show()\n",
        "\n",
        "    #targets.plot(y='X1',x='time')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if not skip:\n",
        "\n",
        "    # Convert 'time' to datetime (nanoseconds to datetime)\n",
        "    features_1['time'] = pd.to_datetime(features_1['time'], unit='ns')\n",
        "\n",
        "    # Set 'time' as the index\n",
        "    features_1.set_index('time', inplace=True)\n",
        "\n",
        "    # Optionally, you can plot X1, Y1, Z1 directly\n",
        "    features_1[['Temp Sensor 1', 'Temp Sensor 2', 'Temp Sensor 3', 'Temp Sensor 4', ]].plot()\n",
        "\n",
        "    # Add labels and title\n",
        "    plt.xlabel('Time')\n",
        "    plt.ylabel('Values')\n",
        "    plt.title('Plot of Temp Sensor 1, Temp Sensor 2, Temp Sensor 3, Temp Sensor 4 over Time')\n",
        "\n",
        "    # Show the plot\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[21.36 21.64 21.63 21.59]\n",
            " [21.36 21.7  21.62 21.6 ]\n",
            " [21.36 21.76 21.63 21.6 ]\n",
            " ...\n",
            " [21.23 21.65 21.49 21.47]\n",
            " [21.23 21.64 21.49 21.46]\n",
            " [21.21 21.64 21.48 21.47]]\n",
            "[[0.00509315 0.00554387 0.0203726 ]\n",
            " [0.00384014 0.00700421 0.02241587]\n",
            " [0.0026893  0.0071845  0.02394832]\n",
            " ...\n",
            " [0.00345252 0.00874099 0.00426683]\n",
            " [0.0033774  0.00869291 0.00363582]\n",
            " [0.0034976  0.00853365 0.00366587]]\n",
            "0\n",
            "15866\n",
            "0\n",
            "15863\n"
          ]
        }
      ],
      "source": [
        "if skip:\n",
        "    # If skip is true, we simply load the data \n",
        "    X = np.load(prefix+'/X'+str(hyper_parameters['window_size'])+'training'+str(hyper_parameters['file'])+'.npy')\n",
        "    Y = np.load(prefix+'/Y'+str(hyper_parameters['window_size'])+'training'+str(hyper_parameters['file'])+'.npy')\n",
        "\n",
        "print(X)\n",
        "print(Y)\n",
        "\n",
        "splitPerc = [0.7,0.3]\n",
        "splitted_X = split(X, splitPerc)\n",
        "splitted_Y = split(Y, splitPerc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[21.41 21.69 21.67 21.64]\n",
            " [21.4  21.7  21.67 21.64]\n",
            " [21.42 21.71 21.68 21.65]\n",
            " ...\n",
            " [21.25 21.74 21.51 21.48]\n",
            " [21.25 21.72 21.5  21.5 ]\n",
            " [21.25 21.72 21.51 21.48]]\n",
            "[[0.0109096  0.00178571 0.01841518]\n",
            " [0.0094029  0.00831473 0.02371652]\n",
            " [0.00742188 0.01023996 0.03111049]\n",
            " ...\n",
            " [0.0024135  0.01208147 0.00613839]\n",
            " [0.00186942 0.01131417 0.00683594]\n",
            " [0.00239955 0.00983538 0.00739397]]\n",
            "[[21.41 21.69 21.67 21.64]\n",
            " [21.4  21.7  21.67 21.64]\n",
            " [21.42 21.71 21.68 21.65]\n",
            " ...\n",
            " [21.25 21.74 21.51 21.48]\n",
            " [21.25 21.72 21.5  21.5 ]\n",
            " [21.25 21.72 21.51 21.48]]\n",
            "[[0.0082883  0.0054012  0.02091165]\n",
            " [0.00666706 0.00697838 0.02558153]\n",
            " [0.0047433  0.00777138 0.02884164]\n",
            " ...\n",
            " [0.00366248 0.01060268 0.00273144]\n",
            " [0.0036008  0.01049401 0.00252585]\n",
            " [0.00390919 0.01013863 0.00343633]]\n",
            "[[21.41 21.69 21.67 21.64]\n",
            " [21.4  21.7  21.67 21.64]\n",
            " [21.42 21.71 21.68 21.65]\n",
            " ...\n",
            " [21.25 21.74 21.51 21.48]\n",
            " [21.25 21.72 21.5  21.5 ]\n",
            " [21.25 21.72 21.51 21.48]]\n",
            "[[0.00509315 0.00554387 0.0203726 ]\n",
            " [0.00384014 0.00700421 0.02241587]\n",
            " [0.0026893  0.0071845  0.02394832]\n",
            " ...\n",
            " [0.00345252 0.00874099 0.00426683]\n",
            " [0.0033774  0.00869291 0.00363582]\n",
            " [0.0034976  0.00853365 0.00366587]]\n"
          ]
        }
      ],
      "source": [
        "for i in [15, 20, 25]:\n",
        "    X = np.load(prefix+'/X'+str(i)+'.npy')\n",
        "    Y = np.load(prefix+'/Y'+str(i)+'.npy')\n",
        "\n",
        "    print(X)\n",
        "    print(Y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnlFgCAkol0x"
      },
      "source": [
        "# MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "#1 ARIMA 2 linear\n",
        "#1 MLP 2 linear\n",
        "#\n",
        "#tutti i voting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "datasetTrain = thermal_dataset((splitted_X[0],splitted_Y[0]), hyper_parameters['timesteps'], device)\n",
        "datasetVal = thermal_dataset((splitted_X[1],splitted_Y[1]), hyper_parameters['timesteps'], device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BbEyWHlGEJHm"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3\n",
            "Ensemble Model Summary: ModuleList(\n",
            "  (0): mlp(\n",
            "    (linear_layers): ModuleList(\n",
            "      (0): Linear(in_features=3, out_features=4, bias=True)\n",
            "      (1): Linear(in_features=4, out_features=3, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (1): linear(\n",
            "    (linear_layer): Linear(in_features=3, out_features=3, bias=False)\n",
            "  )\n",
            ") ModuleList(\n",
            "  (0): ARIMA(\n",
            "    (PD): TwoPolynomialOperation(\n",
            "      (first_poly): BiasOnePolynomial()\n",
            "      (second_poly): Polynomial()\n",
            "    )\n",
            "    (Q): BiasOnePolynomial()\n",
            "    (PDS): TwoPolynomialOperation(\n",
            "      (first_poly): BiasOnePolynomial()\n",
            "      (second_poly): Polynomial()\n",
            "    )\n",
            "    (QS): BiasOnePolynomial()\n",
            "  )\n",
            ") ModuleList()\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "list is not an Optimizer",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[24], line 25\u001b[0m\n\u001b[1;32m     20\u001b[0m     optimizer \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mhyper_parameters[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m rnn]\n\u001b[1;32m     24\u001b[0m loss_fn \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mMSELoss()\n\u001b[0;32m---> 25\u001b[0m scheduler \u001b[38;5;241m=\u001b[39m \u001b[43mExponentialLR\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgamma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.9\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m model\n",
            "File \u001b[0;32m~/uni/magistrale/Napoli/eai-project/.venv/lib/python3.13/site-packages/torch/optim/lr_scheduler.py:809\u001b[0m, in \u001b[0;36mExponentialLR.__init__\u001b[0;34m(self, optimizer, gamma, last_epoch, verbose)\u001b[0m\n\u001b[1;32m    805\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    806\u001b[0m     \u001b[38;5;28mself\u001b[39m, optimizer: Optimizer, gamma: \u001b[38;5;28mfloat\u001b[39m, last_epoch\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeprecated\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    807\u001b[0m ):  \u001b[38;5;66;03m# noqa: D107\u001b[39;00m\n\u001b[1;32m    808\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgamma \u001b[38;5;241m=\u001b[39m gamma\n\u001b[0;32m--> 809\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlast_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/uni/magistrale/Napoli/eai-project/.venv/lib/python3.13/site-packages/torch/optim/lr_scheduler.py:99\u001b[0m, in \u001b[0;36mLRScheduler.__init__\u001b[0;34m(self, optimizer, last_epoch, verbose)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28mself\u001b[39m, optimizer: Optimizer, last_epoch\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeprecated\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     96\u001b[0m ):  \u001b[38;5;66;03m# noqa: D107\u001b[39;00m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;66;03m# Attach optimizer\u001b[39;00m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(optimizer, Optimizer):\n\u001b[0;32m---> 99\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(optimizer)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not an Optimizer\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer \u001b[38;5;241m=\u001b[39m optimizer\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;66;03m# Initialize epoch and base learning rates\u001b[39;00m\n",
            "\u001b[0;31mTypeError\u001b[0m: list is not an Optimizer"
          ]
        }
      ],
      "source": [
        "# Training, Test and Validation Dataloader initialization\n",
        "loaderTrain = DataLoader(datasetTrain, shuffle=True, batch_size=hyper_parameters['batch_size'])\n",
        "loaderVal = DataLoader(datasetVal, shuffle=True, batch_size=hyper_parameters['batch_size'])\n",
        "\n",
        "# Model Initialization (True if you want to use the Ensemble model, False in you want to use a single LSTM model)\n",
        "if hyper_parameters['ensemble'] == False:\n",
        "    model = lstm_only(hidden_dim=hyper_parameters['hidden_dim'], timesteps=hyper_parameters['timesteps'] ,input_dim=4, output_dim=3).to(device)\n",
        "elif hyper_parameters['ensemble'] == True:  \n",
        "    model = complete_model(hidden_dim=hyper_parameters['hidden_dim'], input_dim=4, model_dict=ensemble_model, device=device, mode=hyper_parameters['mode'], extractor_type=hyper_parameters['extractor_type']).to(device)\n",
        "\n",
        "# Definition of the optimizer and loss function\n",
        "\n",
        "if hyper_parameters['ensemble'] == False:\n",
        "    optimizer = optim.Adam(model.parameters(), lr=hyper_parameters['lr'])\n",
        "elif hyper_parameters['ensemble'] == True:\n",
        "    optimizer = []\n",
        "    models, arima, rnn =model.get_models()\n",
        "    optimizer += [optim.Adam(model.parameters(), lr=hyper_parameters['lr']) for model in models]\n",
        "    optimizer += [optim.Adam(model.parameters(), lr=hyper_parameters['lr']) for model in arima]\n",
        "    optimizer += [optim.Adam(model.parameters(), lr=hyper_parameters['lr']) for model in rnn]\n",
        "\n",
        "\n",
        "\n",
        "loss_fn = nn.MSELoss()\n",
        "scheduler = ExponentialLR(optimizer, gamma=0.9)\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "train(\n",
        "    num_epochs=hyper_parameters['num_epochs'],\n",
        "    loss_fn=loss_fn,\n",
        "    model=model,\n",
        "    optimizer=optimizer,\n",
        "    scheduler=scheduler,\n",
        "    training_dataloader=loaderTrain,\n",
        "    validation_dataloader=loaderVal,\n",
        "    hyperparams=hyper_parameters,\n",
        "    model_dict = ensemble_model,\n",
        "    complete=hyper_parameters['ensemble']\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Need to specify a model.pt file to load! In the directory results that you want to test\n",
        "result_path = '/results/training_2025-01-31_10-13' \n",
        "model_path = prefix + result_path +'/model.pt'\n",
        "\n",
        "# Read hyperparameters\n",
        "with open (prefix + result_path + '/hyperparam.json', 'r') as f:\n",
        "    hyperparams = json.load(f)\n",
        "    \n",
        "X = np.load(prefix+'/X'+str(hyper_parameters['window_size'])+'testing'+str(hyper_parameters['file'])+'.npy')\n",
        "Y = np.load(prefix+'/X'+str(hyper_parameters['window_size'])+'testing'+str(hyper_parameters['file'])+'.npy')\n",
        "\n",
        "datasetTest = thermal_dataset((X,Y), hyperparams['timesteps'], device)\n",
        "loaderTest = DataLoader(datasetTest, shuffle=True, batch_size=hyperparams['batch_size'])\n",
        "# Section in which we reinitialize the model for testing depending on the hyperparameters.json and ensemble.json (if present) in the directories of results\n",
        "# Read Ensemble models data (if complete = True)\n",
        "if hyperparams['ensemble'] == True:\n",
        "    # Read Ensemble model parameters and initialize the model\n",
        "    with open (prefix + result_path + '/ensemble.json', 'r') as f:\n",
        "        model_dict = json.load(f)\n",
        "    model = complete_model(hidden_dim=hyperparams['hidden_dim'], input_dim=4, model_dict=model_dict, device=device, mode=hyperparams['mode'], extractor_type=hyperparams['extractor_type']).to(device)\n",
        "# Otherwise create an LSTM only model\n",
        "else:\n",
        "    model = lstm_only(hidden_dim=hyperparams['hidden_dim'], timesteps=hyperparams['timesteps'] ,input_dim=4, output_dim=3).to(device)\n",
        "\n",
        "if test_flag:\n",
        "    test_metrics, test_loss_avg, total_inference_time, inference_time_avg, y_true_list, y_pred_list = test(\n",
        "        model=model,\n",
        "        model_path=model_path,\n",
        "        test_dataloader=loaderTest,\n",
        "        loss_fn=loss_fn,\n",
        "        complete=hyperparams['ensemble']\n",
        "    )\n",
        "print(\"Test metrics:\")\n",
        "print(f\"rmse: {test_metrics['rmse']} , mae: {test_metrics['mae']}, r2: {test_metrics['r2']}\")\n",
        "print(\"Others:\")\n",
        "print(f\"Average Loss: {test_loss_avg}, Total Inference Time (All Dataset): {total_inference_time}, Average Inference Time: {inference_time_avg}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "path = prefix + result_path  # type ./results/ensemble_batch_256\n",
        "\n",
        "# Load the dictionaries\n",
        "with open (path + '/train_metrics.json', 'r') as f:\n",
        "    train_metrics = json.load(f)\n",
        "with open (path + '/valid_metrics.json', 'r') as f:\n",
        "    valid_metrics = json.load(f)\n",
        "\n",
        "# Initialize a list of epochs [1,2,3, ...] for the plots x-axis\n",
        "epochs = [i for i in range(1, hyper_parameters['num_epochs']+1)]\n",
        "\n",
        "# Compute training loss as the square of rmse for each element because loss = mse\n",
        "# Both for training and validation\n",
        "training_loss = [rmse**2 for rmse in train_metrics['rmse']] \n",
        "valid_loss = [rmse**2 for rmse in valid_metrics['rmse']] \n",
        "\n",
        "plt.plot(epochs, training_loss, label='Training', color='b')\n",
        "plt.plot(epochs, valid_loss, label='Validation', color='r')\n",
        "plt.title('Loss (RMSE^2)')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss value')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()  # This helps to prevent overlapping of subplots\n",
        "plt.savefig(path+'/loss')  # Save the figure to the specified path\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "path = prefix + result_path  # type ./results/ensemble_batch_256\n",
        "\n",
        "# Load the dictionaries\n",
        "with open (path + '/train_metrics.json', 'r') as f:\n",
        "    train_metrics = json.load(f)\n",
        "with open (path + '/valid_metrics.json', 'r') as f:\n",
        "    valid_metrics = json.load(f)\n",
        "\n",
        "# Initialize a list of epochs [1,2,3, ...] for the plots x-axis\n",
        "epochs = [i for i in range(1, hyper_parameters['num_epochs']+1)]\n",
        "\n",
        "plt.plot(epochs, train_metrics['mae'], label='Training', color='b')\n",
        "plt.plot(epochs, valid_metrics['mae'], label='Validation', color='r')\n",
        "plt.title('Mean Absolute Error')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('MAE value')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()  # This helps to prevent overlapping of subplots\n",
        "plt.savefig(path + '/mae')  # Save the figure to the specified path\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "path = prefix + result_path  # type ./results/ensemble_batch_256\n",
        "\n",
        "# Load the dictionaries\n",
        "with open (path + '/train_metrics.json', 'r') as f:\n",
        "    train_metrics = json.load(f)\n",
        "with open (path + '/valid_metrics.json', 'r') as f:\n",
        "    valid_metrics = json.load(f)\n",
        "\n",
        "# Initialize a list of epochs [1,2,3, ...] for the plots x-axis\n",
        "epochs = [i for i in range(1, hyper_parameters['num_epochs']+1)]\n",
        "\n",
        "plt.plot(epochs, train_metrics['r2'], label='Training', color='b')\n",
        "plt.plot(epochs, valid_metrics['r2'], label='Validation', color='r')\n",
        "plt.title('R2 (Coefficient of determination)')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('R2 value')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()  # This helps to prevent overlapping of subplots\n",
        "plt.savefig(path + '/r2')  # Save the figure to the specified path\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create the lists of X1, Y1, Z1 true values to plot\n",
        "x1_true = [x[0] for x in y_true_list]\n",
        "y1_true = [y[1] for y in y_true_list]\n",
        "z1_true = [z[2] for z in y_true_list]\n",
        "\n",
        "# Create the lists of X1, Y1, Z1 predicted values to plot\n",
        "x1_pred = [x[0] for x in y_pred_list]\n",
        "y1_pred = [y[1] for y in y_pred_list]\n",
        "z1_pred = [z[2] for z in y_pred_list]\n",
        "\n",
        "# Create x-axis\n",
        "t = [i for i in range(1, len(y_pred_list)+1)]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize a list of epochs [1,2,3, ...] for the plots x-axis\n",
        "#t = [i for i in range(1, len(Y[:,0])+1)]\n",
        "plt.plot(t, y1_true, label='Ground Truth', color='b')\n",
        "plt.plot(t, x1_pred, label='Prediction', color='r')\n",
        "plt.title('X1 Sequence')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('X1')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()  # This helps to prevent overlapping of subplots\n",
        "#plt.savefig(path + '/r2')  # Save the figure to the specified path\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize a list of epochs [1,2,3, ...] for the plots x-axis\n",
        "\n",
        "plt.plot(t[:100], y1_true[:100], label='Ground Truth', color='b')\n",
        "plt.plot(t[:100], y1_pred[:100], label='Prediction', color='r')\n",
        "plt.title('Y1 Sequence')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Y1')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()  # This helps to prevent overlapping of subplots\n",
        "#plt.savefig(path + '/r2')  # Save the figure to the specified path\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize a list of epochs [1,2,3, ...] for the plots x-axis\n",
        "\n",
        "plt.plot(t, z1_true, label='Ground Truth', color='b')\n",
        "plt.plot(t, z1_pred, label='Prediction', color='r')\n",
        "plt.title('Z1 Sequence')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Z1')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()  # This helps to prevent overlapping of subplots\n",
        "#plt.savefig(path + '/r2')  # Save the figure to the specified path\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
