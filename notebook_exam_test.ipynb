{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3O4mXmBol0t"
      },
      "source": [
        "# IMPORT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9gQw18CXol0v"
      },
      "outputs": [],
      "source": [
        "# Model\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torch import optim\n",
        "from torch.optim.lr_scheduler import ExponentialLR \n",
        "\n",
        "# Others\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "%matplotlib widget\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "\n",
        "from training.train import train\n",
        "from preprocessing.preprocessing import *\n",
        "from dataset.thermal_dataset import thermal_dataset\n",
        "from utils.csv_utils import *\n",
        "from models.complete_model import complete_model\n",
        "from models.complete_model_autoencoder import complete_model_autoencoder\n",
        "from models.lstm_only import lstm_only\n",
        "from testing.test import test\n",
        "prefix = '.'\n",
        "    \n",
        "pd.set_option('display.max_columns', None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Reproducibility and Device Setting**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set a seed for reproducibility purposes\n",
        "seed = 46\n",
        "torch.manual_seed(seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "np.random.seed(seed)\n",
        "\n",
        "# Set the device (cuda for Nvidia GPUs, mps for M1, M2 .. Apple Silicon)\n",
        "if torch.cuda.is_available():\n",
        "    device = \"cuda\"\n",
        "elif torch.backends.mps.is_available():\n",
        "    device = \"mps\"\n",
        "else:\n",
        "    device = \"cpu\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Need to specify a model.pt file to load! In the directory results that you want to test\n",
        "result_path = '/results/training_2025-03-05_13-29'  \n",
        "model_path = prefix + result_path +'/model.pt'\n",
        "\n",
        "# Loss function\n",
        "loss_fn = nn.MSELoss()\n",
        "\n",
        "# Read hyperparameters\n",
        "with open (prefix + result_path + '/hyperparam.json', 'r') as f:\n",
        "    hyperparams = json.load(f)\n",
        "   \n",
        "if hyperparams['norm']:\n",
        "    X = np.load(prefix+'/data/X'+'testing'+str(hyperparams['file'])+'.npy')\n",
        "    Y = np.load(prefix+'/data/Y'+str(hyperparams['window_size'])+'testing'+str(hyperparams['file'])+'.npy')\n",
        "else:\n",
        "    X = np.load(prefix+'/data/X'+'testing'+str(hyperparams['file'])+'.npy')\n",
        "    Y = np.load(prefix+'/data/Y'+str(hyperparams['window_size'])+'testing'+str(hyperparams['file'])+'.npy')\n",
        "print('X',X)\n",
        "print('Y',Y)\n",
        "datasetTest = thermal_dataset((X,Y), hyperparams['timesteps'], device)\n",
        "loaderTest = DataLoader(datasetTest, shuffle=True, batch_size=hyperparams['batch_size'])\n",
        "# Section in which we reinitialize the model for testing depending on the hyperparameters.json and ensemble.json (if present) in the directories of results\n",
        "# Read Ensemble models data (if complete = True)\n",
        "if hyperparams['ensemble'] == True:\n",
        "    # Read Ensemble model parameters and initialize the model\n",
        "    with open (prefix + result_path + '/ensemble.json', 'r') as f:\n",
        "        model_dict = json.load(f)\n",
        "    \n",
        "    if hyperparams['extractor_type']=='conv':\n",
        "        print(\"HERE\")\n",
        "        with open(prefix + result_path + '/autoencoder.json', 'r') as f:\n",
        "            autoencoder_dict = json.load(f)\n",
        "        model = complete_model_autoencoder(\n",
        "            model_dict=model_dict,\n",
        "            device=device,\n",
        "            autoencoder_dim=autoencoder_dict['in_kern_out'],\n",
        "            pooling_kernel_size=autoencoder_dict['pooling_kernel_size'],\n",
        "            padding=autoencoder_dict['padding'],\n",
        "            pooling=autoencoder_dict['pooling'],\n",
        "            timesteps=hyperparams['timesteps'],\n",
        "            scale_factor=autoencoder_dict['scale_factor'],\n",
        "            upsample_mode=autoencoder_dict['upsample_mode'],\n",
        "            mode=hyperparams['mode'],\n",
        "            heterogeneous=hyperparams['heterogeneous'],\n",
        "            norm=hyperparams['norm']\n",
        "        ).to(device)\n",
        "    elif hyperparams['extractor_type']=='lstm':\n",
        "        with open(prefix + result_path + '/autoencoder.json', 'r') as f:\n",
        "            autoencoder_dict = json.load(f)\n",
        "        model = complete_model_autoencoder(\n",
        "                                    model_dict=model_dict, \n",
        "                                    device=device, \n",
        "                                    timesteps=hyperparams['timesteps'],\n",
        "                                    autoencoder_dim=autoencoder_dict['in_hidd'], \n",
        "                                    dropout=autoencoder_dict['dropout'],\n",
        "                                    extractor_type=hyperparams['extractor_type'],\n",
        "                                    heterogeneous=hyperparams['heterogeneous'],\n",
        "                                    norm=hyperparams['norm']\n",
        "                                    ).to(device)\n",
        "    else:\n",
        "        model = complete_model(\n",
        "            hidden_dim=hyperparams['hidden_dim'], \n",
        "            input_dim=4, \n",
        "            model_dict=model_dict, \n",
        "            device=device, \n",
        "            num_layers=hyperparams['num_layers'], \n",
        "            mode=hyperparams['mode'], \n",
        "            extractor_type=hyperparams['extractor_type']).to(device)\n",
        "\n",
        "# Otherwise create an LSTM only model\n",
        "else:\n",
        "    model = lstm_only(\n",
        "        hidden_dim=hyperparams['hidden_dim'], \n",
        "        timesteps=hyperparams['timesteps'] ,\n",
        "        input_dim=4, \n",
        "        output_dim=3).to(device)\n",
        "\n",
        "print(hyperparams)\n",
        "#print(\"state_dict\",model.state_dict().keys())\n",
        "\n",
        "\n",
        "test_model_metrics, test_autoencoder_metrics, loss_model_avg, loss_autoencoder_avg, total_inference_time, inference_time_avg, y_true_list, y_pred_list, x_true_list, x_pred_list = test(\n",
        "    model=model,\n",
        "    model_path=model_path,\n",
        "    test_dataloader=loaderTest,\n",
        "    loss_fn=loss_fn,\n",
        "    complete=hyperparams['ensemble'],\n",
        "    autoencoder= hyperparams['extractor_type'] == 'conv' or hyperparams['extractor_type'] == 'lstm',\n",
        "    autoencoder_only=True,\n",
        "    device=device\n",
        ")\n",
        "\n",
        "#train_val = True\n",
        "print('Legend metrics:[X1,Y1,Z1]')\n",
        "print(\"Test Model metrics:\")\n",
        "print(f\"rmse: {test_model_metrics['rmse'][0]} , mae: {test_model_metrics['mae'][0]}, r2: {test_model_metrics['r2'][0]}\")\n",
        "print(\"Reference metrics(wrt. 0):\")\n",
        "print(f\"rmse: {test_model_metrics['rmse_ref'][0]} , mae: {test_model_metrics['mae_ref'][0]}, r2: {test_model_metrics['r2_ref'][0]}\")\n",
        "print(\"Test Autoencoder metrics:\")\n",
        "print(f\"rmse: {test_autoencoder_metrics['rmse'][0]} , mae: {test_autoencoder_metrics['mae'][0]}, r2: {test_autoencoder_metrics['r2'][0]}\")\n",
        "print(\"Others:\")\n",
        "print(f\"Model Average Loss: {loss_model_avg}, Autoencoder Average Loss: {loss_autoencoder_avg}, Total Inference Time (All Dataset): {total_inference_time}, Average Inference Time: {inference_time_avg}\")\n",
        "if hyperparams['ensemble'] == True:\n",
        "    if not 'NoOpModule' in str(type(model.ensemble)):\n",
        "        print(f\"Weights of the Ensemble models: {model.ensemble.weights.cpu().tolist()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "path = prefix + result_path  # type ./results/ensemble_batch_256\n",
        "\n",
        "# Load the dictionaries\n",
        "with open (path + '/train_model_metrics.json', 'r') as f:\n",
        "    train_metrics = json.load(f)\n",
        "with open (path + '/valid_model_metrics.json', 'r') as f:\n",
        "    valid_metrics = json.load(f)\n",
        "\n",
        "# Initialize a list of epochs [1,2,3, ...] for the plots x-axis\n",
        "epochs = [i for i in range(1, hyperparams['num_epochs']+1)]\n",
        "\n",
        "# Compute training loss as the square of rmse for each element because loss = mse\n",
        "# Both for training and validation\n",
        "training_loss = train_metrics['loss']\n",
        "valid_loss = valid_metrics['loss'] \n",
        "\n",
        "fig1, ax1 = plt.subplots()\n",
        "\n",
        "ax1.plot(epochs, training_loss, label='Training', color='b')\n",
        "ax1.plot(epochs, valid_loss, label='Validation', color='r')\n",
        "ax1.set_title('Loss (RMSE^2)')\n",
        "ax1.set_xlabel('Epochs')\n",
        "ax1.set_ylabel('Loss value')\n",
        "ax1.legend()\n",
        "\n",
        "plt.savefig(path+'/loss')  # Save the figure to the specified path\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#print(len(x_pred_list[0][0]))\n",
        "\n",
        "#list is made like [number of sample windows][number of sensors][number of timesteps] [7472][3][199]\n",
        "x_pred_sensor_1 = x_pred_list[0][0].copy()\n",
        "x_pred_sensor_2 = x_pred_list[0][1].copy()\n",
        "x_pred_sensor_3 = x_pred_list[0][2].copy()\n",
        "x_pred_sensor_4 = x_pred_list[0][3].copy()\n",
        "# we unroll the sliding windows to get the predictions as a continuous list because the windows are overlapped\n",
        "x_pred_sensor_1 += [x_pred[0][-1] for x_pred in x_pred_list[1:]]\n",
        "x_pred_sensor_2 += [x_pred[1][-1] for x_pred in x_pred_list[1:]]\n",
        "x_pred_sensor_3 += [x_pred[2][-1] for x_pred in x_pred_list[1:]]\n",
        "x_pred_sensor_4 += [x_pred[3][-1] for x_pred in x_pred_list[1:]]\n",
        "\n",
        "x_true_sensor_1 = x_true_list[0][0].copy() \n",
        "x_true_sensor_2 = x_true_list[0][1].copy()\n",
        "x_true_sensor_3 = x_true_list[0][2].copy()\n",
        "x_true_sensor_4 = x_true_list[0][3].copy()\n",
        "# we unroll the sliding windows to get the predictions as a continuous list because the windows are overlapped\n",
        "x_true_sensor_1 += [x_true[0][-1] for x_true in x_true_list[1:]]\n",
        "x_true_sensor_2 += [x_true[1][-1] for x_true in x_true_list[1:]]\n",
        "x_true_sensor_3 += [x_true[2][-1] for x_true in x_true_list[1:]]\n",
        "x_true_sensor_4 += [x_true[3][-1] for x_true in x_true_list[1:]]\n",
        "\n",
        "print(len(x_true_sensor_3))\n",
        "print(len(x_pred_sensor_3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "path = prefix + result_path  # type ./results/ensemble_batch_256\n",
        "\n",
        "# Load the dictionaries\n",
        "with open (path + '/train_model_metrics.json', 'r') as f:\n",
        "    train_metrics = json.load(f)\n",
        "with open (path + '/valid_model_metrics.json', 'r') as f:\n",
        "    valid_metrics = json.load(f)\n",
        "\n",
        "# Initialize a list of epochs [1,2,3, ...] for the plots x-axis\n",
        "epochs = [i for i in range(1, hyperparams['num_epochs']+1)]\n",
        "\n",
        "fig2, ax2 = plt.subplots()\n",
        "\n",
        "ax2.plot(epochs, [mae[1] for mae in train_metrics['mae']], label='Training', color='b')\n",
        "ax2.plot(epochs, [mae[1] for mae in valid_metrics['mae']], label='Validation', color='r')\n",
        "ax2.set_title('Mean Absolute Error')\n",
        "ax2.set_xlabel('Epochs')\n",
        "ax2.set_ylabel('MAE value Y')\n",
        "ax2.legend()\n",
        "\n",
        "plt.savefig(path + '/mae')  # Save the figure to the specified path\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "path = prefix + result_path  # type ./results/ensemble_batch_256\n",
        "\n",
        "# Load the dictionaries\n",
        "with open (path + '/train_model_metrics.json', 'r') as f:\n",
        "    train_metrics = json.load(f)\n",
        "with open (path + '/valid_model_metrics.json', 'r') as f:\n",
        "    valid_metrics = json.load(f)\n",
        "\n",
        "# Initialize a list of epochs [1,2,3, ...] for the plots x-axis\n",
        "epochs = [i for i in range(1, hyperparams['num_epochs']+1)]\n",
        "\n",
        "fig3, ax3 = plt.subplots()\n",
        "\n",
        "ax3.plot(epochs, [r2[1] for r2 in train_metrics['r2']], label='Training', color='b')\n",
        "ax3.plot(epochs, [r2[1] for r2 in valid_metrics['r2']], label='Validation', color='r')\n",
        "ax3.set_title('R2 (Coefficient of determination)')\n",
        "ax3.set_xlabel('Epochs')\n",
        "ax3.set_ylabel('R2 value Y')\n",
        "plt.legend()\n",
        "\n",
        "plt.savefig(path + '/r2')  # Save the figure to the specified path\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "path = prefix + result_path\n",
        "\n",
        "# Create the lists of X1, Y1, Z1 true values to plot\n",
        "x1_true = [x[0] for x in y_true_list]\n",
        "y1_true = [y[1] for y in y_true_list]\n",
        "z1_true = [z[2] for z in y_true_list]\n",
        "\n",
        "# Create the lists of X1, Y1, Z1 predicted values to plot\n",
        "x1_pred = [x[0] for x in y_pred_list]\n",
        "y1_pred = [y[1] for y in y_pred_list]\n",
        "z1_pred = [z[2] for z in y_pred_list]\n",
        "\n",
        "# Create x-axis\n",
        "t = [i for i in range(1, len(y_pred_list)+1)]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig4, ax4 = plt.subplots()\n",
        "\n",
        "ax4.plot(t, y1_true, label='Ground Truth', color='b')\n",
        "ax4.plot(t, x1_pred, label='Prediction', color='r')\n",
        "ax4.set_title('X1 Sequence')\n",
        "ax4.set_xlabel('Time')\n",
        "ax4.set_ylabel('X1')\n",
        "plt.legend()\n",
        "\n",
        "plt.savefig(path + '/X1')  # Save the figure to the specified path\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize a list of epochs [1,2,3, ...] for the plots x-axis\n",
        "\n",
        "fig5, ax5 = plt.subplots()\n",
        "\n",
        "ax5.plot(t, y1_true, label='Ground Truth', color='b')\n",
        "ax5.plot(t, y1_pred, label='Prediction', color='r')\n",
        "ax5.set_title('Y1 Sequence')\n",
        "ax5.set_xlabel('Time')\n",
        "ax5.set_ylabel('Y1')\n",
        "plt.legend()\n",
        "\n",
        "plt.savefig(path + '/Y1')  # Save the figure to the specified path\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize a list of epochs [1,2,3, ...] for the plots x-axis\n",
        "fig6, ax6 = plt.subplots()\n",
        "\n",
        "ax6.plot(t, z1_true, label='Ground Truth', color='b')\n",
        "ax6.plot(t, z1_pred, label='Prediction', color='r')\n",
        "ax6.set_title('Z1 Sequence ')\n",
        "ax6.set_xlabel('Time [1 u = 11 s]')\n",
        "ax6.set_ylabel('Z1')\n",
        "plt.legend()\n",
        "\n",
        "plt.savefig(path + '/Z1')  # Save the figure to the specified path\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#print(len(x_pred_list[0][0]))\n",
        "\n",
        "#list is made like [number of sample windows][number of sensors][number of timesteps] [7472][3][199]\n",
        "x_pred_sensor_1 = x_pred_list[0][0].copy()\n",
        "x_pred_sensor_2 = x_pred_list[0][1].copy()\n",
        "x_pred_sensor_3 = x_pred_list[0][2].copy()\n",
        "x_pred_sensor_4 = x_pred_list[0][3].copy()\n",
        "# we unroll the sliding windows to get the predictions as a continuous list because the windows are overlapped\n",
        "x_pred_sensor_1 += [x_pred[0][-1] for x_pred in x_pred_list[1:]]\n",
        "x_pred_sensor_2 += [x_pred[1][-1] for x_pred in x_pred_list[1:]]\n",
        "x_pred_sensor_3 += [x_pred[2][-1] for x_pred in x_pred_list[1:]]\n",
        "x_pred_sensor_4 += [x_pred[3][-1] for x_pred in x_pred_list[1:]]\n",
        "\n",
        "x_true_sensor_1 = x_true_list[0][0].copy() \n",
        "x_true_sensor_2 = x_true_list[0][1].copy()\n",
        "x_true_sensor_3 = x_true_list[0][2].copy()\n",
        "x_true_sensor_4 = x_true_list[0][3].copy()\n",
        "# we unroll the sliding windows to get the predictions as a continuous list because the windows are overlapped\n",
        "x_true_sensor_1 += [x_true[0][-1] for x_true in x_true_list[1:]]\n",
        "x_true_sensor_2 += [x_true[1][-1] for x_true in x_true_list[1:]]\n",
        "x_true_sensor_3 += [x_true[2][-1] for x_true in x_true_list[1:]]\n",
        "x_true_sensor_4 += [x_true[3][-1] for x_true in x_true_list[1:]]\n",
        "\n",
        "# Create x-axis\n",
        "t_x = [i for i in range(1, len(x_true_sensor_4)+1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig7, ax7 = plt.subplots()\n",
        "\n",
        "ax7.plot(t_x, x_true_sensor_1, label='Ground Truth', color='b')\n",
        "ax7.plot(t_x, x_pred_sensor_1, label='Prediction', color='r')\n",
        "ax7.set_title('Autoencoder Sensor 1 Prediction')\n",
        "ax7.set_xlabel('Time [1 u = 11 s]')\n",
        "ax7.set_ylabel('Temp1 [째C]')\n",
        "plt.legend()\n",
        "\n",
        "plt.savefig(path + '/temp1')  # Save the figure to the specified path\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig8, ax8 = plt.subplots()\n",
        "\n",
        "ax8.plot(t_x, x_true_sensor_2, label='Ground Truth', color='b')\n",
        "ax8.plot(t_x, x_pred_sensor_2, label='Prediction', color='r')\n",
        "ax8.set_title('Autoencoder Sensor 2 Prediction')\n",
        "ax8.set_xlabel('Time [1 u = 11 s]')\n",
        "ax8.set_ylabel('Temp2 [째C]')\n",
        "plt.legend()\n",
        "\n",
        "plt.savefig(path + '/temp2')  # Save the figure to the specified path\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig9, ax9 = plt.subplots()\n",
        "\n",
        "ax9.plot(t_x, x_true_sensor_3, label='Ground Truth', color='b')\n",
        "ax9.plot(t_x, x_pred_sensor_3, label='Prediction', color='r')\n",
        "ax9.set_title('Autoencoder Sensor 3 Prediction')\n",
        "ax9.set_xlabel('Time [1 u = 11 s]')\n",
        "ax9.set_ylabel('Temp3 [째C]')\n",
        "plt.legend()\n",
        "\n",
        "plt.savefig(path + '/temp3')  # Save the figure to the specified path\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig10, ax10 = plt.subplots()\n",
        "\n",
        "ax10.plot(t_x, x_true_sensor_4, label='Ground Truth', color='b')\n",
        "ax10.plot(t_x, x_pred_sensor_4, label='Prediction', color='r')\n",
        "ax10.set_title('Autoencoder Sensor 4 Prediction')\n",
        "ax10.set_xlabel('Time [1 u = 11 s]')\n",
        "ax10.set_ylabel('Temp4 [째C]')\n",
        "plt.legend()\n",
        "\n",
        "plt.savefig(path + '/temp4')  # Save the figure to the specified path\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig10, ax10 = plt.subplots()\n",
        "\n",
        "ax10.plot(t_x, x_true_sensor_4, label='Ground Truth', color='b')\n",
        "ax10.plot(t_x, x_pred_sensor_4, label='Prediction', color='r')\n",
        "ax10.set_title('Autoencoder Sensor 4 Prediction')\n",
        "ax10.set_xlabel('Time')\n",
        "ax10.set_ylabel('Temp4')\n",
        "plt.legend()\n",
        "\n",
        "plt.savefig(path + '/temp4')  # Save the figure to the specified path\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
