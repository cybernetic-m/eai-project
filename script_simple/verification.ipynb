{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "!git clone \"https://github.com/cybernetic-m/eai-project.git\" # type: ignore\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import optim\n",
    "from torch.optim.lr_scheduler import ExponentialLR \n",
    "\n",
    "# Others\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import pickle\n",
    "\n",
    "sys.path.append('/content/eai-project/training')\n",
    "sys.path.append('/content/eai-project/preprocessing')\n",
    "sys.path.append('/content/eai-project/dataset')\n",
    "sys.path.append('/content/eai-project/utils')\n",
    "sys.path.append('/content/eai-project/models')\n",
    "sys.path.append('/content/eai-project/modules')\n",
    "sys.path.append('/content/eai-project/testing')\n",
    "sys.path.append('/content/eai-project')\n",
    "from train import train\n",
    "from preprocessing import *\n",
    "from thermal_dataset import thermal_dataset \n",
    "from csv_utils import *\n",
    "from complete_model import complete_model \n",
    "from testing.test import test\n",
    "from blocks import mlp, linear, rnn, lstm\n",
    "prefix = '/content'\n",
    "    \n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a seed for reproducibility purposes\n",
    "seed = 46\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Set the device (cuda for Nvidia GPUs, mps for M1, M2 .. Apple Silicon)\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = \"cpu\""
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
